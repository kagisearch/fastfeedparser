<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><atom:link href="https://anteru.net/rss.xml" rel="self" type="application/rss+xml"/><title>Anteru's blog</title><link>https://anteru.net</link><description>Anteru's blog is a blog about development, software architecture and 3D graphics.</description><generator>Liara 2.7.3</generator><language>en-US</language><copyright>Licensed under the &lt;a href="http://creativecommons.org/licenses/by/4.0/"&gt; Creative Commons Attribution 4.0 International License.</copyright><lastBuildDate>Sun, 15 Feb 2026 11:02:59 +0100</lastBuildDate><item><title>20 years of blogging</title><link>https://anteru.net/blog/2025/20-years-of-blogging</link><pubDate>Mon, 13 Jan 2025 12:00:00 +0200</pubDate><guid>https://anteru.net/blog/2025/20-years-of-blogging</guid><description>&lt;p&gt;Time flies, as people say, and this blog has been around now for &lt;strong&gt;twenty&lt;/strong&gt; years. Trying to do a retrospective on the past twenty years turns out to be actually much harder than anticipated - I&amp;rsquo;ll get to the &lt;em&gt;technical&lt;/em&gt; details in a minute, but the primary bottleneck here is my own memory. Which is funny considering this blog is somewhat a diary, but it&amp;rsquo;s missing the context as to why something was written, and how I did go about it. You only see the finished product. It&amp;rsquo;s an interesting exercise to try to figure out a certain trend tens years later - kind of like being the detective and the murderer at the same time.&lt;/p&gt;
&lt;h2 class="demoted"&gt;Non-tech&lt;/h2&gt;
&lt;p&gt;That said, the motivation as to why I&amp;rsquo;m blogging did definitely change over the years, and it&amp;rsquo;s not hard to see how and why. At the beginning, I&amp;rsquo;ve used my blog for personal &amp;ldquo;status updates&amp;rdquo; and what I thought were interesting news. Mind you, this was the time before social media was taking off and before there were more convenient ways to share &amp;ldquo;small news&amp;rdquo;. These days, you get enough &amp;ldquo;news&amp;rdquo; that I don&amp;rsquo;t feel there&amp;rsquo;s any value add from me posting about them. As for personal stuff &amp;ndash; it&amp;rsquo;s hard to have any kind of privacy these days even when not being on social media directly as you still get indirectly tagged, photographed, and what not. So personal updates also got sparse over time until they dried up completely.&lt;/p&gt;
&lt;p&gt;I also used to have comments enabled back in the day so I could have some kind of relationship with my readership, but turns out, that never was a thing. It was fairly clear to me early on (while I still had stats running) that nobody was reading the blog because of me, but because of technical content that they found via a search engine. Would have things gone differently if I had seen more engagement? I can&amp;rsquo;t tell. I was never looking for much praise or approval from my audience, so it&amp;rsquo;s really not clear to me in hindsight that the blog would me markedly different had I seen a community form around it.&lt;/p&gt;
&lt;p&gt;The other major trend is that I&amp;rsquo;ve become much more deliberate in what I&amp;rsquo;m posting about; or, one could say, professional? I would always proof-read a blog post, so that&amp;rsquo;s not it, but I wouldn&amp;rsquo;t always set up a list of &amp;ldquo;goals&amp;rdquo; I want to get across in a blog post. The bar to post went up a lot - which may have prevented a few &amp;ldquo;good enough&amp;rdquo; blog posts from coming out, but hopefully also resulted in a much better reading experience. Some more technical blog posts in recent years have definitely done extremely well as a result.&lt;/p&gt;
&lt;p&gt;One experiment I did a few times was to write a blog series, like the series about build systems, or the advent series. While this definitely does help to get a lot more content written than usual, it&amp;rsquo;s also fairly time-consuming. I don&amp;rsquo;t know if the series will have much of a future as a result.&lt;/p&gt;
&lt;h2 class="demoted"&gt;Tech&lt;/h2&gt;
&lt;p&gt;Technology wise, I used Wordpress for around half of the duration of this blog, and I got increasingly frustrated with it. After a brief stint using Nikola I ended up with my own static page generator &amp;ndash; actually the successor to the tool I wrote for the website of a small company. Looking back, I do regret that I didn&amp;rsquo;t carefully track the state of the blog over the years; there are a few theme changes I don&amp;rsquo;t recall at all that I can&amp;rsquo;t reproduce, and much of the Wordpress configuration was a &amp;ldquo;live installation&amp;rdquo; with no backup and no version control. Since switching to a static page generator things are much better, I can reasonably reconstruct the state of my blog in the last couple of years, but not having an archive of theme screenshots that I can review is kind of a bummer in retrospective. Not to mention it also means I always looked at the last and the current design when doing things; not at &amp;ldquo;how did I end up with this in the first place&amp;rdquo; as the history was lost.&lt;/p&gt;
&lt;p&gt;The stack today is incredibly simple. A web server hosting static files, a repository holding the blog content, and a &lt;code&gt;cron&lt;/code&gt; job (actually, a &lt;code&gt;systemd&lt;/code&gt; timer) which deploys the blog once every hour (if changed) to said server. This has served me reliably for a few years now, with I think less than 15 minutes of total maintenance needed. Very much the kind of system I like to have, especially as I want to keep the overhead of writing/maintaining this blog to a minimum so I use all the time I spend on this blog on adding content.&lt;/p&gt;
&lt;h2 class="demoted"&gt;Other thoughts&lt;/h2&gt;
&lt;p&gt;With all that said, where is this going? Spare time to blog has definitely been in decline, but I try to use this blog to &amp;ldquo;not repeat myself&amp;rdquo; and write down things I end up looking up every time I need them (like, how to write a &lt;code&gt;systemd&lt;/code&gt; timer.) At the same time, I&amp;rsquo;m fairly disappointed by the fact that &amp;ldquo;AI companies&amp;rdquo; suck up the knowledge and insights from blogs like the very one you&amp;rsquo;re reading and serve it to their customers, bypassing the source. The original deal when I started blogging was that a search engine would point you at it, you would read it, and form your opinion yourself, seeing the full unaltered blog post with my references as you read it. These days, you get a potentially incorrect summary, without attribution, and you can&amp;rsquo;t figure out where the information came from. Even if it gets attributed, there&amp;rsquo;s no guarantee the summary you see is correct, in which case you may think that I made the mistakes the large language model added &amp;ndash; and there&amp;rsquo;s no way for me to step in and correct it.&lt;/p&gt;
&lt;p&gt;This is definitely one factor which discourages me from blogging. I&amp;rsquo;m sure in the &amp;ldquo;big scheme of things&amp;rdquo; me blogging less or more is not going to help the overall situation, but it&amp;rsquo;s one of those things &amp;ldquo;out there&amp;rdquo; that quietly causes harm even if you don&amp;rsquo;t actually see the harm being done. That said, I still reference my blog myself, so I&amp;rsquo;ll keep using it as a notepad for &lt;em&gt;my&lt;/em&gt; problems.&lt;/p&gt;
&lt;p&gt;One last thought before I wrap this up: Link stability on the internet! I&amp;rsquo;ve been going to great lengths to make sure my blog has stable links; with hundreds of redirections in place to make sure old Wordpress-style links work (before I switched to slug-like links.) I&amp;rsquo;m also regularly running a script to make sure that outgoing links work, and sadly, the stories about &amp;ldquo;the internet never forgets&amp;rdquo; are quite exaggerated. A lot of links are gone, and despite me trying sometimes quite hard to find the referenced document, things are really gone. It&amp;rsquo;s actually quite surprising how much &amp;ldquo;stuff&amp;rdquo; is no longer available after 5, let alone 10 years on the internet. I haven&amp;rsquo;t found a good way to prevent this &amp;ndash; I guess trying to get the link into archive.org is one way, but it won&amp;rsquo;t work for software where even if you would find the download link, it&amp;rsquo;s no longer supported, the activation server is down, or whatever. Certainly not surprising, but disappointing that a lot of our &amp;ldquo;digital heritage&amp;rdquo; is just disappearing.&lt;/p&gt;
&lt;p&gt;So, what does the future hold? I&amp;rsquo;m not sure. Hopefully a few more blog posts about technical things, if I find the time to figure out some things &#128512;&lt;/p&gt;</description></item><item><title>Data formats: Why CSV and JSON aren't the best</title><link>https://anteru.net/blog/2024/data-formats-why-csv-and-json-aren-t-the-best</link><pubDate>Sun, 29 Dec 2024 15:15:00 +0100</pubDate><guid>https://anteru.net/blog/2024/data-formats-why-csv-and-json-aren-t-the-best</guid><description>&lt;p&gt;First an admission - I&amp;rsquo;m guilty of doing this myself, many moons ago, I would store results from experiments in a MongoDB and thus by extension as JSON. I hope that the corresponding blog post didn&amp;rsquo;t fuel the dramatic expansion of JSON as a storage format for data, as I learned over the years that JSON for data - along with CSV - is causing harm in the field. In this blog post, I want to correct for past mistakes and hopefully encourage you to re-consider the way you&amp;rsquo;re storing what is commonly referred to as &amp;ldquo;tabular&amp;rdquo; data (no, this is not how to do backups, store VM images, large files, etc. - really just stuff you would open in a spreadsheet application one day.)   &lt;/p&gt;
&lt;p&gt;Before we discuss the solution, I like to cover the requirements and &amp;ldquo;how did we get here in the first place&amp;rdquo;. Requirements are fairly easy - you&amp;rsquo;re running some application doing measurements, each measurement has many dimensions; i.e. you know what you&amp;rsquo;re measuring ahead of time (that&amp;rsquo;s your dimension/column names), and each time you measure you measure the same things (each measurement is a row.) If your dimensions change widely between measurements, then I&amp;rsquo;m not sure what you&amp;rsquo;re measuring; this may be fine at the beginning while exploring, but eventually you&amp;rsquo;ll want to settle down on a set of dimensions you care about and only evolve it carefully. Evolution here means versioning: You want to know &lt;em&gt;what&lt;/em&gt;  you measured and also &lt;em&gt;how&lt;/em&gt; you measured it. Versions allow you to capture both pieces of information, as long as you maintain a changelog.   &lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m stressing the versioning information here, as it&amp;rsquo;s critical to know what measurements you can trust. Unless you have perfect knowledge of everything, there &lt;em&gt;will be bugs&lt;/em&gt;  in your collection or processing, which will results in some dimensions containing garbage data at times. Time alone is not sufficient to identify this, some measurement devices/applications can get updated at different times, so you really want to bake in some version with each data set. If you don&amp;rsquo;t have versioning ready, your tools will start breaking over time, and your analysis becomes less and less reliable as different errors in measurements get mixed in. &lt;/p&gt;
&lt;p&gt;So far we have &amp;ldquo;tabular data&amp;rdquo; and &amp;ldquo;versioning&amp;rdquo; as requirements, one more requirement that&amp;rsquo;s more important than anyone would think at first and that trumps all other needs &lt;em&gt;in practice&lt;/em&gt; is &amp;ldquo;easy to explore&amp;rdquo;. If you need to write a script to look at the data, this may be fine in some cases, but if all you get is a raw file, you better be able to look at it with minimal friction. Minimal friction somewhat implies plain text, but we&amp;rsquo;ll get to that later.&lt;/p&gt;
&lt;p&gt;There are other requirements like performance or disk size, but they&amp;rsquo;re at best secondary until they completely dominate the decision. The majority of the time - at least in my experience - getting some data quickly is what matters most, and only once you accumulated a lot of data people will start to notice that all their disk drives are full and they should do something about it. I&amp;rsquo;m getting ahead of myself here though.&lt;/p&gt;
&lt;h2 class="demoted"&gt;The contenders&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s look at three popular solutions I&amp;rsquo;ve seen in the wild. A lot. Like, cannot be unseen times lot.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spreadsheet files for your favorite spreadsheet application&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.json.org"&gt;JSON&lt;/a&gt; (includes JSON stored in databases, be it NoSQL or thanks to recent improvements also real SQL databases)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Comma-separated_values"&gt;CSV&lt;/a&gt; - comma separated values&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="demoted"&gt;Spreedsheet files (application specific)&lt;/h2&gt;
&lt;p&gt;They&amp;rsquo;re not versioned, but we&amp;rsquo;ve obviously all seen people trying to put some extra info in a random cell, so let&amp;rsquo;s say they can be versioned with pain (an extra sheet with a version number, document properties, it&amp;rsquo;s not the end of the world.) Easy to look at - absolutely, as long as your favorite spreadsheet application is installed. Do they store tabular data well? Except for random re-interpretation of entries because you got the format wrong, they&amp;rsquo;re actually not terrible. The main issue I have with spreadsheet files as your main source of truth is - generating them is non-trivial, especially if you want to get all types done correctly, and they tend to be very large and slow to query (as in, batch processing of spreadsheet files is often not a good idea.) That said, out of the three popular solutions, if done right, they&amp;rsquo;re the least terrible. I really don&amp;rsquo;t like using them for performance reasons and because they tend to break in funny ways, but if you are hard pressed to make something work, and &amp;ldquo;convenience&amp;rdquo; is a premium, by all means, before going for the two solutions outlined below, get your &lt;a href="https://pandas.pydata.org/"&gt;Pandas&lt;/a&gt; script ready and use &lt;a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html"&gt;&lt;code&gt;to_excel&lt;/code&gt;&lt;/a&gt; (and keep in mind that can also create &lt;a href="https://groups.oasis-open.org/communities/tc-community-home2?CommunityKey=4bf06d41-79ad-4c58-9e8e-018dc7d05da8"&gt;ODF&lt;/a&gt; files so you&amp;rsquo;re not locked in.)&lt;/p&gt;
&lt;h2 class="demoted"&gt;CSV&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s get to CSV quickly: Trivial to generate, to the point that everyone generates their favorite flavor of CSV. I&amp;rsquo;ve written parsers for a dozen or so different variants of CSV in my life, mostly due to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No standard for string escaping. Every CSV file out there will have strings eventually, then strings with spaces, then strings with quotes, and all hell will break loose. I&amp;rsquo;ve seen escapes, triple quoting, double quotes, &amp;ldquo;last column is text&amp;rdquo;, and everything in-between.&lt;/li&gt;
&lt;li&gt;No standard types: Dates will be stored as strings (see above), and numbers won&amp;rsquo;t round-trip, because generally most CSV files out there are generated with &lt;code&gt;printf&lt;/code&gt; and friends which are not optimized to produce the shortest string or most accurate representation. Also, booleans will be &lt;code&gt;On&lt;/code&gt;/&lt;code&gt;Off&lt;/code&gt;, &lt;code&gt;Yes&lt;/code&gt;/&lt;code&gt;No&lt;/code&gt;, &lt;code&gt;True&lt;/code&gt;/&lt;code&gt;False&lt;/code&gt;, &lt;code&gt;0&lt;/code&gt;/&lt;code&gt;1&lt;/code&gt;, just never consistent.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Is CSV trivial to open? In theory yes, in practice - there are spreadsheet applications which can import CSV, but some fail in funny ways because commas are decimal separators in Europe for example. As a result your comma separated file is a one large number and imports as a single column over here. Do they work in editors? Not really, unless someone starts formatting the CSV for better readability (comma separated but tab-aligned values, anyone?)&lt;/p&gt;
&lt;p&gt;The final nail in the coffin in my book is that they simply can&amp;rsquo;t store versions. You&amp;rsquo;ll find a million different ways to put a version into a CSV file, all of which require domain knowledge by the reader to remove it (some extra row somewhere that needs to be ignored, a dummy column name, part of the filename, &amp;hellip;) That makes them really bad for archival storage in my book. You find some random CSV somewhere, your guess is as good as mine as to what version it was, what application it belonged to, how it was captured, etc.&lt;/p&gt;
&lt;p&gt;Why are they so popular? Other than &amp;ldquo;trivial to generate&amp;rdquo; and &amp;ldquo;feels trivial to look at because it&amp;rsquo;s text&amp;rdquo;, I&amp;rsquo;m not sure. They cause long-term harm due to complexity throughout the stack to process them, and the &amp;ldquo;trivial to look at because it&amp;rsquo;s text&amp;rdquo; argument falls short the moment you have a decent amount of data (ever tried opening a 20+ MiB CSV file in an editor?) It&amp;rsquo;s really a perception issue more than any hard technical argument that keeps them so popular.&lt;/p&gt;
&lt;h2 class="demoted"&gt;JSON&lt;/h2&gt;
&lt;p&gt;The other popular choice - especially due to NoSQL databases - is JSON. Versioning and metadata is easy with JSON, just add additional fields, so let&amp;rsquo;s get that sorted out immediately. Reading by humans? JSON is definitely not meant to be consumed by humans, especially once the files become big and consist of arrays mostly. With &lt;code&gt;jq&lt;/code&gt; you can get something resembling a query language for JSON, but good luck getting your JSON data into a spreadsheet application (or a tabular format, for that matter.) The biggest problem with JSON though is that it &amp;hellip; can&amp;rsquo;t store numbers properly. It&amp;rsquo;s JSON, so everything is a &lt;code&gt;double&lt;/code&gt;, in theory, but doubles can only represent integers up to 53 bit precisely, and again you have the same issues with round-trips of numbers as CSV (and in practice much earlier than that, for example, 64-bit integers don&amp;rsquo;t work in general.) Not to mention, there&amp;rsquo;s no standard way to store a date in JSON.&lt;/p&gt;
&lt;p&gt;Finally, I&amp;rsquo;ve seen JSON storing each row as an object, with the column names repeated: That&amp;rsquo;s a 10-100x expansion of the source data. Granted, any compression algorithm will get this removed again, but the amount of redundant parsing in those cases is staggering.&lt;/p&gt;
&lt;p&gt;To wrap it up, JSON fails on all accounts as a &lt;em&gt;file format&lt;/em&gt;, and the main reason to use it is really for convenience when using a document based database. But even then, if the database was extracting out the structure and store everything binary, you still get all the problems of JSON back when translating to/from JSON across the wire.&lt;/p&gt;
&lt;p&gt;Before you start with binary JSON and alternative JSON encodings: There&amp;rsquo;s simply too many of them (&lt;a href="https://bsonspec.org/"&gt;BSON&lt;/a&gt;, &lt;a href="https://ubjson.org/"&gt;UBJSON&lt;/a&gt;, &lt;a href="https://cbor.io/"&gt;CBOR&lt;/a&gt;, &lt;a href="https://msgpack.org/"&gt;MessagePack&lt;/a&gt;, &amp;hellip;) and there&amp;rsquo;s no standard, so good luck finding a library to write whatever flavour of binary JSON you have and find a matching reader in your scripting language or elsewhere.&lt;/p&gt;
&lt;h2 class="demoted"&gt;Protocol Buffers, HDF5, Parquet to the rescue?&lt;/h2&gt;
&lt;p&gt;There&amp;rsquo;s a bunch of structured message formats like protocol buffers out there, but they&amp;rsquo;re not really that well suited for processing large data sets as their goal is to facilitate RPC (and they come with a fair amount of overhead, i.e. protocol definitions, etc.) There&amp;rsquo;s also HDF5 which technically sounds like a good solution, but never really took off outside of its community. If I had to guess, it&amp;rsquo;s a bit too flexible for its own good - I&amp;rsquo;m sure there are good use cases to store arbitrary binary files inside a HDF5 file, but it also adds complexity on the consumer side. It also doesn&amp;rsquo;t give you much in terms of simplified access or &amp;ldquo;tabular&amp;rdquo; data benefits.&lt;/p&gt;
&lt;p&gt;Interestingly, there is a format though which is pretty much a 1:1 replacement for CSV and spreadsheet files, with little &amp;ldquo;extra&amp;rdquo;, and it&amp;rsquo;s binary, and has bindings for most (all?) programming language you&amp;rsquo;d care about: &lt;a href="https://parquet.apache.org/"&gt;Parquet&lt;/a&gt;. It&amp;rsquo;s a column based format (that only matters if you filter out columns), it supports modern compression algorithms (&lt;a href="https://facebook.github.io/zstd/"&gt;Zstd&lt;/a&gt;), and it provides a fairly clean mapping of the &amp;ldquo;spreadsheet&amp;rdquo; concept. The format itself is a bit too complex for my taste (being layered on top of Apache Thrift), but, it slots into the right place in the ecosystem. It&amp;rsquo;s trivially readable/writable by Pandas, and there are open-source viewers for it (like &lt;a href="https://github.com/microsoft/vscode-data-wrangler"&gt;Data Wrangler&lt;/a&gt;), and also databases for it (&lt;a href="https://iceberg.apache.org/"&gt;Iceberg&lt;/a&gt;, &lt;a href="https://duckdb.org/"&gt;DuckDB&lt;/a&gt;.) Spreadsheet application support is non-existant, but, it&amp;rsquo;s fairly easy to convert Parquet into other formats, so my recommendation would be to treat the other formats as a derivative and generate them on-demand.&lt;/p&gt;
&lt;p&gt;Parquet does solve the typing problem nicely, as each column is strongly typed, and being binary it means it will round-trip. The main strength is really that it&amp;rsquo;s super simple to process a Parquet file &amp;ldquo;down to&amp;rdquo; CSV or other formats as it&amp;rsquo;s not dramatically different. You can&amp;rsquo;t trivially convert HDF5 to CSV or any of the JSON formats, but here you can and that makes it easy to please the convenience crowd.&lt;/p&gt;
&lt;p&gt;Does this solve all problems? It allows for versioning by adding meta-data to the file, so that&amp;rsquo;s covered. Tabular data - by construction. Easy to view - relatively good. It does win big time on the performance and size dimensions though, and it&amp;rsquo;s easy to use from various programming languages, so in the end it has become my current format of choice as the &lt;em&gt;primary&lt;/em&gt; storage format. It seems also reasonable good for archival storage as the format is well-documented and everything built around it is open-source, so at the very least, at some day you&amp;rsquo;ll be able to convert from Parquet into whatever will be the best format at the time to store things. As long as it&amp;rsquo;s not JSON or CSV, you have my blessing! In the meantime, I think Parquet is about as good as it gets, so if you are struggling with the same problems as I do, please give it a shot.&lt;/p&gt;</description></item><item><title>Replacing cron with systemd-timers</title><link>https://anteru.net/blog/2024/replacing-cron-with-systemd-timers</link><pubDate>Sun, 21 Apr 2024 16:00:00 +0200</pubDate><guid>https://anteru.net/blog/2024/replacing-cron-with-systemd-timers</guid><description>&lt;p&gt;I&amp;rsquo;ve been recently spending some time &amp;ldquo;cleaning up&amp;rdquo; my system configuration across a few VMs I&amp;rsquo;m running locally, and as part of that, I&amp;rsquo;ve moved all recurring jobs from &lt;a href="https://en.wikipedia.org/wiki/Cron"&gt;&lt;code&gt;cron&lt;/code&gt;&lt;/a&gt; to &lt;a href="https://www.freedesktop.org/software/systemd/man/latest/systemd.timer.html"&gt;&lt;code&gt;systemd&lt;/code&gt;&lt;/a&gt;. This may seem like the most boring task in the world, but it turns out that &lt;code&gt;systemd-timer&lt;/code&gt; is so much better than &lt;code&gt;cron&lt;/code&gt; that it was actually quite a lot of fun in the end to have everything converted. The end result is a cleaner system configuration, with more functionality, but I&amp;rsquo;m already getting ahead of myself here. Let&amp;rsquo;s go back to the start: Why do I even bother?&lt;/p&gt;
&lt;h3 class="demoted"&gt;What&amp;rsquo;s wrong with &lt;code&gt;cron&lt;/code&gt;?&lt;/h3&gt;
&lt;p&gt;My gripes with &lt;code&gt;cron&lt;/code&gt; are numerous, but the main issues I have with it are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No easy way to try out short of copy/pasting command lines around. I sometimes want to run a job immediately (like, deploy this very blog), and there&amp;rsquo;s no easy way to do so with &lt;code&gt;cron&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;There&amp;rsquo;s no easy way to find all jobs to start with. Ansible likes to put them into &lt;code&gt;crontab&lt;/code&gt;, other tools put them into &lt;code&gt;/etc/cron.d&lt;/code&gt;, but there&amp;rsquo;s no unified view of all jobs and when they ran last time or going to run next time.&lt;/li&gt;
&lt;li&gt;Log output goes somewhere I can never find it.&lt;/li&gt;
&lt;li&gt;There&amp;rsquo;s no easy way to disable a job briefly. I want to run a backup and stop three jobs from running, so I need to start moving files in and out of &lt;code&gt;/etc/cron.d/&lt;/code&gt; &amp;hellip;?&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cron&lt;/code&gt; doesn&amp;rsquo;t care if your previous job finished, so if you do something like a mirror script, it may start the next job while the previous hasn&amp;rsquo;t finished yet.&lt;/li&gt;
&lt;li&gt;Can&amp;rsquo;t start a job at a randomized time, or at a time relative to system boot, or make sure a job gets run on next boot if the machine was off during the scheduled time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It&amp;rsquo;s actually quite a few issues if you think about this, for something which looks easy at first. To be clear: I&amp;rsquo;m not blaming the &lt;code&gt;cron&lt;/code&gt; authors here &amp;ndash; it was a great tool when it was written, and it does its job well. But my needs have grown beyond the basics of what &lt;code&gt;cron&lt;/code&gt; can provide. There&amp;rsquo;s no simple way to &amp;ldquo;fix&amp;rdquo; &lt;code&gt;cron&lt;/code&gt; without making it a complete mess, and I wouldn&amp;rsquo;t recommend anyone to try it. It&amp;rsquo;s one of those cases where the complexity has grown over time and there&amp;rsquo;s no simple solution to it; trying to retro-fit this into &lt;code&gt;cron&lt;/code&gt; would take away the main appeal of it, which is actually the simplicity.&lt;/p&gt;
&lt;h3 class="demoted"&gt;&lt;code&gt;systemd-timer&lt;/code&gt; to the rescue?!&lt;/h3&gt;
&lt;p&gt;What&amp;rsquo;s this new solution you&amp;rsquo;re asking? It&amp;rsquo;s &lt;code&gt;systemd-timer&lt;/code&gt; &amp;ndash; I&amp;rsquo;ve learned about &lt;code&gt;systemd-timer&lt;/code&gt; a while ago, but never had a chance to use them in earnest. A few months ago I did have a regular script I needed to run at work where the issue was that &lt;code&gt;cron&lt;/code&gt; cannot be configured to run it every 5 minutes &lt;em&gt;after&lt;/em&gt; it has finished, so it ended up running for example at 5 past, not at 10 past (as it hasn&amp;rsquo;t finished), then again at 15 past, then at 25 past the hour, and so on, depending on how lucky we were with execution time. I&amp;rsquo;ve moved this to &lt;code&gt;systemd-timer&lt;/code&gt; and now it runs super regularly, and while this was a minor win, it convinced me that &lt;code&gt;systemd-timer&lt;/code&gt; is worth a look.&lt;/p&gt;
&lt;p&gt;Over the last two weeks, I&amp;rsquo;ve converted &lt;em&gt;all&lt;/em&gt; my &lt;code&gt;cron&lt;/code&gt; jobs to &lt;code&gt;systemd-timer&lt;/code&gt;, and what can I say - things are looking great. The process for converting itself is fairly manual, you need to create two things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;code&gt;your-timer.service&lt;/code&gt; unit file describing what to run. This is also what you use for debugging, i.e. you run &lt;code&gt;systemctl run your-timer.service&lt;/code&gt; if you want to run it at any given time manually.&lt;/li&gt;
&lt;li&gt;A &lt;code&gt;your-timer.timer&lt;/code&gt; unit file describing the timer itself. This is what you enable/start using &lt;code&gt;systemctl&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once you set it up this way, you can use &lt;code&gt;systemctl list-timers&lt;/code&gt; to view all timers, when they ran last time, and when they will run next time. This includes (amazingly!) also random offsets you want to add to the timers, for example, to avoid your &lt;code&gt;Let's encrypt&lt;/code&gt; script from hitting the servers at precisely 02:00 every night.&lt;/p&gt;
&lt;h3 class="demoted"&gt;What makes it really useful&lt;/h3&gt;
&lt;p&gt;More cool stuff you can do with &lt;code&gt;systemd-timer&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;systemd-analyze calendar&lt;/code&gt; allows you to check your timing rules. With &lt;code&gt;--iterations=N&lt;/code&gt; you can also check for additional iterations - that saves so much time it&amp;rsquo;s not even funny.&lt;/li&gt;
&lt;li&gt;For per-user timers, you can put them into &lt;code&gt;~/.config/systemd/user&lt;/code&gt;. Make sure to enable linger (&lt;code&gt;loginctl enable-linger username&lt;/code&gt;) so they get executed.&lt;/li&gt;
&lt;li&gt;Check when your timer ran last time and when it&amp;rsquo;s scheduled to run again &amp;ndash; &lt;code&gt;systemctl list-timers&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Output is trivially found via &lt;code&gt;journalctl -u your-timer.service&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Randomize the start time, for example, using &lt;code&gt;RandomizedDelaySec&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For deployment, I continue to use &lt;code&gt;ansible&lt;/code&gt;, and it boils down to copying two files over and enabling the service. In the end, it didn&amp;rsquo;t take me that long to revisit all my jobs, move them to Ansible, and I&amp;rsquo;m very pleased with the results so far. I already had to disable some jobs while replacing a drive which was trivial to do, as I could use the &lt;a href="https://cockpit-project.org/"&gt;&lt;code&gt;cockpit&lt;/code&gt; UI&lt;/a&gt; to simply click on them to disable (I know, I know, what kind of Linux administrator uses the mouse &amp;hellip;). It&amp;rsquo;s one of those &amp;ldquo;small things&amp;rdquo; that seem insignificant at first, but once you realize the first benefits, it&amp;rsquo;s hard to go back to the more arcane ways. That&amp;rsquo;s all for today, thanks for reading, and if you have &lt;code&gt;cron&lt;/code&gt; jobs on your system, you know what to do!&lt;/p&gt;</description></item><item><title>Open Source Maintenance</title><link>https://anteru.net/blog/2024/open-source-maintenance</link><pubDate>Tue, 02 Apr 2024 22:00:00 +0200</pubDate><guid>https://anteru.net/blog/2024/open-source-maintenance</guid><description>&lt;p&gt;This has been a topic I wanted to cover for a long time now, but with the recent stories about &lt;a href="https://www.cve.org/CVERecord?id=CVE-2021-44228"&gt;&lt;code&gt;log4j&lt;/code&gt;&lt;/a&gt; and the &lt;a href="https://www.cve.org/CVERecord?id=CVE-2024-3094"&gt;&lt;code&gt;xz&lt;/code&gt;&lt;/a&gt; vulnerability, I figured it&amp;rsquo;s high time to get this finally out of the door. Open source software the way we know simply doesn&amp;rsquo;t work any more, and we&amp;rsquo;ve probably crossed the point where it can be fixed without a lot of pain for everyone involved.&lt;/p&gt;
&lt;p&gt;&#9888; Warning: I&amp;rsquo;ll be obviously generalizing here. There&amp;rsquo;s always that one unicorn library somewhere which is well funded, has no security issues, no dependencies, and what not. Please don&amp;rsquo;t get hung up because there&amp;rsquo;s one counter example.&lt;/p&gt;
&lt;h3 class="demoted"&gt;Maintainer fatigue&lt;/h3&gt;
&lt;p&gt;As an open source project maintainer myself, I do want to talk about &amp;ldquo;maintainer fatigue&amp;rdquo;. Many open source projects out there are hobby projects which make no money (more on this later though.) This means they&amp;rsquo;re a &amp;ldquo;labor of love&amp;rdquo;, but most of the time, they&amp;rsquo;re scratching some particular itch of the maintainer. That also means that open source maintenance comes without guarantees or commitments &amp;ndash; I can always step away for a while, a long time, or forever, and it&amp;rsquo;s my problem first and foremost. If it becomes your problem that some open source library becomes dormant, that usually implies you&amp;rsquo;ve been building a business on top of someone&amp;rsquo;s free labor (even if they&amp;rsquo;re paid for writing it, you got it for free in the end by virtue of being open source), and this &amp;ldquo;no cost&amp;rdquo; mentality is now causing you trouble.&lt;/p&gt;
&lt;p&gt;Everyone needs to be aware that an open source maintainer is probably a person who has a day job (which means money is probably not the main motivation anyways!), has a life outside of work as well (and that life consists of more things than maintaining their open source library), and that a lot of time in an open source project already sinks into just dealing with feedback and making a release to start with. I&amp;rsquo;ve seen it many times where someone feels entitled that their favorite PR or issue should get addressed by the maintainers, who are already struggling to even keep the number of PRs not growing exponentially, and are still expected to make regular releases on top of everything. Burning out maintainers is a sure way to make things worse very quickly for everyone involved, and I see very few open source projects run by volunteers who aren&amp;rsquo;t struggling with this. Even those with commercial backing usually have their share of &amp;ldquo;grumpy customers&amp;rdquo; who don&amp;rsquo;t pay and yet demand, and still struggle to handle external contributions.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s also something about open source software which I&amp;rsquo;d call &amp;ldquo;doing it right&amp;rdquo;. Given it&amp;rsquo;s a hobby project for most developers, and also something they care about, that care usually translates into not taking shortcuts and adhering to higher quality standards than you&amp;rsquo;d have let&amp;rsquo;s say in a company where there&amp;rsquo;s pressure to hit some deadline. This results in some &amp;ldquo;guilt driven development&amp;rdquo;: As an open source maintainer, you really want to do things properly, which means most PRs won&amp;rsquo;t meet the bar to start with (especially from people with said deadlines), and you get into a self-reinforcing cycle.&lt;/p&gt;
&lt;p&gt;What makes this a real problem is that there&amp;rsquo;s really no simple way out. You can try to pay maintainers (if they have set up means for that), but that doesn&amp;rsquo;t necessarily translate into more time devoted to the project. You can fork the project which most of the time results in a disaster if you take it public. You can try to contribute to the project in helpful ways to reduce/offload the maintainers, but that may only get you so far. Finally, you can also try to become actively involved, but realistically that&amp;rsquo;s probably not what you want (especially if you only care about this one feature) and it brings us to the next problem, which is: Trust.&lt;/p&gt;
&lt;h3 class="demoted"&gt;Maintainer trust&lt;/h3&gt;
&lt;p&gt;There&amp;rsquo;s no guarantee to start with that your friendly maintainer is even the person you think they are. Some random contributor may be a malicious actor, only waiting to have enough power to use the project for bad. This will become worse over time as maintainers simply retire or die, and we&amp;rsquo;ll have to figure out how to hand over maintenance from a well-known public figure to someone who may not have built up any reputation or trust with the community. There&amp;rsquo;s no help for maintainers to make this transition, and the security implications are mind-blowing and worrying. Just think about it: At any given time, the &amp;ldquo;load bearing&amp;rdquo; libraries with 1-2 maintainers may have one maintainer hit by a bus and then some enthusiastic person in the community shows up to take over or forks it and puts some work to make the fork look attractive. How quickly would you switch to a new &lt;code&gt;zlib&lt;/code&gt; if you heard the original one got abandoned and &lt;code&gt;super-zlib-turbo2&lt;/code&gt; is merging all new features and making rapid progress? Would you audit this new library if you see a reputable project use it? Would you &lt;em&gt;pay&lt;/em&gt; for an audit?&lt;/p&gt;
&lt;p&gt;The reality is that the software ecosystem is a house of cards held together by duct tape and hope, and the fact that it hasn&amp;rsquo;t completely imploded yet is because there&amp;rsquo;s still just enough people paying attention. But we can clearly see that hope is not enough, and with software becoming increasingly more complex, the number of attack vectors is increasing. Every dependency we introduce into our software is a potential security issue, and every maintainer we don&amp;rsquo;t know is another random person we hand the key to our system. You wouldn&amp;rsquo;t plug in a random USB thumb drive you&amp;rsquo;d find in the streets, but we&amp;rsquo;re more than happy to pull in 10.000 different pieces of code and execute them during a build. Trust is hard to build in the real world, and historically we&amp;rsquo;ve trusted our fellow software developers to do the right thing. It&amp;rsquo;s clear by now that we need to change the default assumption from &amp;ldquo;trust everyone&amp;rdquo; to &amp;ldquo;trust no-one&amp;rdquo; if we don&amp;rsquo;t want history to repeat itself.&lt;/p&gt;
&lt;h3 class="demoted"&gt;AI will save us&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;m a bit puzzled that nobody has brought up the &amp;ldquo;AI will save us&amp;rdquo; card yet. You could imagine that someone could train an AI to audit code for &amp;ldquo;suspicious changes&amp;rdquo; and help maintain it in the same way as the original maintainer (&amp;ldquo;what would Linus do?&amp;rdquo;) It&amp;rsquo;s an interesting avenue to explore, but ultimately, it doesn&amp;rsquo;t solve the underlying problems of maintainer fatigue, and from a security perspective this may be even worse (&amp;ldquo;the AI thinks this blob of data is safe&amp;rdquo;.) Not to mention that training an AI on security backdoors may backfire in the sense we&amp;rsquo;ll get AI assisted backdoor injection, which will only end up in an arms race where understaffed projects will have no chance to survive under a barrage of AI generated, hard-to-spot backdoors. I&amp;rsquo;m mostly adding it for the sake of completeness here, not because I see it as a general solution.&lt;/p&gt;
&lt;h3 class="demoted"&gt;Closed source is better&lt;/h3&gt;
&lt;p&gt;Just to get this out as well: There&amp;rsquo;s no reason to assume that closed source helps here; there&amp;rsquo;s little closed source code in existence these days which doesn&amp;rsquo;t heavily rely on open source to start with; and we simply don&amp;rsquo;t see what&amp;rsquo;s going on in a closed source codebase. Given the widespread fallout we see from open source library security issues, and how most closed source handles dependencies (and updates), it&amp;rsquo;s fair to assume that &amp;ldquo;closed source&amp;rdquo; doesn&amp;rsquo;t actually solve any of the problems.&lt;/p&gt;
&lt;h3 class="demoted"&gt;And now what?&lt;/h3&gt;
&lt;p&gt;That&amp;rsquo;s the question I&amp;rsquo;ve been asking myself for a while. What do we do about all of this? For me for example, more money wouldn&amp;rsquo;t actually make me more motivated to spend time on my open source projects, and it&amp;rsquo;s hard to imagine that I could actually make a living off my open source projects. Doesn&amp;rsquo;t look like a promising avenue to me. Mandatory payment however to fund audits of open source software could be interesting, together with &amp;ldquo;tagged and certified&amp;rdquo; releases. Something which allows you to get at least one working version of every dependency which has been at least audited to some extent. That&amp;rsquo;s only a partial solution though as dependency management these days is so complex, that there&amp;rsquo;s no way to fully solve this until you can basically audit close to every version of every dependency.&lt;/p&gt;
&lt;p&gt;What else could we do? Mandatory identity management for contributors, at least that way you could figure out if a person is real, but that poses a lot of problems if your project gets considered problematic (think: &lt;code&gt;DeCSS&lt;/code&gt;), and it&amp;rsquo;s unclear how well this would work if state actors are involved anyways: What&amp;rsquo;s the point if having a verified identity if the government issuing it is involved? What could be done though is at least mandate all verified commits, 2FA, the little things that give at least some confidence that an account hasn&amp;rsquo;t been compromised.&lt;/p&gt;
&lt;p&gt;This is really a complex problem, and the solution to this will be equally complex. Just helping maintainers for example is not going to resolve ownership issues, security problems, and certainly doesn&amp;rsquo;t fix the fact that a lot of &amp;ldquo;the industry&amp;rdquo; relies on essentially free labor. Similarly, introducing more process will not help when your maintainer is already burned out and struggling to even make one release happen. I wish I had some answers to the problems, but for now, I think the most important steps everyone can take is to review their own situation. If you&amp;rsquo;re a maintainer or consumer of an open source project, start asking yourself &amp;ldquo;what if?&amp;rdquo; and try to come up with ideas. Eventually I&amp;rsquo;m sure we&amp;rsquo;ll figure something out that works better than what we have now, because I hope it&amp;rsquo;s clear by now that the &amp;ldquo;status quo&amp;rdquo; will eventually lead to a &amp;ldquo;system wide&amp;rdquo; disaster (i.e. vulnerabilities affecting the majority of all users.)&lt;/p&gt;</description></item><item><title>Angular, Caddy, Gunicorn and Django</title><link>https://anteru.net/blog/2023/angular-caddy-and-django</link><pubDate>Sat, 21 Oct 2023 14:00:00 +0200</pubDate><guid>https://anteru.net/blog/2023/angular-caddy-and-django</guid><description>&lt;p&gt;This took me way more time than I anticipated, so here&amp;rsquo;s the summary in case any of you (or future me) runs into the same situation. The stage: I have a &lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; application which provides a &lt;a href="https://graphql.org/"&gt;GraphQL&lt;/a&gt; endpoint, and an &lt;a href="https://angular.io/"&gt;Angular&lt;/a&gt; frontend using it. Everything is hosted via &lt;a href="https://caddyserver.com/"&gt;Caddy&lt;/a&gt;, and Django is served through &lt;a href="https://gunicorn.org/"&gt;Gunicorn&lt;/a&gt;. So far so good. Now, I was using Django (via some plugins) to serve the Angular web application, so the typical request would be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Caddy gets the requests and forwards it to Gunicorn&lt;/li&gt;
&lt;li&gt;Gunicorn invokes Django&lt;/li&gt;
&lt;li&gt;Django reads the static file and serves it&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of this mostly because I was too lazy to set this up correctly; Django has a static files module which seemed like it could do the trick, and it somewhat works, but the correct way to do this is as following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Caddy serves &lt;em&gt;all&lt;/em&gt; static files&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If the path is &lt;code&gt;/static/*&lt;/code&gt;, it serves from the Django &lt;a href="https://docs.djangoproject.com/en/4.2/ref/settings/#std-setting-STATIC_ROOT"&gt;&lt;code&gt;STATIC_ROOT&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Otherwise, if the file exists, it serves from the Angular root&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If the path is unknown, it redirects it to the Angular root (as we assume this is an Angular route)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;How do we achieve that? It&amp;rsquo;s actually not that complicated. On the Django side, there&amp;rsquo;s nothing to do really. Just set the &lt;code&gt;STATIC_ROOT&lt;/code&gt; and remember what you set it to. Now comes the &lt;code&gt;Caddyfile&lt;/code&gt;:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;my.host.url {
        tls /srv/certs/caddy/cert.crt /srv/certs/caddy/cert.key

        @angular {
                not path /graphql
                not path /admin/*
                not path /account/*
        }

        handle_path /static/* {
                root * /srv/app/django/static
                file_server
        }

        handle {
                reverse_proxy unix//run/gunicorn.sock
        }

        handle @angular {
                root * /srv/app/angular
                try_files {path} {path}/ /index.html
                file_server
        }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;What this does is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Defines a &lt;a href="https://caddyserver.com/docs/caddyfile/matchers#named-matchers"&gt;named matcher&lt;/a&gt; to exclude all paths that should be handled by Angular (&lt;code&gt;@angular&lt;/code&gt;) &amp;ndash; this matches the paths that should &lt;em&gt;not&lt;/em&gt; go to Django&lt;/li&gt;
&lt;li&gt;Sends all &lt;code&gt;/static/*&lt;/code&gt; requests to a &lt;a href="https://caddyserver.com/docs/caddyfile/directives/file_server#file-server"&gt;file server&lt;/a&gt; (note: You can configure that path in case it conflicts with your Angular app via &lt;a href="https://docs.djangoproject.com/en/4.2/ref/settings/#static-url"&gt;&lt;code&gt;STATIC_URL&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Connects Caddy to Gunicorn/Django &amp;ndash; everything that is not handled by Caddy will go here. This is important so we can run the admin console.&lt;/li&gt;
&lt;li&gt;Sends the remaining requests to Angular: &lt;a href="https://caddyserver.com/docs/caddyfile/directives/try_files#try-files"&gt;&lt;code&gt;try_files&lt;/code&gt;&lt;/a&gt; tries to serve a local file, and if that fails, it will serve &lt;code&gt;index.html&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Voil&#224;, that&amp;rsquo;s it. It&amp;rsquo;s easier if you don&amp;rsquo;t care about the Django admin page and so on, but in my case, I do want to keep the ability to open that. With this configuration, you get the optimal performance serving any static file (as both the Django and Angular static files get served by Caddy), while retaining all the usual Django goodness, without any additional build time complexity.&lt;/p&gt;</description></item><item><title>Effective meetings</title><link>https://anteru.net/blog/2022/effective-meetings</link><pubDate>Mon, 12 Sep 2022 21:30:00 +0200</pubDate><guid>https://anteru.net/blog/2022/effective-meetings</guid><description>&lt;p&gt;If you&amp;rsquo;re a &amp;ldquo;knowledge worker&amp;rdquo; in a &amp;ldquo;normal&amp;rdquo; company, meetings will be a familiar occurrence in your calendar, more so now with a lot of work-from-home/remote workers. In my experience, while there is an infinite amount of ways to run ineffective meetings, effective meetings tend to all look kind of similar.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll be focusing here on the usual half-an-hour to an hour or two meeting trying to &amp;ldquo;move things forward&amp;rdquo; and give you some ideas how you can improve those. Before implementing things, please do take the time to make sure that the goals you&amp;rsquo;re trying to achieve in a meeting are aligned with the goals outlined below. Not all meetings fall into the category I&amp;rsquo;m covering here. For example, offsites, 15 minute standups, team discussions, etc. likely require a different treatment because they address different needs. If you&amp;rsquo;re meeting over lunch to improve the team spirit, trying to turn that into an &amp;ldquo;effective meeting&amp;rdquo; as outlined here will probably achieve the opposite result.&lt;/p&gt;
&lt;h3 class="demoted"&gt;Why are we meeting?&lt;/h3&gt;
&lt;p&gt;Before we start, we need to take a step back. In my opinion, if there&amp;rsquo;s a meeting, there should be a goal associated with it. That goal should be one of those two:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Provide information &lt;strong&gt;without&lt;/strong&gt; immediate decision making/task assignment &amp;ndash; this covers everything from a weekly status update to a presentation of some work.&lt;/li&gt;
&lt;li&gt;Provide information &lt;strong&gt;with&lt;/strong&gt; immediate decision making/task assignment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you&amp;rsquo;re not providing any information, then the first kind of meeting is pointless, and the second one will result in bad decisions as some decision makers will be missing information. There&amp;rsquo;s of course the unlikely case that everyone has the information needed to make a decision, then your meeting should be rather short. One thing you should also keep in mind here that decision making can also mean that &lt;em&gt;no&lt;/em&gt; decision is taken and things get postponed. That&amp;rsquo;s perfectly fine!&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s easy to see that &lt;em&gt;providing information&lt;/em&gt; has to be part of every meeting, otherwise you&amp;rsquo;re not gaining anything from it. Before we look at how to convey the information, we need to answer another question first: How &lt;em&gt;valuable&lt;/em&gt; is the information?&lt;/p&gt;
&lt;h3 class="demoted"&gt;The value of a &lt;strike&gt;meeting&lt;/strike&gt; piece of information&lt;/h3&gt;
&lt;p&gt;The reason for quantifying the value is simple: If you want to optimize something, you need to measure it first. That may feel really complicated for a meeting &amp;ndash; what metric should we use? How the heck do I quantify a meeting? Clearly a simple metric &amp;ndash; for example, the number of action items provided &amp;ndash; is not going to cut it. However, we just said that &lt;em&gt;providing information&lt;/em&gt; is at the core of a meeting, so if we could quantify the value of the information we could maybe get somewhere. While this may sound equally difficult at first, in my opinion, there&amp;rsquo;s a great way to quantify any kind of information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How &lt;em&gt;much&lt;/em&gt; does it change your behavior?&lt;/li&gt;
&lt;li&gt;How &lt;em&gt;quickly&lt;/em&gt; does it change?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is a simple method which works well when it comes to a piece of information. If I tell you the lottery numbers for next week, you&amp;rsquo;ll likely change your behavior immediately. This makes it a piece of high value information. If I tell you the weather forecast for next year, you may change your behavior (install an A/C, or something), but it&amp;rsquo;s unlikely it&amp;rsquo;ll happen immediately. And if I tell you that a brand new TV has come out but you already have one, you make take a note, but your behavior will not change much and not anytime soon, so this is a not very valuable information. To put it into a plot, you want to be in the top-right corner all the time if you can help it:&lt;/p&gt;
&lt;figure class="diagram"&gt;
  &lt;img alt="Information quality chart: An XY chart, the X axis being the urgency of change, and the Y axis the scope of change. A box in the top-right, i.e. most urgent, largest scope change says 'You'll die tomorrow unless you act' to indicate a high-priority, large-scope change. The bottom-left box says 'New TV, but you have one' to exemplify a low-priority, small-scope change. Two more boxes are depicted: Bottom right says 'Lottery numbers' and the middle-left 'Hot summer next year'." src="/images/2022/information-quality.svg" style="max-width: 512px"&gt;
&lt;/figure&gt;

&lt;p&gt;In my opinion, meetings should be measured using the same metric. &lt;strong&gt;A good meeting should cause people to act differently afterwards&lt;/strong&gt;. A bad meeting results in everyone continuing as before. This also implies that even if your information may not be that fantastic to start with, ending a meeting by making decisions/assigning tasks increases the value as it will result in behavior changes. After all, someone will not do the other thing that you made a decision on; or someone will not take on a task that wasn&amp;rsquo;t assigned to them.&lt;/p&gt;
&lt;h3 class="demoted"&gt;Applying optimization techniques&lt;/h3&gt;
&lt;p&gt;Armed with that information (which is valuable, as we can immediately apply it!) we can now try to optimize our metric. Interestingly, for both kinds of meetings, the same guidelines apply:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Only &lt;strong&gt;include people who are directly affected&lt;/strong&gt;. That requires some discipline from everyone as being invited to meetings makes you feel important, but do check what value &lt;em&gt;you&lt;/em&gt; get out of it. How does it help our metric? It increases the chance that the people in the meeting will be the ones changing their behavior as there are no bystanders.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Provide information up-front&lt;/strong&gt; to quickly move into the process of assigning actions, as much as possible. This means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Always have an agenda. That&amp;rsquo;s the &lt;em&gt;absolute minimum&lt;/em&gt; of pre-meeting information that must be shared.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you have slides, send them ahead of the meeting so everyone can read them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ideally: Provide some text that gets everyone up to speed, as text has higher information density than slides. It also requires more effort on the producer/consumer side, so it more likely gets the message across.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How does this help? It ensures that information is available and shortens the time on bringing everyone onto the same page.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Start with a quick review&lt;/strong&gt; of the information provided, the motivation, and the ask you have. How does this help our metric? It makes sure that people who shouldn&amp;rsquo;t be there can leave, and helps everyone agree on the desired outcome. This makes it again more likely people will act on it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Always take notes&lt;/strong&gt;: Make sure to &lt;em&gt;not&lt;/em&gt; continue on the notes from the last meeting, but specifically what was covered in that particular instance.  Meeting recordings are not nearly as valuable as good meeting notes, as you can&amp;rsquo;t review a recording quickly. How does this help our cause? Meeting notes document the commitments made, so everyone is clear on the next steps.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Amazon is famously known for taking the &amp;ldquo;prepare text before meetings&amp;rdquo; to an &lt;a href="https://writingcooperative.com/the-anatomy-of-an-amazon-6-pager-fc79f31a41c9"&gt;extreme&lt;/a&gt;. Supposedly, they not only require a multi-page written document, but they also force everyone to read through it during the allocated meeting time. I&amp;rsquo;m not a huge fan of this kind of very rigid process, but I can see how this can work. In my experience, one-two pages of text already provide you with 80% of the value of having text in the first place. Going in with no preparation however is a sure way to waste everyone&amp;rsquo;s time.&lt;/p&gt;
&lt;h3 class="demoted"&gt;Preventing sabotage&lt;/h3&gt;
&lt;p&gt;All right, let&amp;rsquo;s get rolling. We got our agenda dialed in, the invite has all the information everyone needs, and it&amp;rsquo;s showtime! While good preparation is a prerequisite, a meeting can still derail if you don&amp;rsquo;t notice bad patterns. Did you encounter any of the following behaviors in a meeting:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Someone is bringing up anecdotes.&lt;/li&gt;
&lt;li&gt;More than five people trying to make a decision?&lt;/li&gt;
&lt;li&gt;Are you revisiting recently made decisions?&lt;/li&gt;
&lt;li&gt;People advice for caution and don&amp;rsquo;t want to make decisions?&lt;/li&gt;
&lt;li&gt;Decisions get delegated into &amp;ldquo;working groups&amp;rdquo;?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If so, congratulations, there&amp;rsquo;s a good chance you have someone who read the &amp;ldquo;&lt;a href="https://en.wikisource.org/wiki/Simple_Sabotage_Field_Manual"&gt;Simple Sabotage Field Manual&lt;/a&gt;&amp;rdquo;, as all the techniques above (and a few more) have been found highly effective at sabotaging meetings. Call those behaviors out when you see them, even if you&amp;rsquo;re sure that you have no spies working for the competition in a call.&lt;/p&gt;
&lt;p&gt;Seriously though, being aware of anti-patterns is as least as important as having a good meeting setup. Once you are aware of them, it&amp;rsquo;s easy to avoid them: For example, revisiting should not happen a lot because meetings have notes about actions taken and a rationale, and unless new information has been gathered which clearly shows the decision was made based on flawed data (this occurs very rarely in practice!) there&amp;rsquo;s no point in rehashing things.&lt;/p&gt;
&lt;p&gt;There are of course more indicators of a meeting going wrong, but the majority of them can be spotted if you remind yourself of the guidelines above. Lots of watchers in the dark silently enduring the meeting? Chances are, you invited the wrong group, or your meeting notes are so bad people want to experience things first hand. Endless discussions on minute details of the plan? The information that was shared up-front was probably no good. In general, a meeting should be approached with a clear goal, and if you do want a specific outcome, you&amp;rsquo;re going to sidestep most of the problems mentioned.&lt;/p&gt;
&lt;h3 class="demoted"&gt;Closing remarks&lt;/h3&gt;
&lt;p&gt;I hope with this post you got some new ideas how to improve the meetings you&amp;rsquo;re calling or you&amp;rsquo;re in. There&amp;rsquo;s one last remark I&amp;rsquo;d like to make here: Don&amp;rsquo;t be afraid to call out the cost and &lt;strong&gt;cancel meetings which will not result in immediate action&lt;/strong&gt;. Besides all the cost to the business, there&amp;rsquo;s another much more valuable currency you have to pay with: Your lifetime, as &lt;strong&gt;none of us lives long enough that we can afford spending time in pointless meetings&lt;/strong&gt;.&lt;/p&gt;</description></item><item><title>Advent 2021: Open source</title><link>https://anteru.net/blog/2021/advent-2021-open-source</link><pubDate>Fri, 24 Dec 2021 18:00:00 +0100</pubDate><guid>https://anteru.net/blog/2021/advent-2021-open-source</guid><description>&lt;p&gt;I didn&amp;rsquo;t want to end this series with a grand finale and reserving the &amp;ldquo;prime spot&amp;rdquo; for the best tool/language/framework, because frankly, all of them are solutions for different problems, and any kind of global ranking would be unfair. Instead, I want to use today&amp;rsquo;s prime spot to talk about a topic that is close to my heart: Open source software.&lt;/p&gt;
&lt;p&gt;All of those languages, frameworks and tools I talked about have something in common. They&amp;rsquo;re free and open source, or there is at least one free and open source implementation of them. C++ has for instance the &lt;a href="https://gcc.gnu.org/"&gt;GCC&lt;/a&gt; and &lt;a href="https://clang.llvm.org/"&gt;Clang&lt;/a&gt; compilers implementing the language. The open source world is where a lot of the innovation is happening these days. Sometimes the projects are backed by companies making money with them, but often times open source projects are ran by volunteers like you and me. People with a day job who sit down in their evenings and weekends to participate in the open source ecosystem.&lt;/p&gt;
&lt;p&gt;Those people deserve our thanks, our support, and our money. If you&amp;rsquo;re an individual or a business, and you&amp;rsquo;re depending on open source code for your job, take a moment to look up how to contribute and send some money to the maintainers (if you&amp;rsquo;re in a situation that allows you to donate &amp;ndash; which is hopefully the case if you&amp;rsquo;re reading my blog and working in IT, which I know most of you are!). Writing and maintaining software is a hard job that should be rewarded. Writing and maintaining open source software, where every person out there is a critic and you don&amp;rsquo;t get paid for by someone, is a &lt;em&gt;really hard job&lt;/em&gt;, and nobody can live from reputation alone.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s also really easy to help those projects. To help you get started, I&amp;rsquo;m providing the donation links to the projects I talked about that accept donations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.blender.org/about/donations/"&gt;Blender&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/catchorg/Catch2"&gt;Catch2&lt;/a&gt; &amp;ndash; via GitHub sponsoring&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.djangoproject.com/foundation/donate/"&gt;Django&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.fsf.org/about/ways-to-donate/"&gt;FSF &amp;ndash; GCC and other projects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.linuxfoundation.org/donate/"&gt;Linux Foundation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://numfocus.org/eoy2021"&gt;Matplotlib, Numpy and Pandas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://openzfs.org/wiki/Main_Page"&gt;OpenZFS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://palletsprojects.com/blog/donate/"&gt;Pallets Projects &amp;ndash; Flask and others&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.python.org/psf/donations/"&gt;Python Software Foundation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://give.thunderbird.net/"&gt;Thunderbird&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are of course tons of other open source projects which need your help. Do take a look at what you&amp;rsquo;re using, and see if there&amp;rsquo;s a way to contribute back to it.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve built a world of software on the shoulders of free labour, volunteers, and idealistic people. If we want to ensure that there will be free software for years to come, we must start appreciating the value. Putting some money behind it is the first step towards a better future, in which people can live writing open source software for the greater good of all the programmers in the world!&lt;/p&gt;</description></item><item><title>Advent 2021: Blender</title><link>https://anteru.net/blog/2021/advent-2021-blender</link><pubDate>Thu, 23 Dec 2021 18:00:00 +0100</pubDate><guid>https://anteru.net/blog/2021/advent-2021-blender</guid><description>&lt;p&gt;I&amp;rsquo;ve never been a good 3D artist, but I&amp;rsquo;ve been always interested in 3D content creation. I&amp;rsquo;ve used quite a few 3D packages over the years, but these days, there&amp;rsquo;s only one I&amp;rsquo;m using: &lt;a href="https://www.blender.org/"&gt;Blender&lt;/a&gt;. I&amp;rsquo;ve known about it from back in the day when the source code was bought off NaN for &#8364; 100.000, but I didn&amp;rsquo;t warm up to it until much later. During my years at the university I used it to process some 3D meshes and eventually ended up organizing a lecture on 3D modelling with Blender (to be clear: I was just organizing the lecture, a proper 3D artist was taking care of the Blender side.) That made me sit down and seriously learn Blender, which resulted (among other things) in me recreating the &lt;a href="https://sh13.net/about/header-image/"&gt;Shelter13.net header image&lt;/a&gt;. That was around 2012 with an updated version in 2014.&lt;/p&gt;
&lt;p&gt;This year, we arrived at &lt;a href="https://www.blender.org/download/releases/3-0/"&gt;Blender 3.0&lt;/a&gt;, and it&amp;rsquo;s been an incredible development. What started as a humble 3D tool with a very own and opinionated way to do things has become a fully-featured 3D package, with a state of the art rendering engine, compositing tools, and modern scene management tools. Back in the day when I started using Blender building bigger scenes was quite tricky, but now Blender ships with all the tools you need to assemble complex scenes from parts. That&amp;rsquo;s also what I like about Blender the most: It&amp;rsquo;s easy to use for simple tasks, but it can handle demanding workloads, and having all in one package is fantastic.&lt;/p&gt;
&lt;p&gt;The most exciting recent development for me personally are the &amp;ldquo;geometry nodes&amp;rdquo;. There&amp;rsquo;s a fun story here with the Shelter 13 model, where the railing on the roof is instantiated along a curve. That was one thing that was always tricky to do in Blender, especially when you compared it to other 3D packages which shipped with a &amp;ldquo;instance along curve&amp;rdquo; feature for years (decades even&amp;hellip;) However, with Blender 3.0, this is not only fully supported, but also in a fantastic framework that allows you to do all sorts of complex, rule based instancing (including &lt;a href="https://docs.blender.org/manual/en/3.0/modeling/geometry_nodes/curve/index.html"&gt;instancing along curves&lt;/a&gt;!)&lt;/p&gt;
&lt;!-- figure-plugin --&gt;
&lt;figure&gt;
&lt;a href="/images/2021/sh13-geo-nodes.jpg"&gt;
&lt;picture&gt;
    &lt;source srcset="/images/2021/sh13-geo-nodes.blog-1x.webp 1x, /images/2021/sh13-geo-nodes.blog-2x.webp 2x" type="image/webp"&gt;
    &lt;img src="/images/2021/sh13-geo-nodes.blog-1x.jpg" alt="Several nodes are connected in a network to produce geometry"&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;figcaption&gt;Geometry node network used to construct the vertical bars on the roof&lt;/figcaption&gt;

&lt;/figure&gt;
&lt;!-- /figure-plugin --&gt;

&lt;p&gt;I took the opportunity to update the whole scene to Blender 3.0 and update and re-render it. It&amp;rsquo;s great to see that I can do so much faster now and at higher quality due to the Cycles X render engine, which is an incredible improvement over cycles from a few years back.&lt;/p&gt;
&lt;!-- figure-plugin --&gt;
&lt;figure class="noshadow"&gt;
&lt;a href="/images/2021/sh13-ao.jpg"&gt;
&lt;picture&gt;
    &lt;source srcset="/images/2021/sh13-ao.blog-1x.webp 1x, /images/2021/sh13-ao.blog-2x.webp 2x" type="image/webp"&gt;
    &lt;img src="/images/2021/sh13-ao.blog-1x.jpg" alt="The Shelter 13 building rendered ith ambient occlusion, showing it in false colors to illustrate the geometry."&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;figcaption&gt;Shelter 13 mesh rendered with an override material&lt;/figcaption&gt;

&lt;/figure&gt;
&lt;!-- /figure-plugin --&gt;

&lt;p&gt;Blender is also getting traction for &amp;ldquo;serious work&amp;rdquo;, and given with the sustainable business model, I&amp;rsquo;m optimistic we&amp;rsquo;ll see Blender thrive and grow in the coming years. If you haven&amp;rsquo;t used it before, now is the time, because this is really as good as it gets for 3D content creation, and it&amp;rsquo;s all open source and free!&lt;/p&gt;</description></item><item><title>Advent 2021: Visual Studio Code</title><link>https://anteru.net/blog/2021/advent-2021-vscode</link><pubDate>Wed, 22 Dec 2021 18:00:00 +0100</pubDate><guid>https://anteru.net/blog/2021/advent-2021-vscode</guid><description>&lt;html&gt;&lt;body&gt;&lt;p&gt;Programming is editing text &#8211; source code or documentation doesn&#8217;t matter, one way or the other the majority of your day is spent in some form of text editor. I&#8217;m one of those people who likes to use a text editor in addition to the primary IDE. As a result, I&#8217;ve used &lt;em&gt;a lot&lt;/em&gt; of different text editors over the years. In the early days, I&#8217;ve started with editors like &#8220;&lt;a href="http://www.pnotepad.org/"&gt;Programmer&#8217;s Notepad 2&lt;/a&gt;&#8221; and &#8220;&lt;a href="https://notepad-plus-plus.org/"&gt;Notepad++&lt;/a&gt;&#8221;, which were nice due to quick startup and some advanced editing capabilities, but nothing ground-breaking. Not until Sublime Text showed up with the &#8220;multi-caret editor&#8221; feature which was &#8211; in my opinion &#8211; a game changer. Suddenly some tasks I would typically do in my IDE were actually faster to do in the &#8220;text editor&#8221;.&lt;/p&gt;
&lt;p&gt;I ended up being an early adopter (and licensee) of &lt;a href="https://www.sublimetext.com/"&gt;Sublime Text&lt;/a&gt; 2, but for various reasons, I moved on to &lt;a href="https://atom.io/"&gt;Atom&lt;/a&gt; when it showed up. The Atom editor was an editor fully built on a web-based shell, with the majority of the code originally written in CoffeeScript (a language which compiles to JavaScript). This resulted in an explosion of extensions because suddenly you could write them in a highly popular language.&lt;/p&gt;
&lt;p&gt;Shortly after Atom showed up, Visual Studio Code also appeared on the stage, with a core written in TypeScript. At first I wasn&#8217;t quite convinced of it (and early on, it was quite a bit &#8220;rougher&#8221; to use as Atom), but it quickly gained a lot of features and polishing. I&#8217;m still wondering if the success was down to picking the right technology, with TypeScript being a &#8220;better&#8221; language to scale a project than CoffeeScript.&lt;/p&gt;
&lt;p&gt;In any case, these days Visual Studio Code ended up my editor of choice. In fact, all of the blog posts in this series have been written in it, as has been the underlying web framework handling my blog. It&#8217;s grown into a &#8220;serious&#8221; editor with various programming languages supporting it as an IDE. For instance, my adventures in &lt;a href="/blog/2021/advent-2021-go"&gt;Go&lt;/a&gt; were all done in Visual Studio Code &#8211; no IDE needed to begin with. Similarly, I write all my &lt;a href="/blog/2021/advent-2021-python"&gt;Python&lt;/a&gt; code in Visual Studio Code.&lt;/p&gt;
&lt;p&gt;This new world of &#8220;web based&#8221; editors might take a while to get used to, because they were definitely nowhere near as snappy as editors used to be, but this has dramatically improved. Together with the incredible ecosystem, first-class support for many modern programming languages, and a constant influx of new features I think it&#8217;s fair to say that this new way of writing editors has proven its value and is here to stay. I think we ended up in a great place here with fantastic editors like Visual Studio Code being readily available and constantly gaining functionality &#8211; and I&#8217;m curious to see what the next big revolution in text editing will be!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</description></item><item><title>Advent 2021: Thunderbird</title><link>https://anteru.net/blog/2021/advent-2021-thunderbird</link><pubDate>Tue, 21 Dec 2021 18:00:00 +0100</pubDate><guid>https://anteru.net/blog/2021/advent-2021-thunderbird</guid><description>&lt;p&gt;While the battle between Chrome, Edge and Firefox is raging, there is another product which is in my opinion equally important for &amp;ldquo;the web&amp;rdquo; without much real competition &amp;ndash; &lt;a href="https://www.thunderbird.net/"&gt;Thunderbird&lt;/a&gt;! Sure, there are commercial email clients, but they&amp;rsquo;re doing other things as well, and when it comes to email only, there is really not that much out there. I think that&amp;rsquo;s mostly due to Thunderbird solving the problem well enough that nobody feels the need to write a (serious) competitor for it. Yes, there are a few more open source clients, but I think it&amp;rsquo;s fair to say that Thunderbird is the dominating open source solution, certainly when it comes to cross-platform clients.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve been using Thunderbird for as long as it&amp;rsquo;s been around, on both Windows and Linux. It&amp;rsquo;s becoming more and more of niche product these days as communication is moving towards instant messaging clients and web mail, but for me as an &amp;ldquo;old-school&amp;rdquo; email user it&amp;rsquo;s still the goto client for all my personal emails. It&amp;rsquo;s easy to use, works reliably with all email servers I ever dealt with, and since a few years, has both good search capabilities as well as an integrated calendar. It&amp;rsquo;s easy to overlook how good a product actually is if it &amp;ldquo;just works&amp;rdquo; in your day-to-day use.&lt;/p&gt;
&lt;p&gt;The Thunderbird project had a bit of a difficult past where it used to be a part of the Mozilla foundation, but subsequently was separated and is now &lt;a href="https://www.thunderbird.net/en-US/about/"&gt;an independent project&lt;/a&gt;. It also picked up speed since then compared to a few years of being in maintenance only mode and the &lt;a href="https://developer.thunderbird.net/planning/roadmap"&gt;roadmap&lt;/a&gt; is getting quite crowded by now. I&amp;rsquo;m glad it&amp;rsquo;s around &amp;ndash; it&amp;rsquo;s been a great piece of software which never failed me, and I&amp;rsquo;m hoping we&amp;rsquo;ll get many more years of Thunderbird to handle all our local email needs!&lt;/p&gt;</description></item></channel></rss>