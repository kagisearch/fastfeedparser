<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[MahdyTech]]></title><description><![CDATA[A starter blog demonstrating what Gatsby can do.]]></description><link>https://mahdytech.com</link><generator>GatsbyJS</generator><lastBuildDate>Sat, 17 Feb 2024 08:03:22 GMT</lastBuildDate><item><title><![CDATA[Livesite by a Thousand Spikes üìà]]></title><description><![CDATA[While my team was moving a service, let‚Äôs call it Billy, to a new cluster with different hardware, Billy‚Äôs performance degraded. Now my team‚Ä¶]]></description><link>https://mahdytech.com/livesite-thousands-spikes/</link><guid isPermaLink="false">https://mahdytech.com/livesite-thousands-spikes/</guid><pubDate>Tue, 30 Aug 2022 12:00:32 GMT</pubDate><content:encoded>&lt;p&gt;While my team was moving a service, let‚Äôs call it Billy, to a new cluster with different hardware, Billy‚Äôs performance degraded. Now my team knows I am into this kind of thing, so they asked me to take a look. I thought it‚Äôd be a matter of accommodating the number of threads to the new hardware, or something similarly straightforward, and said ‚Äúconsider it done‚Äù. In hindsight, way too much confidence üòÖ.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#first-things-first&quot;&gt;&lt;strong&gt;First things first&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#digging-deeper&quot;&gt;&lt;strong&gt;Digging Deeper&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#take-a-step-back-and-retry&quot;&gt;&lt;strong&gt;Take a step back, and retry&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#prepare-the-bait&quot;&gt;&lt;strong&gt;Prepare the bait&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#spikes-in-the-bait&quot;&gt;&lt;strong&gt;Spike‚Äôs in the bait&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;first-things-first&quot;&gt;&lt;strong&gt;First things first&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;My first move is to get a concrete idea of what kind of ‚Äúperf issues‚Äù we have here. With some luck, I can find my way to Billy‚Äôs monitoring graphs. My go-to graph is availability, which visualizes the equation:&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 13.513513513513512%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAB2HAAAdhwGP5fFlAAAAi0lEQVQI12VOSwrFIAzs/W/WdqEU66dQC9oi6gF0Y+eRrAovMEwyGSaZ1nXFtm1QSsFaC+cc5nmG1hpSSnjvGcdxsI80IQRyzgghcE/6vu+8m0i875tBJuLrupBS4hBjDDMdW5YF53myp5SCWiv3z/Mwxxgx4VPv+35H9N45iEBfErfWeDfG+PNT/QAA/9w5xsXPbwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;equation&quot;
        title=&quot;&quot;
        src=&quot;/static/7b5c061cfd953046b83d5ea60abcc19d/fcda8/equation.png&quot;
        srcset=&quot;/static/7b5c061cfd953046b83d5ea60abcc19d/12f09/equation.png 148w,
/static/7b5c061cfd953046b83d5ea60abcc19d/e4a3f/equation.png 295w,
/static/7b5c061cfd953046b83d5ea60abcc19d/fcda8/equation.png 590w,
/static/7b5c061cfd953046b83d5ea60abcc19d/efc66/equation.png 885w,
/static/7b5c061cfd953046b83d5ea60abcc19d/c83ae/equation.png 1180w,
/static/7b5c061cfd953046b83d5ea60abcc19d/42267/equation.png 2670w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;p&gt;There are availability &lt;a href=&quot;https://en.wikipedia.org/wiki/Service-level_agreement&quot;&gt;SLAs&lt;/a&gt; for all services, if availability dips below that SLA, we have got a problem. Billy‚Äôs availability graph was lower than the SLA, so we‚Äôve got a real problem here. There are many reasons for an availability drop ‚Äì as many as the reasons a query can fail. Good client monitoring is essential to triage why we have a low availability; it could be for example a client issue or a server issue, and if it is a server issue could be due to latency or maybe the server is too busy handling other requests. In Billy‚Äôs case, it was high server latency:&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 58.10810810810811%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAADLAAAAywAEoZFrbAAABj0lEQVQoz21Si3LjIAzM/39je51pcmn9SgFj3rAngXGdazWzA4hlJSRdcs6FDKUZr2CbpgnzPFcsywIpJcZxrHtGSgmdf8YlhEDPv8U6rLVP8N7vewfrHCiRg0s5VVRB712xLiLEROdciQwKgrPlmvnJV4XO3Ha+xBiw2Yjxyx1EtkC8xxrxd9xgKCBboiuxJdwnA6VDoxMk+YYH/YIeXZzz9eKxBswqIFHqSipcX14hqX6ehAcKJsWK2+sbvobPGmwUAUJofLzfMA/Eiy1bEqR6pIgSHYZRYLq+Q31ckb1FEXcUIxDkBHl7Q7Qbyjoi64XwgLj9gdeK0ox7PUnQU1Oy08hyoNzv9FdzfIWrExcSt+rJl8Qn0ro81fepy+VEph+3DvYu9rvuY5x8527vXfZ76xu5E/LJ18WPx78I9XMV5CFlxBiPNedUSe0uV3yff+PvTWFVbkwdXFq5BDzAShsYY6C1hrMGmxLV33190Hnlc5u40gT/N/Ys0mNdN2ybQbIaUU1Qq67BWagN9E/7B2BBrMGJodXQAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Billy&apos;s Latency&quot;
        title=&quot;&quot;
        src=&quot;/static/59039c4247ae3e82b6ff2770560fefe3/fcda8/BillyLatency.png&quot;
        srcset=&quot;/static/59039c4247ae3e82b6ff2770560fefe3/12f09/BillyLatency.png 148w,
/static/59039c4247ae3e82b6ff2770560fefe3/e4a3f/BillyLatency.png 295w,
/static/59039c4247ae3e82b6ff2770560fefe3/fcda8/BillyLatency.png 590w,
/static/59039c4247ae3e82b6ff2770560fefe3/efc66/BillyLatency.png 885w,
/static/59039c4247ae3e82b6ff2770560fefe3/c83ae/BillyLatency.png 1180w,
/static/59039c4247ae3e82b6ff2770560fefe3/e53e8/BillyLatency.png 1982w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;center&gt;&lt;I&gt;Billy&apos;s latency on the cluster with the new hardware compared to the old cluster&lt;/I&gt;&lt;/center&gt;
&lt;br/&gt;
I started by preparing a simple change that updated some configs (e.g. number of threads used, maximum number of requests processed at a time, etc) and hoped that would do the trick ‚Äì it didn&apos;t. Latency and availability stayed about the same.
&lt;h2 id=&quot;digging-deeper&quot;&gt;&lt;strong&gt;Digging Deeper&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;In my experience, a latency regression is a sign of an introduced resource contention, 90% of the time it is heap contention during allocating or freeing memory. On Windows, this contention shows up clearly on an ETW capture. I used to use &lt;a href=&quot;https://mahdytech.com/2019/01/13/curious-case-999-latency-hike/&quot;&gt;XPerf&lt;/a&gt; for taking ETW captures, but now I find &lt;a href=&quot;https://docs.microsoft.com/en-us/windows-hardware/test/wpt/wpr-how-to-topics&quot;&gt;WPR&lt;/a&gt; more convenient, I usually suffice with the CPU events using the command:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;Wpr -start cpu.verbose&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The ‚Äú.verbose‚Äù part is important as it means we‚Äôre getting callstacks as well ‚Äì hard to optimize code without knowing which line is causing the issue. I took a very brief 5 second capture (CPU.Verbose captures can quickly grow huge, especially on servers with 100+ cores), I then open the captured etl file with &lt;a href=&quot;https://docs.microsoft.com/en-us/windows-hardware/test/wpt/windows-performance-analyzer&quot;&gt;WPA&lt;/a&gt; on my devbox, and directly jump to the &lt;code class=&quot;language-text&quot;&gt;CPU precise&lt;/code&gt; events:&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 16.89189189189189%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAIAAAAcOLh5AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAq0lEQVQI1yXIywqCQABAUf//J6LIsaCF5UZcCb4CJco0x3Qe6syoE4n6BSnB5SyukroP6D/ps6wR+tQ1p/wWoeTVZG8BcwEhS5J6cS1jmMqi7IpC5BmL71QxL8ezvvc92whJBDni343NQNCBaw+CFnhCdQVwuOYK1WGaz5Zz8PjWIjuLKLZxMnUQh944jF3boqqBjaRyxv1E+gnLici/M+7GUgx4nXNa9XGCfzI6lfs6QFZJAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;WPA&quot;
        title=&quot;&quot;
        src=&quot;/static/ce4c1d8560fa9eb30da2951cef6f0ecd/fcda8/wpa1.png&quot;
        srcset=&quot;/static/ce4c1d8560fa9eb30da2951cef6f0ecd/12f09/wpa1.png 148w,
/static/ce4c1d8560fa9eb30da2951cef6f0ecd/e4a3f/wpa1.png 295w,
/static/ce4c1d8560fa9eb30da2951cef6f0ecd/fcda8/wpa1.png 590w,
/static/ce4c1d8560fa9eb30da2951cef6f0ecd/efc66/wpa1.png 885w,
/static/ce4c1d8560fa9eb30da2951cef6f0ecd/c83ae/wpa1.png 1180w,
/static/ce4c1d8560fa9eb30da2951cef6f0ecd/48463/wpa1.png 2663w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;CPU Precise&lt;/code&gt; contains ‚Äúcontext switching‚Äù events. These are events emitted by the kernel when threads were stopped (‚Äúswitched out‚Äù), as well as when they were resumed (‚Äúswitched back in‚Äù). This view relates to latency issues because, well, CPUs are fast. For my (and most) workloads, delays don‚Äôt happen when CPUs are churning off work non-stop. Rather, latency delays usually happen because threads got stopped for some reason (blocks/waits or CPU starvation), and that‚Äôs exactly what the ‚ÄúCPU Precise‚Äù events tell us more about.&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 35.13513513513513%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB24FB/8QAFxAAAwEAAAAAAAAAAAAAAAAAAAESEf/aAAgBAQABBQKWYyWf/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFhABAQEAAAAAAAAAAAAAAAAAADIB/9oACAEBAAY/Aq1Wqf/EABoQAAICAwAAAAAAAAAAAAAAAAABETFhceH/2gAIAQEAAT8hfGRPUWkZB//aAAwDAQACAAMAAAAQA8//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAWEQADAAAAAAAAAAAAAAAAAAABECH/2gAIAQIBAT8QEX//xAAdEAABAwUBAAAAAAAAAAAAAAABABExIUGBkaHh/9oACAEBAAE/ECA0l/BPMJJxAArpC//Z&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;ContextSwitching&quot;
        title=&quot;&quot;
        src=&quot;/static/05caa8330154afa880c7af98fc28d350/1c72d/context_switch.jpg&quot;
        srcset=&quot;/static/05caa8330154afa880c7af98fc28d350/a80bd/context_switch.jpg 148w,
/static/05caa8330154afa880c7af98fc28d350/1c91a/context_switch.jpg 295w,
/static/05caa8330154afa880c7af98fc28d350/1c72d/context_switch.jpg 590w,
/static/05caa8330154afa880c7af98fc28d350/acb04/context_switch.jpg 750w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;center&gt;Anatomy of a context switch event. Source: &lt;a href=&quot;https://docs.microsoft.com/en-us/windows-hardware/test/wpt/cpu-analysis&quot;&gt;CPU Analysis | Microsoft Docs&lt;/a&gt;&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;Back to Billy‚Äôs profile, I drilled down to the callstack with the highest combo of the number of waits, average wait time, as well as CPU usage. I saw that there was a lock during freeing some object that was causing a lot of threads to wait:&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 28.37837837837838%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAAsTAAALEwEAmpwYAAABJUlEQVQY02XNuU7DMAAA0Pw/YuySUsTIjhhQKwq0QycO0TSx48SOE9+J7TilhxAF9n7A04uMMZ3t8jyHOXTehxCGYfC+ZzRTkmPitZAcQomxJMQ6xxrElDCUmgpHbdtaZyGESZIwzruu+8d9HxqaaiXKMhipBchUiRUhvg+8QVzLtqZdVUTaaOdcVVXr9RoAIIQ4m9X5rGnNChxJrVtra8aSTbpJM5Aj6711Pa0yITgqveSyyQAvMce4tb6uUaMEIw0CNDoO3c++/3JaUSSrPBj++707HbZBwYNXhg1HZ7YE7Xi1F/S0HwZTDl7tlGgbHo0XaLIs42d4ef9+cfcavxQ3q3q8wFePb+MnMJqSeJ5PHj4ms+RqlsQLPJ5/Xi/z0TS9XRV/iw46uTJVghwAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;WPA&quot;
        title=&quot;&quot;
        src=&quot;/static/eef5b2b268366cc0350259313a9ddd59/fcda8/wpa2.png&quot;
        srcset=&quot;/static/eef5b2b268366cc0350259313a9ddd59/12f09/wpa2.png 148w,
/static/eef5b2b268366cc0350259313a9ddd59/e4a3f/wpa2.png 295w,
/static/eef5b2b268366cc0350259313a9ddd59/fcda8/wpa2.png 590w,
/static/eef5b2b268366cc0350259313a9ddd59/efc66/wpa2.png 885w,
/static/eef5b2b268366cc0350259313a9ddd59/c83ae/wpa2.png 1180w,
/static/eef5b2b268366cc0350259313a9ddd59/3707e/wpa2.png 1878w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;p&gt;It looked promising so I went ahead and changed the allocator used to one that does not free its memory (albeit uses more CPU, but CPU starvation was not an issue here). I deployed my change, and tested again, and, latency was not affected ü§∑‚Äç‚ôÇÔ∏è (In hindsight the average wait in the above graph should have been  enough to hint to me that this is not it)&lt;/p&gt;
&lt;h2 id=&quot;take-a-step-back-and-retry&quot;&gt;&lt;strong&gt;Take a step back, and retry&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;My first thought was to go back to the capture and find another locking callstack to fix. But that felt don-quixote-esque. Maybe I missed something?&lt;/p&gt;
&lt;p&gt;I had an idea - what if one machine was causing the latency issue? I went ahead and took a look at the per-machine graphs, instead of the ones earlier that are averaged across many machines:&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 58.10810810810811%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAADLAAAAywAEoZFrbAAABsElEQVQoz21Ta3PjIAz0//+D9+luOk2vqcEx5mVjDGwlkWTch2ZkQIhltcjDcRyNDPyplUfAWgutNZRSmOdZRkMjx3nOexy/n/viw7quKKW0c3Dfd2zbJp5Seo7f478C0gYxq8KQA6VU/GrtZ/wBcj/fAUMIoLIl4aIitEmcKsCcKE4y5P9/UHOieXvGH9U8yucYM+SSBfB1jLjZXQD7jVU0rUfGMf5FXR3tMNkOyMbnjTHPC0TDWgvSXjC7HcqctOEkOsRAZflAjYtc0E4lsp4xRmHKNvRJg4tZ3IaMLZXOsnaGxWliuQvo+QGYFYPlnAVYAGPsDCcq9SDd/Mqg/ZJyZ1LMVXQsbiIdt87y1A28DsE/X1k0HGe6oR3Y8wG1dEC2unkUf+vzaFCo7NqFJP025MTnGryP8rgDg21pxzRR445v8LOCurzA3RSW9xfo13+YqJH17KGVhrleZL3cNMaPEZbWhtbXKRDbhKH33oFE1Fdp2gRPf4R3DnZZsAYnbhaLuG4I3sE52qd2Y18pxmPrOnTAs3E5rKckE3hLAdlOCCQ+l8i6ee/B/ftot7N9Ap8XqWaa4zdDAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Per Machine Latency&quot;
        title=&quot;&quot;
        src=&quot;/static/59f306f4d44d2a830e38a0641c1f8e4b/fcda8/per_machine_latency.png&quot;
        srcset=&quot;/static/59f306f4d44d2a830e38a0641c1f8e4b/12f09/per_machine_latency.png 148w,
/static/59f306f4d44d2a830e38a0641c1f8e4b/e4a3f/per_machine_latency.png 295w,
/static/59f306f4d44d2a830e38a0641c1f8e4b/fcda8/per_machine_latency.png 590w,
/static/59f306f4d44d2a830e38a0641c1f8e4b/efc66/per_machine_latency.png 885w,
/static/59f306f4d44d2a830e38a0641c1f8e4b/c83ae/per_machine_latency.png 1180w,
/static/59f306f4d44d2a830e38a0641c1f8e4b/e53e8/per_machine_latency.png 1982w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;p&gt;It was not just one machine causing latency increase, it was &lt;em&gt;all&lt;/em&gt; the machines! As the graph shows, each machine &lt;em&gt;usually&lt;/em&gt; has normal latency, except once every 15-20 min it would have a crazy high spike, and come down immediately. Now that‚Äôs a different beast from what I was expecting.&lt;/p&gt;
&lt;p&gt;The ETW profile I discussed above only lasted for 5 seconds! I had an infinitesimal chance of catching what caused the spike! It might sound weird why I took such a short capture, but I usually test under more than 1-2k QPS, so in those 5 seconds I have maybe 5k or 10k requests, which is usually a good enough sample. Also, I like keeping profiles as small as possible, as that 5 second ETW profile can already inch close to 500 MBs in size.&lt;/p&gt;
&lt;p&gt;When the problem happens once every 15 minutes, taking a 5 second profile is not going to work. I had to take a different approach.&lt;/p&gt;
&lt;h2 id=&quot;prepare-the-bait&quot;&gt;&lt;strong&gt;Prepare the bait&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The first thing I needed to do is to make sure my captures are ‚Äúcircular‚Äù, meaning that it would not matter how long my capture is, it would have an upper limit on file size, as newer parts overwrite older ones. Luckily, &lt;a href=&quot;https://docs.microsoft.com/en-us/windows-hardware/test/wpt/authoring-recording-profiles&quot;&gt;Wprp profiles&lt;/a&gt; already offer this capability, as you can specify a limit on how many buffers are used &amp;#x26; their size, and when buffers are full the oldest events just get overwritten.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;xml&quot;&gt;&lt;pre class=&quot;language-xml&quot;&gt;&lt;code class=&quot;language-xml&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;SystemCollector&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;Id&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation attr-equals&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;WPR&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token attr-name&quot;&gt;Name&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation attr-equals&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt; WPR&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;
  &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;BufferSize&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;Value&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation attr-equals&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;1024&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;/&gt;&lt;/span&gt;&lt;/span&gt; 
  &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;Buffers&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;Value&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation attr-equals&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;3072&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;/&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;/&lt;/span&gt;SystemCollector&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;center&gt;Adding a limit of about 3 GB (3072 * 1024 kilobytes). Full wprp is &lt;a href=https://github.com/aybassiouny/mahdytech/tree/master/content/blog/livesite-thousands-spikes/cpu.wprp&quot;&gt;here&lt;/a&gt;&lt;/center&gt;
&lt;br/&gt;
&lt;p&gt;The second part was to automate stopping the capture when there‚Äôs a spike. As the spikes happen every 10-15 minutes, and I can only take a maximum of ~1-1.5 minutes captures (otherwise they are too big), it became important to stop the capture right around the time a spike happens. I had my script query Billy‚Äôs latency every 30 seconds, and whenever latency was extremely high (over 500ms!) it would stop the capture. After some (longer than it should) struggle with PowerShell, the final capture script looked something like:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;powershell&quot;&gt;&lt;pre class=&quot;language-powershell&quot;&gt;&lt;code class=&quot;language-powershell&quot;&gt;Wpr &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;start&lt;/span&gt; CPU&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;wprp &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;start&lt;/span&gt; MyCustomEvents&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;wprp
&lt;span class=&quot;token keyword&quot;&gt;While&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;true&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;token variable&quot;&gt;$latency&lt;/span&gt; = queryLatency&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;If&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token variable&quot;&gt;$latency&lt;/span&gt; &gt; 500ms&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;token keyword&quot;&gt;break&lt;/span&gt;
    &lt;span class=&quot;token function&quot;&gt;sleep&lt;/span&gt; 30s
Wpr &lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;stop big_capture_&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;etl&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I then started my capture on several servers to maximize my chances, and started waiting for my bait to catch.&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 512px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEsElEQVQ4y1XMa0xaZxjA8fNp67J0yda5LGmWLFmb1H7Yupp1FRVFQOVIoRwpF7WIgigWUThcDogIDLAI5XaQS7HTUsQuWktrXXW1Koja26ZUEVq77sPare3SLL2sybKljHbJkiW/PHny5P++AMfEI/NrWEh9y7HWRgOv2Sqs7+HVqbn8PmGDgUsRqQkcQbPMKO12SbrttA6rXGM2Wxxyg41xRACYNgzi8zJesLU70WVI6jsuyGpdfPmMwpQ2qhdlkHP0gN76Q+r7x7//8ez5c8doYnJ2+enTJ0+evhi7dBYwpfSdkwjZVk73kDSxHumErFpcJ5lAzGmjeFxUY3PWaE23NpOPHj66f/+eY3B8Jr7464Nffrxz9/SFCKC/rmN5WbVTmJqTWNVslz7Z2xKSKueU5oxO+E17EasSJywROSRjU8uzC1dHzi25Q5Nzi1fjC5vSARWgifdQ3XjOFI4xgqM56umcsiZrnTKhVcW6kctqHtpO6z0Aqng9kefdoZQt+jMcuG4ZnD8z/YDjFAJ19saStsIvOwowR/YcFoAhKzLiNRzUQsXCYq6/iTvEp/upNScojai3d+JBz9nf5MM/6Ubvav1X6u0CgB/pbIkqSM1g7MP9j7eVLchhtpqFExeS9CA3LKjQEko69hHbK5v6+NpgTD+04rG6FL7EV6fvMS0CoC2ihAKtUwVV2a3l2W3E1Bt7wS7ocBSud0gk55yiKFKLCptPwKJBtS4Y95+ajfkQi+eMbTJb65YAxJNETgPmxVslL/LK/3q3fOmdz1vVdOSEFGykHjAq6od5kJ8NuRk0lNFqkXQZdeesWrVWIbSM0kwCgLZK6mfgXm4pfZaH+/PtMiNYNBp1jzt0LEMxcbCYcooAncUfmsQzpwnUKLXCd5EbvEHyzxD6qyhhHADGSeP7sdk3sX+/j7+9HUMdwpn78i9ats7btwp7dpV7SivMpURTKSlYRLAfhMYe0peyjJksNTzGnqsE6IsEGZtw5QPSyy0YV2EF9jx5LpyXvQRkvwMsw/nUWDV7roIZrm5R8HGd0s9EwVLvSuXXm5TQNfp5MtBwtZzgZB4Uh4Q1KmaTDh+lDIU/yk4Dufem0C5qAmRfJlYri+iMMi9q6ToWgANjteGbpAEfe5oEQJNY0FTdoIywNZFDnX1kR5Wkr2Delzdhe49r3ksZJJJRfGXdF21H6EOBo/On/YlhH2o0H3JBzAQIyIfZTeY6Ms8DNjrKoLYON8u+rOhdRoxxuf2a0rUkcyzJVBG+VCOymgwOp1WkERJAbLuziReBgONpxHRRzDfxGQpIMsDpnRb51xS+lMKfknnXZZ41OJBBbDG4oOrTKlpJJRm3fUfezj0fd480H19DADQp8a6/SgMbilzXvy73rMI56KoMTcrcq1L3Kuy+AZunWu1xydFvxRIfW4QyrQti9CYMeG5K3SuwayU3O10r8OtaiuYkpe4k7Em++gJNwt4NuWdN7kkpgptI8A7iWZe7VhAgcBvxZhT+jNKXk1b5Mmp/RpVb/Bkkx5dGfLdeHb0ZxJtG+nM2lN6UMtd40xpgd9GO3Zh/7fxP/v/3/MLXE7MjJ9fv2v8JlorB0/H/AFNSU/NuAZlIAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Fishing&quot;
        title=&quot;&quot;
        src=&quot;/static/6b8f8bf3a31806da906fcf91dc91aee4/01e7c/fishing.png&quot;
        srcset=&quot;/static/6b8f8bf3a31806da906fcf91dc91aee4/12f09/fishing.png 148w,
/static/6b8f8bf3a31806da906fcf91dc91aee4/e4a3f/fishing.png 295w,
/static/6b8f8bf3a31806da906fcf91dc91aee4/01e7c/fishing.png 512w&quot;
        sizes=&quot;(max-width: 512px) 100vw, 512px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;center&gt;What &lt;a href=&quot;https://huggingface.co/&quot;&gt;HuggingFace&apos;s&lt;/a&gt; AI thinks &quot;programmer fishing&quot; looks like&lt;/center&gt;
&lt;br/&gt;
After a couple of failed tries (I hate PowerShell) I finally had my capture. I opened it and verified - my capture stopped at the exact minute a latency spike had happened. I was excited! Inside this capture, I had the CPU events that covered the latency spike!
&lt;h2 id=&quot;spikes-in-the-bait&quot;&gt;&lt;strong&gt;Spike‚Äôs in the bait&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Using the ‚ÄúMyCustomEvents.wprp‚Äù profile above, I was also capturing events that show me latency for each request. This was very helpful, I could immediately jump to requests with the latency spike. In my capture, I found 10 requests with crazy high latencies (over 1 second) while the rest had an average of just over 5 ms. They looked promising:&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 47.972972972972975%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsTAAALEwEAmpwYAAACB0lEQVQozz2MS08TURiGDwsT48ql/8WIJi5cNGJiRFpTiVwagwFJRMpGoY0LfwJFg/QCvbfWRReoG1MaSCtYnTOXM0PrTKdlptOZXulMYeWZtjF58uZ9vvPmgOwRIYqyXNfUZgej4Wy0G+2u1u7W1KYo1flK/UxuieXGILUyr/JFhedqQkkB/v1DWZa6neblhXHR1zGjYuh947zbbPXUxvmZqnFST9YaRUmhKtIvoXosaEgCvNZudzuqovR13dB7Bs5eTx9w2TdkuUUi5c9vKZ8VCAInf/CVPdhnf6RRLvMXiBVJqNZKonTKV1GpzBQFjq/gS7Es4afvBfFduvw+TblTjPsL506xrhTaSLFvE/R6kgaTO4XHPmjbpax+OOUnJn3ElB/aAqQ1gBXa9+BchHWmMsuxwmKceh6j56PkUpJaSuA7CcbW8mB1gDMP1gb5X535MWcOvPp5w/Xt2kbuypsTsJoDK7nrrpOr68fgdR5MeKkJL415gPHRwz5SE8qyg2ZD2ekgYQ3QD/0M3tv26Ce75gbYg7Q9hDBPMWE07CM1YWxBbjlxuBCD8xFmJsLaQ4wjxjiiDN6AW5vEuAdibnvgnS047KZuDfAQNzepR97M/e3CvY/w7gdy3ENYPpGWbfMVPAub/2FmMVF22EdqgqbDpyufj14m4EIcOeLcTAS9SKDFJMKbf5INoTI9oTA5AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;WPA&quot;
        title=&quot;&quot;
        src=&quot;/static/185807125e394b2852bbf4dc84b9e48c/fcda8/wpa3.png&quot;
        srcset=&quot;/static/185807125e394b2852bbf4dc84b9e48c/12f09/wpa3.png 148w,
/static/185807125e394b2852bbf4dc84b9e48c/e4a3f/wpa3.png 295w,
/static/185807125e394b2852bbf4dc84b9e48c/fcda8/wpa3.png 590w,
/static/185807125e394b2852bbf4dc84b9e48c/efc66/wpa3.png 885w,
/static/185807125e394b2852bbf4dc84b9e48c/c83ae/wpa3.png 1180w,
/static/185807125e394b2852bbf4dc84b9e48c/719d0/wpa3.png 1779w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;p&gt;Each row is a different event representing a request. You can see how latencies starting the second half are  getting very high. I picked one row (request), and zoomed in.&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 20.945945945945947%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAIAAAABPYjBAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAvklEQVQI1z2KXQuCMBiF/f+/JQtDIuiyCzEz66bAr5a6ys3tfefX7K4JETzn8MA5VnjNgmNCKCdPXtVAGRYvUTF8ia6sIaf8Tjnl6tm0fyrWUgblW1pu9NhGV4USET/TpPVoYlqPf4af6B8tdkM/mJulh/6jtULkjCkJIARIiQAGI7PP3YCQcp7mldeNaESrlLW7kIWfuufSjYpVkNl+Yh9S4+sTWYdkFeTGN8eL7cVLP3FC4oR3J0gXXry/VV9ZqdXuRamenAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;WPA&quot;
        title=&quot;&quot;
        src=&quot;/static/2650afbefc5a00b3a9463de2fcbbf35f/fcda8/wpa4.png&quot;
        srcset=&quot;/static/2650afbefc5a00b3a9463de2fcbbf35f/12f09/wpa4.png 148w,
/static/2650afbefc5a00b3a9463de2fcbbf35f/e4a3f/wpa4.png 295w,
/static/2650afbefc5a00b3a9463de2fcbbf35f/fcda8/wpa4.png 590w,
/static/2650afbefc5a00b3a9463de2fcbbf35f/efc66/wpa4.png 885w,
/static/2650afbefc5a00b3a9463de2fcbbf35f/c83ae/wpa4.png 1180w,
/static/2650afbefc5a00b3a9463de2fcbbf35f/bcec6/wpa4.png 1834w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;p&gt;I then picked the thread id for that request, &lt;code class=&quot;language-text&quot;&gt;21560&lt;/code&gt;, and searched the thread number in the ‚ÄúCPU Precise‚Äù event tab. I was looking for what happened right before that thread emitted this event.&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 32.43243243243243%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABTElEQVQY002P2W7TUBRF/f//An0oNFEFSAhRKkGdNE3sNPE83CG+du26SXhbnFoF8bB09j7jvV6xClHrPU1VMljLcDjwLBzbdoq9MQxC/8aktWaU2otznKTPloa2tnSVwnt/E3PzUOLahmEcOZ7PvJxOjMfjP17939yk/+s5/z4T64FDM/DcDXi5bFbG0colLZe1vOCVpmkEN0UjviwLsjRFKYWqa7TSojUHo/B3JUleY2qN56wkdU2RpVit6FtH5+TbTx1jLww9jc4w1Q5nS9EF5nGLU9XU2+icqnyktQYli70rP+HiR8i7bysuf+65Xtd8CQ2fAj3xObTMlxFXvwJmi5iZHzH7vmF+FzO/L8Xv+XgXMF/kfPga4T1EBX4Yc7vcsNgmRLojNk9vdCR2IEgzVrstmyRnE2es77cEMhfmVnzKUmpBolj6OX8AGQC2GX4i2tkAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;WPA&quot;
        title=&quot;&quot;
        src=&quot;/static/dd410a94ffa20ced1b2d5c24a0126e6e/fcda8/wpa5.png&quot;
        srcset=&quot;/static/dd410a94ffa20ced1b2d5c24a0126e6e/12f09/wpa5.png 148w,
/static/dd410a94ffa20ced1b2d5c24a0126e6e/e4a3f/wpa5.png 295w,
/static/dd410a94ffa20ced1b2d5c24a0126e6e/fcda8/wpa5.png 590w,
/static/dd410a94ffa20ced1b2d5c24a0126e6e/efc66/wpa5.png 885w,
/static/dd410a94ffa20ced1b2d5c24a0126e6e/c83ae/wpa5.png 1180w,
/static/dd410a94ffa20ced1b2d5c24a0126e6e/a1a4b/wpa5.png 2054w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;p&gt;I could not believe my eyes! This thread had a 1 second wait around the same time my event was emitted, almost exactly matching the latency of this request! I looked at the callstack and saw the &lt;a href=&quot;https://en.cppreference.com/w/cpp/thread/sleep_for&quot;&gt;dreadful call&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;std::this_thread::sleep_for()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Very&lt;/strong&gt; interesting! Some function on our hotpath is waiting for 1 second, contributing to the lion‚Äôs share of this request‚Äôs latency. Can this be it?&lt;/p&gt;
&lt;p&gt;I zoomed out, and here it was! All the requests with 1 second wait coincide with a call to the 1-second sleep function call:&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 31.756756756756754%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAAsTAAALEwEAmpwYAAABKElEQVQY0zWPyXKCQBRF+f/PMYMoJE4BLReQCNgMSjMJTU+EZhArm2CZvDp169zFXTypJIyyqqmaoRZD09y69ir+sq/rvv7ueD2I5lqJn1vf4Kqv6qFtWi4wYZKoOC7ph0M0QLce032uHYnus3v1ue7x9QFrLtvYZA+/lwba2PeqOxSVWEoBCG2w2PqzDRhRNE99oHujT1e2vLZna2e6sOTFKMe7r+zJ0kr8kzQx4iczfrOS1z143jnvVjSiHqBsQvkzVgxnbrrzr5OyB+rOUcxQOUSqYb0YZ+ucS5wzNn7NOYQRcF2Ecdt2D5q2y9Igv0BUXvIwzIMTLhChJI6OlyKvMJYwISOU0TRNgyBIs0z8Xy1EMS6LBOO8TGIEIUGIUpKlfoEKTsgveFk4TDBuON4AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;WPA&quot;
        title=&quot;&quot;
        src=&quot;/static/fc67b5b77a09fe3d3b5525ca6e228270/fcda8/wpa6.png&quot;
        srcset=&quot;/static/fc67b5b77a09fe3d3b5525ca6e228270/12f09/wpa6.png 148w,
/static/fc67b5b77a09fe3d3b5525ca6e228270/e4a3f/wpa6.png 295w,
/static/fc67b5b77a09fe3d3b5525ca6e228270/fcda8/wpa6.png 590w,
/static/fc67b5b77a09fe3d3b5525ca6e228270/efc66/wpa6.png 885w,
/static/fc67b5b77a09fe3d3b5525ca6e228270/c83ae/wpa6.png 1180w,
/static/fc67b5b77a09fe3d3b5525ca6e228270/9c62f/wpa6.png 2162w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;p&gt;With a little digging, it turned out some library we‚Äôre consuming decides on rare occasions to sleep for 1 second, and for some reason, this happens more often on the new machines.&lt;/p&gt;
&lt;p&gt;Definitely one of my more interesting debugging stories :)&lt;/p&gt;
&lt;p&gt;Please feel free to drop a comment on &lt;a href=&quot;https://news.ycombinator.com/item?id=32718824&quot;&gt;hackernews&lt;/a&gt; or reach out on &lt;a href=&quot;https://twitter.com/aybassiouny&quot;&gt;Twitter&lt;/a&gt;.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Large-Pages in Windows: The What, the Why & the How]]></title><description><![CDATA[I stumbled across the concept of ‚ÄúLarge-Pages‚Äù several times, mainly through mentions in our codebase, but I never went much further than‚Ä¶]]></description><link>https://mahdytech.com/large-pages-how-when/</link><guid isPermaLink="false">https://mahdytech.com/large-pages-how-when/</guid><pubDate>Sun, 27 Dec 2020 12:00:32 GMT</pubDate><content:encoded>&lt;p&gt;I stumbled across the concept of ‚ÄúLarge-Pages‚Äù several times, mainly through mentions in our codebase, but I never went much further than exploring the Wikipedia page. I knew they can make memory lookups faster, but that‚Äôs about it. &lt;/p&gt;
&lt;p&gt;Recently, I had a service that was not doing any disk lookups, and bottlenecked on a bunch of memory accesses that were done for each request. I thought to myself; ‚ÄúEasy! I will use large pages and my service will run faster‚Äù. It didn‚Äôt. It hit me that I don‚Äôt know what Large Pages really are, and I needed deeper info - which I am going through in this post.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#the-what&quot;&gt;The What&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#the-why&quot;&gt;The Why&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#the-whynot&quot;&gt;The whynot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#bonus-huge-pages&quot;&gt;Bonus: Huge Pages&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#the-how&quot;&gt;The How&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-add-user-privilege-selockmemoryprivilege&quot;&gt;1. Add User Privilege &lt;code class=&quot;language-text&quot;&gt;SeLockMemoryPrivilege&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2-turn-on-selockmemoryprivilege-before-use&quot;&gt;2. Turn on &lt;code class=&quot;language-text&quot;&gt;SeLockMemoryPrivilege&lt;/code&gt; before use&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#3-use-it&quot;&gt;3. Use it&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#give-me-the-numbers&quot;&gt;Give me the numbers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#last-notes&quot;&gt;Last notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-what&quot;&gt;The What&lt;/h2&gt;
&lt;p&gt;To start things off, what is a page? According to &lt;a href=&quot;https://en.wikipedia.org/wiki/Page_(computer_memory)&quot;&gt;Wikipedia&lt;/a&gt;: &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[A page]  is the smallest unit of data for memory management in a virtual memory operating system.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A page is a chunk of contiguous memory, a big array. The kernel memory manager uses the page as its smallest unit to manage. For example, when we lookup a memory address, what decides if a &lt;a href=&quot;https://scoutapm.com/blog/understanding-page-faults-and-memory-swap-in-outs-when-should-you-worry&quot;&gt;hard fault&lt;/a&gt; is triggered or not, is whether the &lt;em&gt;page&lt;/em&gt; containing this address exists in the physical memory.&lt;/p&gt;
&lt;p&gt;A page is of a fixed size. In Windows, that‚Äôs usually about 4 KB. A &lt;code class=&quot;language-text&quot;&gt;Large-Page&lt;/code&gt; is, as the name suggests, of bigger size, usually 2 MB. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/282b091f5ab956c228cdac5f24f9fcb1/LargePage.svg&quot; alt=&quot;LargePage&quot; title=&quot;Large Pages&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;the-why&quot;&gt;The Why&lt;/h2&gt;
&lt;p&gt;So why is it better or faster? To understand that, we first need to look into how address translation happens. &lt;/p&gt;
&lt;p&gt;Assume our application has a pointer that holds &lt;code class=&quot;language-text&quot;&gt;0x00000085C92FFBE4&lt;/code&gt; and we try to dereference that location, the kernel needs translate this virtual address to a physical one in RAM (if possible). In order to do this there are two familiar ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do the work, which involves multiple lookups in Page Table. While this may sound trivial - it is significant, considering this is done for every memory retrieval&lt;/li&gt;
&lt;li&gt;Look it up from a cache - in this case the CPU‚Äôs &lt;a href=&quot;https://www.geeksforgeeks.org/whats-difference-between-cpu-cache-and-tlb/&quot;&gt;Translation Looksaside Buffer&lt;/a&gt; (TLB) cache, the far faster way&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Large Pages are much more cache friendly than normal sized pages. There are fewer of them, and take a fewer number of entries to cover much more address space. This leads to a much higher probability of having their entries available in TLB, and in turn, faster memory accesses.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/300abaad8735ba75d0efe1b090828da8/TLB.svg&quot; alt=&quot;TLB&quot; title=&quot;TLB&quot;&gt;
If TLB cache only had 5 entries, using Normal pages can only cover 5 pages (20 KB), while using Large Pages can cover up to 2560 pages (10 MB), giving a much higher probability for a cache hit on a given memory access.&lt;/p&gt;
&lt;h3 id=&quot;the-whynot&quot;&gt;The whynot&lt;/h3&gt;
&lt;p&gt;Large pages sound great - but why not have all allocations in large pages? They have pointy downsides: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Large pages are more prone to fragmentation, as they require contiguous free RAM, which might be hard to find after PC has been up for a while. &lt;/li&gt;
&lt;li&gt;Large pages are harder to allocate, as they have strict requirements for allowed page range. For example, a large page can occupy the page ranges 0-511, or 512-1024, etc, but cannot occupy the pages 1-513, even if they are free, limiting our options even further.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Allocations for large pages fail &lt;strong&gt;more often than normal allocations&lt;/strong&gt; - and code should be written to accommodate that; e.g. performance sensitive services that require large pages might prefer to fail the node completely if that one allocation fails, until node managers restarts the machine. &lt;/p&gt;
&lt;h3 id=&quot;bonus-huge-pages&quot;&gt;Bonus: Huge Pages&lt;/h3&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/167215b7fff0fe5537f3bfe6fd32c0cb/dfe3c/biggerFish.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.08108108108109%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAQBAgMF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAeRK903Eyv/EABkQAAIDAQAAAAAAAAAAAAAAAAABAhARIf/aAAgBAQABBQLiFNGiv//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/AUf/xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAgEBPwFX/8QAFxAAAwEAAAAAAAAAAAAAAAAAECAhMv/aAAgBAQAGPwKjSf/EABwQAAICAgMAAAAAAAAAAAAAAAABESEQQTFRkf/aAAgBAQABPyHa99JkG1EsSnkadLzH/9oADAMBAAIAAwAAABBHD//EABYRAQEBAAAAAAAAAAAAAAAAABEAIf/aAAgBAwEBPxAwjf/EABYRAQEBAAAAAAAAAAAAAAAAAAARYf/aAAgBAgEBPxDVv//EAB4QAQEAAgAHAAAAAAAAAAAAAAERACEQMUFRYcHh/9oACAEBAAE/EAgCO6fmAS6TldGJKPfhxtWOupcZ6Bw//9k=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Bigger Fish&quot;
        title=&quot;&quot;
        src=&quot;/static/167215b7fff0fe5537f3bfe6fd32c0cb/1c72d/biggerFish.jpg&quot;
        srcset=&quot;/static/167215b7fff0fe5537f3bfe6fd32c0cb/a80bd/biggerFish.jpg 148w,
/static/167215b7fff0fe5537f3bfe6fd32c0cb/1c91a/biggerFish.jpg 295w,
/static/167215b7fff0fe5537f3bfe6fd32c0cb/1c72d/biggerFish.jpg 590w,
/static/167215b7fff0fe5537f3bfe6fd32c0cb/dfe3c/biggerFish.jpg 625w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;It is possible to allocate even bigger pages - called Huge Pages, that are about 1GB. However, there is no special config for it on top of the usual Large Page config. The memory manager will automatically use a Huge Page, instead of a Lage Page, if allocation size is big enough, and pending memory availability with the same restrictions as &lt;a href=&quot;#the-whynot&quot;&gt;above&lt;/a&gt;. A bigger page size allows for even fewer TLB entries and an even more guaranteed cache hit.&lt;/p&gt;
&lt;h2 id=&quot;the-how&quot;&gt;The How&lt;/h2&gt;
&lt;p&gt;I didn‚Äôt find it straightforward to setup Large-Pages, especially on my Windows Home license (which should not be much of a production issue, I hope). Let‚Äôs go through the steps: &lt;/p&gt;
&lt;h3 id=&quot;1-add-user-privilege-selockmemoryprivilege&quot;&gt;1. Add User Privilege &lt;code class=&quot;language-text&quot;&gt;SeLockMemoryPrivilege&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Large-Pages &lt;a href=&quot;https://devblogs.microsoft.com/oldnewthing/20110128-00/?p=11643&quot;&gt;cannot be paged out&lt;/a&gt;! In other words, they always stay in RAM. Hence, the user allocating large pages needs to have the privilege &lt;a href=&quot;https://docs.microsoft.com/en-us/windows/security/threat-protection/security-policy-settings/lock-pages-in-memory&quot;&gt;SeLockMemoryPrivilege&lt;/a&gt; set. Note that even an admin account might not have that privilege. Good news is, this is a one-time thing that sticks across reboots. &lt;/p&gt;
&lt;p&gt;One way to give yourself that privilege is through Group Policy (for Home users like me, it needs to be &lt;a href=&quot;https://superuser.com/a/1229992&quot;&gt;turned on first&lt;/a&gt;), but it‚Äôs also doable through a mix of PowerShell/Win32 API:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Get your windows SID by running on PowerShell: &lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;powershell&quot;&gt;&lt;pre class=&quot;language-powershell&quot;&gt;&lt;code class=&quot;language-powershell&quot;&gt;&lt;span class=&quot;token variable&quot;&gt;$objUser&lt;/span&gt; = &lt;span class=&quot;token function&quot;&gt;New-Object&lt;/span&gt; System&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Security&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Principal&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;NTAccount&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;AHMED&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token variable&quot;&gt;$strSID&lt;/span&gt; = &lt;span class=&quot;token variable&quot;&gt;$objUser&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Translate&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token namespace&quot;&gt;[System.Security.Principal.SecurityIdentifier]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token variable&quot;&gt;$strSID&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;Value&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;Call &lt;code class=&quot;language-text&quot;&gt;ConvertStringSidToSidA&lt;/code&gt; to convert that to PSID that Win32 API recognizes&lt;/li&gt;
&lt;li&gt;Call &lt;code class=&quot;language-text&quot;&gt;AddPrivileges(sid, GetPolicyHandle());&lt;/code&gt;, where &lt;a href=&quot;https://docs.microsoft.com/en-us/windows/win32/secmgmt/opening-a-policy-object-handle&quot;&gt;GetPolicyHandle&lt;/a&gt; and &lt;a href=&quot;https://docs.microsoft.com/en-us/windows/win32/secmgmt/managing-account-permissions&quot;&gt;AddPrivileges&lt;/a&gt; functions are provided by the docs.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Check &lt;a href=&quot;https://github.com/aybassiouny/mahdytech/blob/master/content/blog/large-pages-how-when/Src/AddPrivilege/AddPrivilege.cpp&quot;&gt;AddPrivilege.cpp&lt;/a&gt; for an example.&lt;/p&gt;
&lt;h3 id=&quot;2-turn-on-selockmemoryprivilege-before-use&quot;&gt;2. Turn on &lt;code class=&quot;language-text&quot;&gt;SeLockMemoryPrivilege&lt;/code&gt; before use&lt;/h3&gt;
&lt;p&gt;While acquiring the privilege is a once-per-user action, every process that needs to allocate large pages need to turn on the privilege first, by calling &lt;code class=&quot;language-text&quot;&gt;AdjustTokenPrivileges&lt;/code&gt;. This needs to be done by an admin account, however the allocation itself does not require admin privileges. &lt;/p&gt;
&lt;p&gt;Check &lt;a href=&quot;https://github.com/aybassiouny/mahdytech/blob/master/content/blog/large-pages-how-when/Src/LargePageTest/LargePageTest/SetLargePagePrivilege.cpp&quot;&gt;SetLargePagePrivilege.cpp&lt;/a&gt; for an example.&lt;/p&gt;
&lt;h3 id=&quot;3-use-it&quot;&gt;3. Use it&lt;/h3&gt;
&lt;p&gt;A call to &lt;code class=&quot;language-text&quot;&gt;VirtualAlloc&lt;/code&gt; finally allocates the needed memory: &lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;token function&quot;&gt;VirtualAlloc&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token constant&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; buffersize&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; MEM_RESERVE &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; MEM_COMMIT &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; MEM_LARGE_PAGES&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; 
    PAGE_READWRITE&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that memory allocated will be &lt;a href=&quot;https://stackoverflow.com/questions/2440434/whats-the-difference-between-reserved-and-committed-memory&quot;&gt;committed&lt;/a&gt; as well, it is not possible to just reserve a &lt;a href=&quot;https://docs.microsoft.com/en-us/windows/win32/memory/large-page-support&quot;&gt;large-page allocation&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;One last note, after we allocate large pages, it‚Äôs not possible to see allocated memory in Task Manager‚Äôs ‚ÄúMemory/Working Set‚Äù, and is rather viewable from ‚ÄúCommit Size‚Äù tab: &lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/052be4f9ccabb53f006fae678712e7e0/82158/task_manager.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 11.486486486486488%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAABJ0AAASdAHeZh94AAAAi0lEQVQI1x2JWQqCUAAAvf+hQuwjMLXIytIo0/S5vFxwTYpJ/BiYYZRnJJBVSz/9aIaJbvwi8oKy6XklOVU7Unfj4nH2nntYfijSmYysqEnmfoQxiSxR1K2NZjloOxfjGuKmHdZNoDsB672Hfgnx0hbVOGMHJXf5wXRjvGxgc/Qx3IiDL1npJ0xP8AcN45JV4JIjqgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Task Manager&quot;
        title=&quot;&quot;
        src=&quot;/static/052be4f9ccabb53f006fae678712e7e0/fcda8/task_manager.png&quot;
        srcset=&quot;/static/052be4f9ccabb53f006fae678712e7e0/12f09/task_manager.png 148w,
/static/052be4f9ccabb53f006fae678712e7e0/e4a3f/task_manager.png 295w,
/static/052be4f9ccabb53f006fae678712e7e0/fcda8/task_manager.png 590w,
/static/052be4f9ccabb53f006fae678712e7e0/82158/task_manager.png 696w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;h2 id=&quot;give-me-the-numbers&quot;&gt;Give me the numbers&lt;/h2&gt;
&lt;p&gt;I ran a simple experiment to see if large pages are really worth the time. I tried to simulate a memory-bound piece of code that accesses a sizeable chunk of memory randomly.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;auto&lt;/span&gt; numAccesses &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token boolean&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;auto&lt;/span&gt; index &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;GetRandomIndex&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    largeBuffer&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;index&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;numAccesses&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I then measured how many accesses can be done per second, when allocating the large chunk normally, vs as a large page:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/a9ba5151cf99ce33fb098173c00515d6/LargePages.gif&quot; alt=&quot;LargePagesTest&quot;&gt;&lt;/p&gt;
&lt;p&gt;Left: Large-page enabled, right: disabled&lt;/p&gt;
&lt;p&gt;Large page memory access are far ahead! Not really a surprise, but it‚Äôs nice to see in action. Check &lt;a href=&quot;https://github.com/aybassiouny/mahdytech/blob/master/content/blog/large-pages-how-when/Src/LargePageTest/LargePageTest/LargePageTest.cpp&quot;&gt;LargePageTest.cpp&lt;/a&gt; for the source of this piece.&lt;/p&gt;
&lt;h2 id=&quot;last-notes&quot;&gt;Last notes&lt;/h2&gt;
&lt;p&gt;Large Pages are especially important if you have a large chunk of memory to allocate, and access frequently. Its major downside: it‚Äôs hard to allocate, and once allocated, it ‚Äúsits‚Äù there in the physical memory, even if the process that did the allocation is idle, as large-page memory is non-pageable.&lt;/p&gt;
&lt;p&gt;In case someone is wondering about the service where large pages didn‚Äôt give gains at the beginning of the blog, it turned out that this memory chunk was &lt;em&gt;already&lt;/em&gt; getting allocated as a large-page, and my hack on top to enable it was doing nothing. Unfortunately, large-pages are not very visible, but at least I now know where to look:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/7707cd7cd91bb48d04e0f94d12c66ea0/0fb99/Rammap.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 67.56756756756756%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAABJ0AAASdAHeZh94AAABy0lEQVQ4y61Ua5OiQAzk//+5rT1FlKeLCooiICiCj750dNTa8mr3w01VapjUpNNJT7DmSYI0SVEUBXa7HaqqQlmWaJoGbduqHY/H+96++J7f+/1e78RxDCsMQ0RhhOVyiSzLsFqtsF6v5bzSs/HT6E/TFJvNRpJXj+Tb7VbJRFEEK4qmihzHMwHLMJ8vkMsFMt7kORaLBF9fMfTebKaJEvHxLr8JSrCyrOB6HiyWFviBApJ+358U9Nh1MMuU3d19p9MJh0MrdsDlclEfz+PxBFbfd7CHNhxnjDzfauDHx6dm5Lqcz+J7gl+vV7xbZ7nneT4sZnVGDjzXV/oMtu2RlFHfAIUBk1zvYO/MsPZ8/8aQyKEIw150XY/JxEVdNw9AU+orwHfGBAyC4A7oev8FMKTKpmRfWP4L0PTwZ4ahAEp/hoOhKlQUpQYPBrb0c/cUpf1dD/1bD3uMRITJ2NVHSoaffwYPURhAUX5aVFkBm7qG67oqDCeApY6kBeYJmTfI0r8bQciMO++5ooXFuj2PooQK6jjST1GLijHjdDrVcXtnuUwSx47JaYyzEvk5cF7JjmPGeeTc8szZpXG+s+zVbjPP8WSbuNdSKWP/AmsaLGoe0gfMAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Rammap&quot;
        title=&quot;&quot;
        src=&quot;/static/7707cd7cd91bb48d04e0f94d12c66ea0/fcda8/Rammap.png&quot;
        srcset=&quot;/static/7707cd7cd91bb48d04e0f94d12c66ea0/12f09/Rammap.png 148w,
/static/7707cd7cd91bb48d04e0f94d12c66ea0/e4a3f/Rammap.png 295w,
/static/7707cd7cd91bb48d04e0f94d12c66ea0/fcda8/Rammap.png 590w,
/static/7707cd7cd91bb48d04e0f94d12c66ea0/efc66/Rammap.png 885w,
/static/7707cd7cd91bb48d04e0f94d12c66ea0/0fb99/Rammap.png 965w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;</content:encoded></item><item><title><![CDATA[Profiling Processor Cache Misses with VTune]]></title><description><![CDATA[I heard about VTune a while ago as a processor instruction level profiler, but I never got the chance to play around with it. This blog‚Ä¶]]></description><link>https://mahdytech.com/vtune-cache-miss/</link><guid isPermaLink="false">https://mahdytech.com/vtune-cache-miss/</guid><pubDate>Tue, 06 Aug 2019 12:00:32 GMT</pubDate><content:encoded>&lt;p&gt;I heard about &lt;a href=&quot;https://software.intel.com/en-us/vtune&quot;&gt;VTune&lt;/a&gt; a while ago as a processor instruction level profiler, but I never got the chance to play around with it. This blog - and maybe others in the future - will narrate my trials to get a hang of VTune.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#first-things-first-what-is-vtune&quot;&gt;First things first: What is VTune&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#getting-vtune&quot;&gt;Getting VTune&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#lets-take-vtune-for-a-ride-cache-misses&quot;&gt;Let‚Äôs Take VTune for a Ride: Cache Misses&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#row-major-and-column-major-2d-array-traversal&quot;&gt;Row-Major and Column-Major 2D Array Traversal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#how-slow-is-this&quot;&gt;How Slow is This&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#profiling-with-vtune&quot;&gt;Profiling with VTune&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#column-major-access&quot;&gt;Column-Major Access&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#row-major-access&quot;&gt;Row-Major Access&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#detour-trying-a-naive-fix&quot;&gt;Detour: Trying a Naive Fix&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;first-things-first-what-is-vtune&quot;&gt;First things first: What is VTune&lt;/h2&gt;
&lt;p&gt;VTune is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Profiling_(computer_programming)&quot;&gt;profiler&lt;/a&gt; capable of a similar job to CPU sampled profiling in &lt;a href=&quot;https://mahdytech.com/2019/01/13/curious-case-999-latency-hike/#f1-profile0&quot;&gt;XPerf&lt;/a&gt; or Visual Studio debugger, with a significant edge: it supports hardware-based event sampling, using a special chip on Intel processors called the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-performance-counter-monitor&quot;&gt;Performance Monitoring Unit&lt;/a&gt; (PMU). Using events reported by the PMU, VTune can give an in-depth look into an application‚Äôs performance, and a general ‚Äúverdict‚Äù, such as being &lt;a href=&quot;https://software.intel.com/en-us/vtune-amplifier-help-front-end-bound&quot;&gt;front-end bound&lt;/a&gt; or &lt;a href=&quot;https://software.intel.com/en-us/vtune-amplifier-help-back-end-bound&quot;&gt;back-end bound&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;While OS-reported CPU usage levels are effective most times, the time comes when we need a deeper insight into what is happening on the hardware level. In my experience, this is most beneficial in tight loops or portions of the code on an ultra-hot path: those 50 lines of code responsible for more CPU usage than the thousands of lines in the rest of of the application, it is for those 50 lines that VTune can come in handy.&lt;/p&gt;
&lt;h3 id=&quot;getting-vtune&quot;&gt;Getting VTune&lt;/h3&gt;
&lt;p&gt;I was pleasantly surprised to see that personal use for VTune has become &lt;a href=&quot;https://software.intel.com/en-us/vtune/choose-download#standalone&quot;&gt;free&lt;/a&gt;, until recently it was only a 30-day evaluation. The 2019 edition comes with a sleek GUI and great integration with Visual Studio. Using VTune from within Visual Studio is straightforward and fits nicely into my usual development cycle.&lt;/p&gt;
&lt;h2 id=&quot;lets-take-vtune-for-a-ride-cache-misses&quot;&gt;Let‚Äôs Take VTune for a Ride: Cache Misses&lt;/h2&gt;
&lt;p&gt;We‚Äôre always told to build applications to be &lt;a href=&quot;https://www.youtube.com/watch?v=WDIkqP4JbkE&amp;#x26;feature=youtu.be&quot;&gt;cache-friendly&lt;/a&gt;, but such things are easier said than done. Now, if we can &lt;em&gt;detect&lt;/em&gt; being non-cache friendly and fix it, that‚Äôs powerful. For my first VTune experiment, I want to explore if it can detect cache unfriendliness.&lt;/p&gt;
&lt;h3 id=&quot;row-major-and-column-major-2d-array-traversal&quot;&gt;Row-Major and Column-Major 2D Array Traversal&lt;/h3&gt;
&lt;p&gt;A classic example for cache misses is the 2D array traversal problem. Say, we need to find the sum of all elements in an array, we could either loop on rows, or on columns:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// row major traversal&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; numRows&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; j &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; j &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; numColumns&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;j&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        sum &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; matrix&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;j&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;// column major traversal&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; numRows&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; j &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; j &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; numColumns&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;j&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        sum &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; matrix&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;j&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To choose a row or a column-major design depends entirely on how the matrix is represented in memory. Assuming &lt;code class=&quot;language-text&quot;&gt;matrix&lt;/code&gt; is an array of pointers (e.g. &lt;code class=&quot;language-text&quot;&gt;int**&lt;/code&gt; or a &lt;code class=&quot;language-text&quot;&gt;vector&amp;lt;vector&amp;lt;int&gt;&gt;&lt;/code&gt;) the column major traversal has a huge issue: it will trigger vastly more cache misses than row-major traversal.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For an overview of what‚Äôs a cache miss and CPU memory access costs checkout &lt;a href=&quot;https://fgiesen.wordpress.com/2016/08/07/why-do-cpus-have-multiple-cache-levels/&quot;&gt;‚ÄúWhy do CPUs have multiple cache levels?‚Äù&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A picture makes things easier:&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 57.432432432432435%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAQACBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe26QmP/xAAWEAEBAQAAAAAAAAAAAAAAAAAQEUH/2gAIAQEAAQUC0j//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAYEAACAwAAAAAAAAAAAAAAAAAAASAhMv/aAAgBAQAGPwJ2aj//xAAaEAADAAMBAAAAAAAAAAAAAAAAAREQITFR/9oACAEBAAE/IUS7C52kWwi8WP/aAAwDAQACAAMAAAAQq8//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAVEQEBAAAAAAAAAAAAAAAAAAAQEf/aAAgBAgEBPxCn/8QAHBABAAICAwEAAAAAAAAAAAAAAQAhETFRYXHx/9oACAEBAAE/EG4tTNcRor5gl9PYgaFnc+RADRif/9k=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Traversal&quot;
        title=&quot;&quot;
        src=&quot;/static/bd61a4177fcda591a806e2b7db6973af/1c72d/rowcolumnarrays.jpg&quot;
        srcset=&quot;/static/bd61a4177fcda591a806e2b7db6973af/a80bd/rowcolumnarrays.jpg 148w,
/static/bd61a4177fcda591a806e2b7db6973af/1c91a/rowcolumnarrays.jpg 295w,
/static/bd61a4177fcda591a806e2b7db6973af/1c72d/rowcolumnarrays.jpg 590w,
/static/bd61a4177fcda591a806e2b7db6973af/80e3c/rowcolumnarrays.jpg 720w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;center&gt;Source: &lt;a href=https://craftofcoding.wordpress.com/2017/02/03/column-major-vs-row-major-arrays-does-it-matter/&gt;craftofcoding&lt;/a&gt;&lt;/center&gt;
&lt;p&gt;When code tries to access element &lt;code class=&quot;language-text&quot;&gt;1&lt;/code&gt;, processor fetches it from the main memory into the cache, and adjacent elements &lt;code class=&quot;language-text&quot;&gt;2&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;3&lt;/code&gt; are fetched as well, which comes in handy as code accesses them next. However, a column-major pattern accesses &lt;code class=&quot;language-text&quot;&gt;4&lt;/code&gt; afterwards, not using &lt;code class=&quot;language-text&quot;&gt;2&lt;/code&gt; or &lt;code class=&quot;language-text&quot;&gt;3&lt;/code&gt; that we already have in cache, and incurring an additional memory access.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note that the above is a toy sample, and there need be over 3 elements per row, otherwise the whole array could be cached after the first element access.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;how-slow-is-this&quot;&gt;How Slow is This&lt;/h3&gt;
&lt;p&gt;To test the effects of array access pattern, I used a tiny app that builds an array, then tries to sum its elements several 1000 times, to emulate a real CPU load. I created two versions, one with row-major and one with column-major access for the array, code for both is on &lt;a href=&quot;https://github.com/aybassiouny/mahdytech/tree/master/content/blog/vtune-cache-miss&quot;&gt;github&lt;/a&gt;. Then, I ran both examples for varying array sizes: &lt;/p&gt;
&lt;p&gt;&lt;canvas class=&quot;js-chart&quot; width=&quot;400&quot; height=&quot;400&quot; data-chart=&quot;
    {
        &apos;data&apos;: [
            {
                &apos;label&apos;: &apos;Row-major&apos;,
                &apos;data&apos;: [33,27,197,111,57,223,1272,2809,12298,41725,208140]
            },
            {
                &apos;label&apos;: &apos;Column-Major&apos;,
                &apos;data&apos;: [16,23,32,85,257,976,3366,11967,75507,382699,2559339]
            }
        ]
    }
    &quot; 
    data-labels-chart = &quot;1,2,4,8,16,32,64,128,256,512,1024&quot;
    data-yaxis-chart=&quot;logarithmic&quot;
    data-yaxis-name = &quot;Latency in Nanoseconds (Logarithmic Scale)&quot; data-xaxis-name = &quot;Array Size&quot;
    &gt;&lt;/canvas&gt;&lt;/p&gt;
&lt;p&gt;The graph shows that as array size goes beyond several elements, where the whole array might even be cached, row-major access is the very clear winner. Now that we have a ripe test case, let‚Äôs see how VTune can profile this.&lt;/p&gt;
&lt;h2 id=&quot;profiling-with-vtune&quot;&gt;Profiling with VTune&lt;/h2&gt;
&lt;p&gt;From Vistual Studio, it is straightforward to trigger a VTune profile by clicking &lt;code class=&quot;language-text&quot;&gt;Profile with VTune Amplifier&lt;/code&gt;, adjusting config, then clicking &lt;code class=&quot;language-text&quot;&gt;Start&lt;/code&gt;: &lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 62.16216216216216%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAB2HAAAdhwGP5fFlAAAB+ElEQVQoz3VTaW/aQBD1//8j/d5ErUIOoMSCVGqrJiUtEGJ8YER84wPb2LzODFoSImWkpz08++a92bXWe3BwfW/j4vcS3bGLx6kBw7AxmRmY8nzhYP0SwHFWtG/CtFwsTBeWtcLS9QQ27RnTOebPNrRvf0yMZmsMn3yM5gEGt0Ocf7lE50bHYPgD+uin4JYg67tfMlfrvv4dnesBOl0dVz0dWlPmYLQE1FtSQxWXLnw/wCbNsNs1KMsK222JlNbPC4sUWvDoexhFss9RVZyzhZZmGRSyLIdpu7gf/8P474zGCR4ep5gblmDyZMB2XLjuCp7nUT6dS1MBz5umgZYJ0QFFUSCOE/hBIGqiKEaSJKRyJyjLUhz4vkd5sayLbSHKGEKY5zkYTJjnBbIkRhGHqLINqjRBlaeoyU5d10IqVsNQCPlc27ZQsd/v3xPmooxVqZ4wkQomjJONELJNRfIWJ4TcQ7bNVlg+J7ACHoWM2sGEAbWEi70lOipU/VPEfKNMyMqYVBFz1PVOesgXwiqFlPbbdn8sflSYUGXuT1G8NpgTlEIeuVgQ8lMp8FFo6sqTOIK3dk7svoIbv0dNtvlZrdYeKfWx9oJT0B+lBSQ9pKpxFCB+MVGRCoiNVqwccFDJls+udHw6u8Flf4Tu4A6fv3ZxftEn9GT8D87KiqsifdcNAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;VTune inside Visual Studio&quot;
        title=&quot;&quot;
        src=&quot;/static/216624ddcc987856e0c575f0d76c6f98/fcda8/vtune_inside_vs.png&quot;
        srcset=&quot;/static/216624ddcc987856e0c575f0d76c6f98/12f09/vtune_inside_vs.png 148w,
/static/216624ddcc987856e0c575f0d76c6f98/e4a3f/vtune_inside_vs.png 295w,
/static/216624ddcc987856e0c575f0d76c6f98/fcda8/vtune_inside_vs.png 590w,
/static/216624ddcc987856e0c575f0d76c6f98/efc66/vtune_inside_vs.png 885w,
/static/216624ddcc987856e0c575f0d76c6f98/c83ae/vtune_inside_vs.png 1180w,
/static/216624ddcc987856e0c575f0d76c6f98/c08fe/vtune_inside_vs.png 2931w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;p&gt;Note using &lt;code class=&quot;language-text&quot;&gt;Microarchitecture Exploration&lt;/code&gt; under the How, as VTune can do User-Mode sampling, but I would rather use XPerf or &lt;a href=&quot;https://docs.microsoft.com/en-us/visualstudio/profiling/how-to-install-the-stand-alone-profiler?view=vs-2019&quot;&gt;F1&lt;/a&gt; for that.&lt;/p&gt;
&lt;p&gt;One more note is to make sure to set paths for system symbols. While VTune interface does not stress adding them, results were useless without system symbols:&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 33.78378378378378%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAB2GAAAdhgFdohOBAAABRklEQVQoz32PTUsCURiF718K2rRrF/0CoX2bltGPqE1CUW2EMIwgjLDR8Ws0ndHRETGUtKmQBooY3MyHN3JG9HRnxCK1Djycy315zz2XDIdDeBiGAU3TYFkWPI1GI4zH4z/x5osg/pDhOA4opXBc1w/8b8mbTTT1HxHDsPBJbdaMYdPJ2TTRpx9wWbj30NQHgwFzF3afwjAthj0H4TIigtEyuIwEIVfE0bWMyE0BnY7qf7/X632j6zpsdldrtBBL5sFnRfCZ4i/IVriOlcMOAidV7EWrWD1uY2lXQVKs40F9RPNehfrUhaw0UKnd+aTzJXCpW8TThTnIRqiB9dMu1g5q2IkoCJy/YHm/icusgpIkoa0+4/XtHTE+z8j57i0mWJtFkIuEhM2QjLN4CWlBxHa4guCVjGxOZE3KSAmS32h2cRo6G/4Fvn/pWDcQr+YAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Adding Symbols&quot;
        title=&quot;&quot;
        src=&quot;/static/4d965f00f307e51425ed6f5bfcb534b6/fcda8/symbols_1.png&quot;
        srcset=&quot;/static/4d965f00f307e51425ed6f5bfcb534b6/12f09/symbols_1.png 148w,
/static/4d965f00f307e51425ed6f5bfcb534b6/e4a3f/symbols_1.png 295w,
/static/4d965f00f307e51425ed6f5bfcb534b6/fcda8/symbols_1.png 590w,
/static/4d965f00f307e51425ed6f5bfcb534b6/efc66/symbols_1.png 885w,
/static/4d965f00f307e51425ed6f5bfcb534b6/e2310/symbols_1.png 968w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 51.35135135135135%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAB2HAAAdhwGP5fFlAAAA5ElEQVQoz72SQQ6CMBREe/+1N/EGsvMEQCS6wYBCgYKAbWHsr6IIYlw5yUubTDv9gWGcc8RxjDzPIZVCXdeoqgukVNBdB6214b4qZdBzpJQguZ4HJoSwYcqEXY1xOp8RhkdwnkGUJQryiwJlVd0D1JzrEOi6YBip7/vHJMq+2pkJxzxOzRg83/fBKGTKkqz/IfJj4PPCZP8Lb4HD5b8HftPiNyTj2xRL0I8keVSb6WtUoSmFqU3btpamad72BFWHFAQBWJqmGEiSBFEU2aLTOoZ8zl9nCZFn8A4hVust3N0ejrPBDR3gDKQrSZVGAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Adding Symbols&quot;
        title=&quot;Adding Symbols to VTune&quot;
        src=&quot;/static/da9adc21b298d7d0815f96eb034578fd/fcda8/symbols_2.png&quot;
        srcset=&quot;/static/da9adc21b298d7d0815f96eb034578fd/12f09/symbols_2.png 148w,
/static/da9adc21b298d7d0815f96eb034578fd/e4a3f/symbols_2.png 295w,
/static/da9adc21b298d7d0815f96eb034578fd/fcda8/symbols_2.png 590w,
/static/da9adc21b298d7d0815f96eb034578fd/efc66/symbols_2.png 885w,
/static/da9adc21b298d7d0815f96eb034578fd/c83ae/symbols_2.png 1180w,
/static/da9adc21b298d7d0815f96eb034578fd/81e05/symbols_2.png 2235w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;Adding Symbols to VTune&lt;/figcaption&gt;
  &lt;/figure&gt;
      &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;One last note - VTune also supports profile using a portable executable, allowing for capture &amp;#x26; analysis to happen on different machines.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A profile capture is now ready - let‚Äôs have a look at the results!&lt;/p&gt;
&lt;h3 id=&quot;column-major-access&quot;&gt;Column-Major Access&lt;/h3&gt;
&lt;p&gt;In this test, I used an array of size 2048, and ran that operation for 200 times. Running VTune for the app resulted in:&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAB2HAAAdhwGP5fFlAAACTklEQVQoz3WSu28TQRDGTymoqAgNDS0FFHQQIWiCUEQbKIMETZDo6FA6pBRIiCYIiX8gkUA0UESKCHnwcBIcHGJisOPEie27s32272Hf+3w/1mcsJCRGGn27M7vffjOzUmprmy+babbSGVKb23zP5pCVGjvZn2R2c2QE5g7K7JdrFCs1CscqBbHOH1bY+1VMzg09mysgVWSFg9IxFVml0dBQVRXHceh0bVzPw+p00UzhHQfd9uiGMd0InCDCE3nPDwT6uK6XoGTaPtVml5bl0ItjgjCg3WxiG2365mgqi9MTvJ26wvuHt9mYmeLzgwmy83OYjke9pmKaJkOTjK6Horu0Oh5x3EuCoSA1dJ2WB1oxz6exET6cl0jdGGX18ghLZyXWp8fJH5XZTn+lVCqJu3HikmW7qG2bassR6sIBoedgag2qZg+1WCB18wxr106yMXmOj+OnWLkosTJ1iXKlymHxgKrAKIoGCiHGFX1QBKkfhGIHke9iaXWUTox+tM/ymMSiULg+cZrlqydYuiDx7voo33bS/MjvodSVhCxROKy9afk0DJcw6glCD6PVpG5FYlAqzx/f4emjSV4+uc+L2bs8m7nF3Ow95pcWWFh9zau1N1hO56/CMIyEQoeu6yfBoE9omMi6hy6mKzcNkbcoyTVyxRIbmV0q9aY4Y6CLXvex1xv0X/JEmZrpUtZsQRgkQd/3MawOhhNieyF1QVZvGbSFalWRUeQqNVUR6htompaQ9stNCF3xn3Q7EF8gEI0dvNJ/LfwzoH9tOM3/5X4DFJzHnBnkqyAAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Column Major&quot;
        title=&quot;&quot;
        src=&quot;/static/4d51b4f8db220e98a973eda220811270/fcda8/column_major.png&quot;
        srcset=&quot;/static/4d51b4f8db220e98a973eda220811270/12f09/column_major.png 148w,
/static/4d51b4f8db220e98a973eda220811270/e4a3f/column_major.png 295w,
/static/4d51b4f8db220e98a973eda220811270/fcda8/column_major.png 590w,
/static/4d51b4f8db220e98a973eda220811270/efc66/column_major.png 885w,
/static/4d51b4f8db220e98a973eda220811270/c83ae/column_major.png 1180w,
/static/4d51b4f8db220e98a973eda220811270/487ba/column_major.png 2367w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;p&gt;As trivial as this example is - I was impressed by the verbose verdict. The &lt;code class=&quot;language-text&quot;&gt;Memory Bound&lt;/code&gt; red box aligns well with our expectations, we‚Äôre accessing too much memory and too little cache.&lt;/p&gt;
&lt;h3 id=&quot;row-major-access&quot;&gt;Row-Major Access&lt;/h3&gt;
&lt;p&gt;Next, I ran same app with a small change in indices used to access the array:  &lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.08108108108109%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAB2HAAAdhwGP5fFlAAACaklEQVQoz4WSzWsTURTFAy4E/QNE0JUgVMGCdVO7qhZUunBRdCciCC2KXWgputF2YTcKduVal4pI6Rc1jf1IW6OxaotV0Sxa26RpPiYzmWTmzVfy880kBrrRAwfuG+6cd+55NzQ6Oc3o1Czj4TlGJiNE5mMsr3xjamaRyUhUcoE3szEW3n/mXXyVaOwTM9EPNS7EmZiOMvZmlonwPFNvFwnl8gqbqTQ72TzFok5RU/FRKum4rhPUprDYzCn8ziqowmY3qrtOobJwSasCRRdUqlWqkpVKhUKhgK7rQVPm5xqvei7y8non4fs9rA7fY3mwm/WZMYRbpVjQsOsXhbSyIKUYZDSB53mBoA/HtqSoRkbAVnyOSMd+wmf2MXfpCGNtexhpCjHe3U7s6xeWPi7yayNREzSlcr4oSComtuM2hqiYJdRMmmwR5hNxWh61cmzoJB1PO2l53MbRoWbahzs4/vAUhweaaH1yFsu1CQVuXDdwKWynkYVjCelQJWdA4keM/muHuH3lAIO9J+i7epBbXXu523ea/hcP6H1+h4HXQ7ieS6gq8zKky6280XDow5Ujq6rGthRUvq+wevMCqzfOs9J3meXucyx1NZN4Nixztimk8xhquTayDE069NhRTTTDxrTcYGRPlNHyeVKqJb8LtuQPyaLBRiZHIrXD2vqmjEMntZ0kuZ1CKSh1wTqUkiVzFHI9fKdefWSNtGYH54JuoOplyvLlc5kMuWwGRV5YKpUCCiFqgo5bQTdrq5MrWpTkGrleNWgwTBNZNl7+f/D7Qn5+ihzFd2BZFo5jB/RrUwr+XdxqfUf/RR9/ABy+DEu44oOkAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Row Major&quot;
        title=&quot;&quot;
        src=&quot;/static/5f2a71bf69a94e43df0c37a8bf99d0ef/fcda8/row_major.png&quot;
        srcset=&quot;/static/5f2a71bf69a94e43df0c37a8bf99d0ef/12f09/row_major.png 148w,
/static/5f2a71bf69a94e43df0c37a8bf99d0ef/e4a3f/row_major.png 295w,
/static/5f2a71bf69a94e43df0c37a8bf99d0ef/fcda8/row_major.png 590w,
/static/5f2a71bf69a94e43df0c37a8bf99d0ef/efc66/row_major.png 885w,
/static/5f2a71bf69a94e43df0c37a8bf99d0ef/c83ae/row_major.png 1180w,
/static/5f2a71bf69a94e43df0c37a8bf99d0ef/465de/row_major.png 2371w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;p&gt;Note the ‚ÄúElapsed Time‚Äù of 2.5s, a 7x speedup over the row-major test. Furthermore, the 30.5% &lt;code class=&quot;language-text&quot;&gt;Retiring&lt;/code&gt; box (in green) represents the percentage of instructions the processor successfully predicted &amp;#x26; executed, a higher number represents more efficient execution - again aligning with expectations.&lt;/p&gt;
&lt;p&gt;VTune makes it clear this is by far not a perfect implementation and shows two red boxes. The red &lt;code class=&quot;language-text&quot;&gt;Core Bound&lt;/code&gt; box below represents backend non-memory issues, in our case &lt;em&gt;probably&lt;/em&gt; referring to missing out on &lt;a href=&quot;https://www.codingame.com/playgrounds/283/sse-avx-vectorization&quot;&gt;vectorizing instructions&lt;/a&gt; for array traversal and sum. The other red box, &lt;code class=&quot;language-text&quot;&gt;Memory Bound&lt;/code&gt; &lt;em&gt;probably&lt;/em&gt; refers to the inter-dependency of our stores: all array accesses are appended to the same variable &lt;code class=&quot;language-text&quot;&gt;sum&lt;/code&gt;, and dependent stores are hard to parallelize.&lt;/p&gt;
&lt;h3 id=&quot;detour-trying-a-naive-fix&quot;&gt;Detour: Trying a Naive Fix&lt;/h3&gt;
&lt;p&gt;Before signing off, I tried one more interesting experiment. The &lt;a href=&quot;#Row-Major-Access&quot;&gt;last profile&lt;/a&gt; had pointed to a memory bound, and I wanted to see if I could improve the code - in the silliest way possible. I replaced the single storage variable &lt;code class=&quot;language-text&quot;&gt;sum&lt;/code&gt; with an array, and hence, &lt;em&gt;artificially&lt;/em&gt; decreasing instruction inter-dependency:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;// Before&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;GetSum&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; TMatrix&lt;span class=&quot;token operator&quot;&gt;&amp;amp;&lt;/span&gt; matrix&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; sums &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; matrix_size&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        sum &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; matrix&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; sum&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;// After&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;GetSumArr&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; TMatrix&lt;span class=&quot;token operator&quot;&gt;&amp;amp;&lt;/span&gt; matrix&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; sums&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; i &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt; matrix_size&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
        sums&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;i&lt;span class=&quot;token operator&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;+=&lt;/span&gt; matrix&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; sum&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; sum&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; sum&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; sum&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now let‚Äôs re-run VTune:&lt;/p&gt;
&lt;p&gt;
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 46.621621621621614%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAB2HAAAdhwGP5fFlAAACLElEQVQoz3WS20tUURTG5z+IfAhiQqOgwoxSiDAjo17sL4ighwrLt8SHigorjLALVk9FEJIlSJCBYJdpxrEcGydNsKggiErRuZyZcx/POTPnzPzac2TyqQXfZl32+lj72yvwKhThZSjKm/A4o68jxOLTfP3+g/D4JBGBdx+mmUjMkpj94iM+M+djUuRiiU+8jcYIjb3370cnpgjIqs5iSiKn6FiWRSqZxHFsqiYtpVj4+YvF33+wjTwlu4An8D8LGFaRpGKjmg7lMti2jSRJFFwPT8ShvjM8PNrAQMd+hrsOM3SiiWcdLYTHnhOdixGZGSOtpH2yUqlEQDEsluRlMprtJypm6hpp1UI2PU4PtlN7Icju3iYO3T3Apot1NPbsoPl2Kxu6t7HmbJBH8QG/z/VcApZTIKvbLMoWRdf1C7YikcyZ5AyX9hddBG/spP7ePvbcb2Pd9Xq23Gmm5UEbdb3bqblaR//M01XCilMouv6UVcJlQxNxHtMu0/H4OOs719J4uZ6DN1vYfC7Iru6t7L3VysYrDdScr6V/6skqoSu00vIOC9k8ebsodCxjqjKSZqFaHomhPkZ6jjHae4qRaycZ7Gxj+NIR4h/DxL+JDfg8SUpe0bDSG1h2PLKGeLbhiEk9P+nYK3pWfEUXWoq6oppkJZn5+SWyWRVdNVCyCrqs4Ymh/hFWjlKp7AdVq7jV2LQccrqJYZrIco5MJi22IIMmPk43DAwBz1sl/AsCSmIjslxDigAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Row Major Array Sum&quot;
        title=&quot;&quot;
        src=&quot;/static/4d977fa88f8c4c954fe322e6a52aeed5/fcda8/row_major_arrsum.png&quot;
        srcset=&quot;/static/4d977fa88f8c4c954fe322e6a52aeed5/12f09/row_major_arrsum.png 148w,
/static/4d977fa88f8c4c954fe322e6a52aeed5/e4a3f/row_major_arrsum.png 295w,
/static/4d977fa88f8c4c954fe322e6a52aeed5/fcda8/row_major_arrsum.png 590w,
/static/4d977fa88f8c4c954fe322e6a52aeed5/efc66/row_major_arrsum.png 885w,
/static/4d977fa88f8c4c954fe322e6a52aeed5/c83ae/row_major_arrsum.png 1180w,
/static/4d977fa88f8c4c954fe322e6a52aeed5/d9774/row_major_arrsum.png 2365w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  &lt;/p&gt;
&lt;p&gt;And we achieved the goal: retiring instruction rate has doubled, but at a very severe cost: it‚Äôs much slower, and on top of that, VTune report looks counterintuitively better.&lt;/p&gt;
&lt;p&gt;This is not a surprise - quoting the &lt;a href=&quot;https://software.intel.com/en-us/vtune-amplifier-help-retiring&quot;&gt;docs&lt;/a&gt;: ‚Äúa high Retiring value does not necessary mean no more room for performance improvement.‚Äù It just means the instructions are being run efficiently but those instructions might be bloated, as in our code above where we‚Äôre executing a lot more instructions that needed.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Elapsed time above is not accurate as I have increased number of total runs to get more accurate summary from VTune. Actual comparable runtime is about double the row-major access.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I am impressed with VTune so far and wonder how does it scale for profiling production scale applications. Nonetheless, VTune is educational, I have learnt a bunch about hardware, even though I ran one of the simplest examples possible.&lt;/p&gt;
&lt;p&gt;Code samples &amp;#x26; VTune captures for those interested in further debugging are in the &lt;a href=&quot;https://github.com/aybassiouny/mahdytech/tree/master/content/blog/vtune-cache-miss/Captures&quot;&gt;post material&lt;/a&gt;. Thanks for reading!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Help &lt;a href=&quot;https://github.com/aybassiouny/mahdytech/issues&quot;&gt;improve this text&lt;/a&gt; or discuss it on &lt;a href=&quot;https://www.reddit.com/r/programming/comments/cmuhvd/profiling_processor_cache_misses_with_vtune/&quot;&gt;reddit&lt;/a&gt;, &lt;a href=&quot;https://news.ycombinator.com/item?id=20628120&quot;&gt;hackernews&lt;/a&gt;.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[More is Sometimes Less: When Lower Load Triggers Higher Latencies]]></title><description><![CDATA[Backdrop Narrowing it Down Data Store is Innocent gRPC Profile Cures All More Debugging What if Ignite the Network Engineer Within Now‚Ä¶]]></description><link>https://mahdytech.com/low-qps-higher-latency/</link><guid isPermaLink="false">https://mahdytech.com/low-qps-higher-latency/</guid><pubDate>Sun, 12 May 2019 12:00:32 GMT</pubDate><content:encoded>&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#backdrop&quot;&gt;Backdrop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#narrowing-it-down&quot;&gt;Narrowing it Down&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#data-store-is-innocent&quot;&gt;Data Store is Innocent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#grpc&quot;&gt;gRPC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#profile-cures-all&quot;&gt;Profile Cures All&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#more-debugging&quot;&gt;More Debugging&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#what-if&quot;&gt;What if&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#ignite-the-network-engineer-within&quot;&gt;Ignite the Network Engineer Within&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#now-which-os-are-we-on&quot;&gt;Now, which OS are we on&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#nagles-algorithm&quot;&gt;Nagle‚Äôs algorithm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;backdrop&quot;&gt;Backdrop&lt;/h2&gt;
&lt;p&gt;As in &lt;a href=&quot;https://mahdytech.com/2019/01/13/curious-case-999-latency-hike/&quot;&gt;most posts&lt;/a&gt; - a distributed service was misbehaving, let‚Äôs call this service Alvin. This time, I didn‚Äôt discover the issue myself, it was instead reported by the team owning the client.&lt;/p&gt;
&lt;p&gt; One day, I woke up to a disgruntled email due to high latencies caused by Alvin, that we were planning to launch soon. In particular, the client was facing 99th latency around 50ms, way above our latency budget. That was surprising, as I have thoroughly tested this service, especially the latency - the point of complaint.&lt;/p&gt;
&lt;p&gt; Before declaring Alvin &lt;em&gt;testable&lt;/em&gt;, I had run many experiments with 40k QPS, all showing less than 10ms latency. I got ready to reply dismissing their results. However, another look at the email showed something new: I didn‚Äôt &lt;em&gt;exactly&lt;/em&gt; test the conditions they mentioned, their &lt;a href=&quot;https://en.wikipedia.org/wiki/Queries_per_second&quot;&gt;QPS&lt;/a&gt; was much lower than mine. While I was testing with 40k QPS, they were testing with only 1k. I ran my experiment once again, with lower QPS this time, just to humour them.&lt;/p&gt;
&lt;p&gt;Since I am blogging about this - you probably figured it out already: their numbers were correct. I re-ran my dummy client again and again, all with the same result: Lower QPS, not only leads to higher latencies, but just plain higher number of requests with latency over 10ms. In other words, if at 40k QPS 50 queries every second were over 50ms, at 1k QPS there were 100 queries every second above 50ms. Paradox!&lt;/p&gt;
&lt;p&gt;&lt;canvas class=&quot;js-chart&quot; width=&quot;400&quot; height=&quot;400&quot; data-chart=&quot;
    {
        &apos;data&apos;: [
            {
                &apos;label&apos;: &apos;500 QPS&apos;,
                &apos;data&apos;: [3, 10, 45, 50]
            },
            {
                &apos;label&apos;: &apos;1k QPS&apos;,
                &apos;data&apos;: [2, 5, 15, 30]
            },
            {
                &apos;label&apos;: &apos;30k QPS&apos;,
                &apos;data&apos;: [1, 2, 3, 5]
            }
        ]
    }
    &quot; data-labels-chart = &quot;Avg,90th,95th,99th&quot; data-labels-chart = &quot;Avg,90th,95th,99th&quot; data-yaxis-name = &quot;Latency in Milliseconds&quot; data-xaxis-name = &quot;Latency Percentile&quot;&gt;&lt;/canvas&gt;&lt;/p&gt;
&lt;h2 id=&quot;narrowing-it-down&quot;&gt;Narrowing it Down&lt;/h2&gt;
&lt;p&gt;In a distributed system with many components, the first thing to do when faced with a latency issue is to shortlist the suspects. Let‚Äôs dig a bit deeper into Alvin‚Äôs architecture:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/9635ff334dcfcdac97abb7cef6f8711c/AlvinStore.svg&quot; alt=&quot;AlvinStore&quot;&gt;&lt;/p&gt;
&lt;p&gt;A good starting point is to list the IO hops done (Network calls/Disk seeks, etc), and try and figure out which one contains the latency delay. Besides the obvious IO between Alvin and its client,  Alvin is doing an extra IO step - it is calling into a Data Store. However, this Data Store lives in the same cluster with Alvin, so it should be a smaller network hop than the one between Client &amp;#x3C;=&gt; Alvin. The following suspect list lines up:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Network call from &lt;code class=&quot;language-text&quot;&gt;Client&lt;/code&gt; to &lt;code class=&quot;language-text&quot;&gt;Alvin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Network call from &lt;code class=&quot;language-text&quot;&gt;Alvin&lt;/code&gt; to &lt;code class=&quot;language-text&quot;&gt;Data Store&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;Data Store&lt;/code&gt; disk seek&lt;/li&gt;
&lt;li&gt;Network call from &lt;code class=&quot;language-text&quot;&gt;Data Store&lt;/code&gt; to &lt;code class=&quot;language-text&quot;&gt;Alvin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Network call from &lt;code class=&quot;language-text&quot;&gt;Alvin&lt;/code&gt; to &lt;code class=&quot;language-text&quot;&gt;Client&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let‚Äôs try to strike through some names.&lt;/p&gt;
&lt;h3 id=&quot;data-store-is-innocent&quot;&gt;Data Store is Innocent&lt;/h3&gt;
&lt;p&gt;First thing I did was converting Alvin into a ping-ping server, a server that does no request processing and once it gets a request, returns an empty response. If latency improves, then my implementation for Alvin or Data Store has a bug - nothing unheard of. This yielded the graph for the first experiment:&lt;/p&gt;
&lt;p&gt;&lt;canvas class=&quot;js-chart&quot; width=&quot;400&quot; height=&quot;400&quot; data-chart=&quot;
    {
        &apos;data&apos;: [
            {
                &apos;label&apos;: &apos;High QPS&apos;,
                &apos;data&apos;: [1,2,3,5]
            },
            {
                &apos;label&apos;: &apos;Low QPS&apos;,
                &apos;data&apos;: [3,10,45,50]
            },
            {
                &apos;label&apos;: &apos;Low QPS (Ping Pong Alvin)&apos;,
                &apos;data&apos;: [3,9,46,49]
            }
        ]
    }
    &quot; data-labels-chart = &quot;Avg,90th,95th,99th&quot; data-yaxis-name = &quot;Latency in Milliseconds&quot; data-xaxis-name = &quot;Latency Percentile&quot;&gt;&lt;/canvas&gt;&lt;/p&gt;
&lt;p&gt;As the graph shows, there is no improvement when using a ping-pong server, meaning that Data Store is not contributing to the latency hike, our suspect list is shortened to half:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Network call from &lt;code class=&quot;language-text&quot;&gt;Client&lt;/code&gt; to &lt;code class=&quot;language-text&quot;&gt;Alvin&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Network call from &lt;code class=&quot;language-text&quot;&gt;Alvin&lt;/code&gt; to &lt;code class=&quot;language-text&quot;&gt;Client&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Great! Our list is getting quickly smaller. I thought I was almost there.&lt;/p&gt;
&lt;h3 id=&quot;grpc&quot;&gt;gRPC&lt;/h3&gt;
&lt;p&gt;Now is a good time to introduce a new player to the scene: &lt;a href=&quot;https://github.com/grpc/grpc&quot;&gt;gRPC&lt;/a&gt;. &lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; is an open-source library by Google for intra-process &lt;a href=&quot;https://en.wikipedia.org/wiki/Remote_procedure_call&quot;&gt;RPC&lt;/a&gt; communication. While &lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; is highly optimized and heavily adopted, this was my first time using it on scale, and I was expecting that my usage was not optimal - to put it mildly.&lt;/p&gt;
&lt;p&gt;Having &lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; on board introduced a new question: is it my implementation, or is &lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; causing the latency problem? A new suspect is added to the list:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Client calls into &lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; library&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; library on the Client performs a network call into  &lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; library on the Server&lt;/li&gt;
&lt;li&gt;&lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; library calls into &lt;code class=&quot;language-text&quot;&gt;Alvin&lt;/code&gt; request processing callback (A no-op in the case of ping-pong server)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To have an idea what the code looked like at this point, my Client/Alvin implementation did not look much different from client/server &lt;a href=&quot;https://github.com/grpc/grpc/tree/v1.19.0/examples/cpp/helloworld&quot;&gt;async examples&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: The list above is a bit of a simplification, since &lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; gives consumers power (boilerplate?) of using their own threading model resulting in an intertwined execution stack between &lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; and consumer implementation. Let‚Äôs stick with this model for the sake of simplicity.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;profile-cures-all&quot;&gt;Profile Cures All&lt;/h3&gt;
&lt;p&gt;After striking out &lt;code class=&quot;language-text&quot;&gt;Data Store&lt;/code&gt; I had thought I was almost done. I figured: ‚ÄúEasy! I will take a profile and find out which part is causing the delay‚Äù. I am a &lt;a href=&quot;https://mahdytech.com/2019/01/13/curious-case-999-latency-hike/&quot;&gt;big fan of precise profiling&lt;/a&gt;, because CPUs are blazing fast, and most often they are not the bottleneck. The CPU having to stop processing to do something else is what brings about most delays. Precise CPU profiling is made just for that: it has an accurate record of all &lt;a href=&quot;https://www.tutorialspoint.com/what-is-context-switching-in-operating-system&quot;&gt;context switches&lt;/a&gt;, and in so an idea of where delays are.&lt;/p&gt;
&lt;p&gt;I took four profiles: one under high QPS (low latency), and one with ping-pong low QPS server (high latency), on both the client and server sides. And just for the heck of it, I also took a sampled CPU profile. When comparing profiles, I usually look for an abnormal callstack. For example, the bad side with high latency showing a lot more context switches (10x or more) than the good side with low latency. But what I found was an almost matching context switching between good and bad runs. To my dismay, however, nothing of substance was there.&lt;/p&gt;
&lt;h2 id=&quot;more-debugging&quot;&gt;More Debugging&lt;/h2&gt;
&lt;p&gt;I was getting desperate. My toolbox was empty, and my next plan was to basically wing it, iterating over experiments rather than diagnosing the problem.&lt;/p&gt;
&lt;h3 id=&quot;what-if&quot;&gt;What if&lt;/h3&gt;
&lt;p&gt;From the start, the 50ms latency number has been bugging me. 50ms is &lt;em&gt;a lot&lt;/em&gt; of time. I decided that my goal is to keep cutting pieces from my code until I can figure out which part is exactly causing this error. Next came the experiment that worked.&lt;/p&gt;
&lt;p&gt;It was pretty simple, and hindsight is 20/20 as usual. I placed my client in the same machine as Alvin, and sent the request to &lt;code class=&quot;language-text&quot;&gt;localhost&lt;/code&gt;. And the latency increase was gone!  &lt;/p&gt;
&lt;p&gt;&lt;canvas class=&quot;js-chart&quot; width=&quot;400&quot; height=&quot;400&quot; data-chart=&quot;
    {
        &apos;data&apos;: [
            {
                &apos;label&apos;: &apos;High QPS&apos;,
                &apos;data&apos;: [1,2,3,5]
            },
            {
                &apos;label&apos;: &apos;Low QPS&apos;,
                &apos;data&apos;: [3,10,45,50]
            },
            {
                &apos;label&apos;: &apos;Low QPS (Ping Pong Alvin)&apos;,
                &apos;data&apos;: [3,9,46,49]
            },
            {
                &apos;label&apos;: &apos;Low QPS (Localhost Client)&apos;,
                &apos;data&apos;: [0.8,1.7,2.5,4.5]
            }
        ]
    }
    &quot; data-labels-chart = &quot;Avg,90th,95th,99th&quot; data-yaxis-name = &quot;Latency in Milliseconds&quot; data-xaxis-name = &quot;Latency Percentile&quot;&gt;&lt;/canvas&gt;&lt;/p&gt;
&lt;p&gt;Something was wrong with the network.&lt;/p&gt;
&lt;h3 id=&quot;ignite-the-network-engineer-within&quot;&gt;Ignite the Network Engineer Within&lt;/h3&gt;
&lt;p&gt;I have a confession: my networking knowledge is abysmal, relatively to how much I deal with networks on a daily basis. Usually I‚Äôd say that‚Äôs to show how good abstraction layers work. However, network was the suspect #1, and I needed to learn how to debug that.&lt;/p&gt;
&lt;p&gt;Fortunately, internet is kind to those wanting to learn. A combination of ping and tracert seemed like a good enough start for debugging network transport issues.&lt;/p&gt;
&lt;p&gt;First, I ran &lt;a href=&quot;https://docs.microsoft.com/en-us/sysinternals/downloads/psping&quot;&gt;PsPing&lt;/a&gt; and targeted the TCP port Alvin was listening on. I used default parameters - nothing fancy. Despite running over a 1000 pings, I didn‚Äôt see any of which exceed 10ms, except for the first one for warmup. This contradicts the observed 50ms 99% latency increase, we should have seen about one 50ms request for each 100 requests sent.&lt;/p&gt;
&lt;p&gt;Then, I tried &lt;a href=&quot;https://support.microsoft.com/en-ca/help/314868/how-to-use-tracert-to-troubleshoot-tcp-ip-problems-in-windows&quot;&gt;tracert&lt;/a&gt;, maybe there was an issue with one of the hops requests were hitting on the way between Alvin and the client. However,  tracert came back empty-handed.&lt;/p&gt;
&lt;p&gt;So, it was not my code, gRPC implementation or the network causing the delays. I was starting to get worried I am never going to figure this out.&lt;/p&gt;
&lt;h3 id=&quot;now-which-os-are-we-on&quot;&gt;Now, which OS are we on&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; is widely adopted on Linux, however its Windows adoption is not even close. I decided to run the experiment that worked: I spun a Linux VM and compiled Alvin for Linux, and deployed it.  &lt;/p&gt;
&lt;p&gt;&lt;canvas class=&quot;js-chart&quot; width=&quot;400&quot; height=&quot;400&quot; data-chart=&quot;
    {
        &apos;data&apos;: [
            {
                &apos;label&apos;: &apos;Low QPS Baseline&apos;,
                &apos;data&apos;: [3,10,45,50]
            },
            {
                &apos;label&apos;: &apos;Windows Sample&apos;,
                &apos;data&apos;: [3,9,46,49]
            },
            {
                &apos;label&apos;: &apos;Linux Sample&apos;,
                &apos;data&apos;: [1,1.7,2.6,4.6]
            }
        ]
    }
    &quot; data-labels-chart = &quot;Avg,90th,95th,99th&quot; data-yaxis-name = &quot;Latency in Milliseconds&quot; data-xaxis-name = &quot;Latency Percentile&quot;&gt;&lt;/canvas&gt;&lt;/p&gt;
&lt;p&gt;Lo and behold: Linux ping-pong server didn‚Äôt have the latency issues of its Windows peer, despite using my source being the same. &lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt;‚Äôs Windows implementation had a problem.&lt;/p&gt;
&lt;h3 id=&quot;nagles-algorithm&quot;&gt;Nagle‚Äôs algorithm&lt;/h3&gt;
&lt;p&gt;All along, I had thought I was missing a &lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; flag, now I realized it might actually be &lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; that was missing a Windows flag. I searched an internal RPC library that I knew to behave well for all the &lt;a href=&quot;https://docs.microsoft.com/en-us/windows/desktop/winsock/windows-sockets-start-page-2&quot;&gt;Winsock&lt;/a&gt; flags it set. I then went ahead and added all of them to gRPC, and deployed Alvin on Windows, and that fixed Windows ping-pong server!  &lt;/p&gt;
&lt;p&gt;&lt;canvas class=&quot;js-chart&quot; width=&quot;400&quot; height=&quot;400&quot; data-chart=&quot;
    {
        &apos;data&apos;: [
            {
                &apos;label&apos;: &apos;Low QPS Baseline&apos;,
                &apos;data&apos;: [3,10,45,50]
            },
            {
                &apos;label&apos;: &apos;Windows Sample&apos;,
                &apos;data&apos;: [3,9,46,49]
            },
            {
                &apos;label&apos;: &apos;Linux Sample&apos;,
                &apos;data&apos;: [1,1.7,2.6,4.6]
            },
            {
                &apos;label&apos;: &apos;Windows Sample With Winsock Flags&apos;,
                &apos;data&apos;: [1.1,2.2,3,5]
            }
        ]
    }
    &quot; data-labels-chart = &quot;Avg,90th,95th,99th&quot; data-yaxis-name = &quot;Latency in Milliseconds&quot; data-xaxis-name = &quot;Latency Percentile&quot;&gt;&lt;/canvas&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Almost&lt;/em&gt; there: I removed the flags I added  one by one until regression returned, so that I could pin the one flag that made the difference. It was the infamous &lt;a href=&quot;https://docs.microsoft.com/en-us/windows/desktop/api/winsock/nf-winsock-setsockopt&quot;&gt;TCP_NODELAY&lt;/a&gt;, the switch for Nagle‚Äôs algorithm.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Nagle%27s_algorithm&quot;&gt;Nagle‚Äôs algorithm&lt;/a&gt; tries to decrease number of packets sent over the network, by delaying message transmission until outstanding size exceeds certain number of bytes. While this can be nice for the average user, this is devastating for real-time servers, as it means OS will delay some messages, causing the latency hikes observed under low QPS. &lt;code class=&quot;language-text&quot;&gt;gRPC&lt;/code&gt; had this flag on for its Linux implementation for TCP sockets, but not for Windows, I have fixed that with &lt;a href=&quot;https://github.com/grpc/grpc/commit/1dce1009e67ea4b5934a61b1bcf8a217bd12cc76&quot;&gt;1dce1009&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Latency was high at low QPS due to an OS optimization. In hindsight, profile did not catch the delays because they were on the Kernel side of things, not in &lt;a href=&quot;https://blog.codinghorror.com/understanding-user-and-kernel-mode/&quot;&gt;User Mode&lt;/a&gt;. I do not know if Nagle‚Äôs algorithm could be observed through ETW captures, but that would be interesting.&lt;/p&gt;
&lt;p&gt;As for the &lt;a href=&quot;#what-if&quot;&gt;localhost experiment&lt;/a&gt;, it probably did not touch actual network code, and Nagle‚Äôs algorithm was not triggered, hence latency issues went away when client called Alvin through localhost.&lt;/p&gt;
&lt;p&gt;The next time you see higher latency coinciding with lower QPS, Nagle‚Äôs algorithm should be on your checklist!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Help &lt;a href=&quot;https://github.com/aybassiouny/mahdytech&quot;&gt;improve this text&lt;/a&gt; or discuss it on &lt;a href=&quot;https://www.reddit.com/r/programming/comments/bntthh/more_is_sometimes_less_when_lower_load_can/&quot;&gt;reddit&lt;/a&gt;, &lt;a href=&quot;https://news.ycombinator.com/item?id=19894402&quot;&gt;hackernews&lt;/a&gt;.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[UMDH: Catching Slow Leaks Red-Handed]]></title><description><![CDATA[This language is lacking In garbage collecting So now I‚Äôve got a memory leak ‚ÄúMemory Leak‚Äù by Awesome If you manage memory on your own, it‚Ä¶]]></description><link>https://mahdytech.com/2019/03/25/umdh-slow-leaks/</link><guid isPermaLink="false">https://mahdytech.com/2019/03/25/umdh-slow-leaks/</guid><pubDate>Mon, 25 Mar 2019 12:00:32 GMT</pubDate><content:encoded>&lt;blockquote&gt;
&lt;p&gt;This language is lacking&lt;br&gt;
In garbage collecting&lt;br&gt;
So now I‚Äôve got a memory leak&lt;br&gt;
&lt;a href=&quot;https://awesomeinquotes.com/track/memory-leak&quot;&gt;‚ÄúMemory Leak‚Äù&lt;/a&gt; by Awesome&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you manage memory on your own, it is almost inevitable that some code, at some point, will mismanage memory. Memory leaks are one type of this mismanagement. They show the app allocated memory, but forgot to deallocate it.&lt;/p&gt;
&lt;p&gt;It is good to have an approximate idea how much memory an app is expected to use. This way, when the app misbehaves, we can refer to that baseline and measure the impact. Once a regression is confirmed, the tough task now is to investigate which part of the code caused that - and fix it. In my experience, finding memory bugs is orders of magnitude harder, than the eventual fix that, in many occasions, is a one-liner.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#backdrop&quot;&gt;Backdrop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#sure-xperfs-got-it&quot;&gt;Sure XPerf‚Äôs Got it&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#user-memory-heap-dump-umdh-for-the-rescue&quot;&gt;‚ÄúUser Memory Heap Dump‚Äù (UMDH) For the Rescue&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#so-whats-umdh&quot;&gt;So, What‚Äôs UMDH&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#how-to-run-it&quot;&gt;How to Run it&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#interpreting-umdh-output&quot;&gt;Interpreting UMDH Output&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#what-happened-next&quot;&gt;What happened next&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;backdrop&quot;&gt;Backdrop&lt;/h2&gt;
&lt;p&gt;One day, I found out one of my services, running in a cloud cluster, is using a couple hundred MBs more than expected. There was one issue that differentiated this from a standard memory leak: the leak took place excruciatingly slowly:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/040c8c489f31cd37aa520e9de5b48406/4971b/MemoryUsage.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 62.83783783783784%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAA7EAAAOxAGVKw4bAAABL0lEQVQ4y41Ti46EMAj0///UvWg2nrUvKMdQ63PXHMkI1naAKXY5Z4GVUm4gIpnn2bAsy8c90qAWQpAupfSVEEBCAOR3kgoitlcjfKqwrJnrs0aWRAlSZvGBZAlZfCTbExvhN7KdVKtg1sNkAEFQoDKsl1vLD0TwOOw8WmdhJWittn117djyVWTBpiJRCZxWBL83vUtYDu9nwoNlKqpNNm2iD8IpiFCUkhFXX3I8gRWVMLZbLibo/KvjoSOSllk4uO0wiE7IB6xrKNMqxDjAUkxC9oH2Wxf5N7aWY4yrHpWAV5Grpuot5sf4fikf55APxOUeX86cCJFtm0feM8KaJLDrevt74PEN3XZ1Qafd+6qlEr9eP/J+vw3jOOpFTRb3fS/DMMg0TeKck9YdiBr+AJ04A0PXt2bDAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Memory Usage&quot;
        title=&quot;&quot;
        src=&quot;/static/040c8c489f31cd37aa520e9de5b48406/fcda8/MemoryUsage.png&quot;
        srcset=&quot;/static/040c8c489f31cd37aa520e9de5b48406/12f09/MemoryUsage.png 148w,
/static/040c8c489f31cd37aa520e9de5b48406/e4a3f/MemoryUsage.png 295w,
/static/040c8c489f31cd37aa520e9de5b48406/fcda8/MemoryUsage.png 590w,
/static/040c8c489f31cd37aa520e9de5b48406/4971b/MemoryUsage.png 784w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;Note how the issue only materializes several days after running without restart, and even a week after, it only accounts for a 400 MB leak, a measly 1% of total app memory usage. (From here on, I refer to memory usage and &lt;a href=&quot;https://mahdytech.com/2019/01/05/task-manager-memory-info/&quot;&gt;private bytes&lt;/a&gt; interchangeably).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: fluctuations in memory at the healthy state the week before - the orange line - are caused by cache saturation and data reload. This does not make leak detection any easier as what looks like a leak might just be a heavier-than-usual data drop.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;sure-xperfs-got-it&quot;&gt;Sure XPerf‚Äôs Got it&lt;/h2&gt;
&lt;p&gt;XPerf is the first tool my hand goes for, but it didn‚Äôt work here. Ever tried to run an ETW capture for one hour? Probably not - because it is humongous. An hour under high QPS guarantees a file that is almost impossible to analyze or copy around in raw format. Even then, with the snail-paced leak at hand, one hour might not be enough. It could have too many false positives to judge where the leak is coming from.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: &lt;a href=&quot;https://peteronprogramming.wordpress.com/2017/11/01/compressing-etl-etw-output-files/&quot;&gt;peteronprogramming&lt;/a&gt; has a rather interesting work to improve on XPerf‚Äôs compression and file size overall. I am yet to try it myself, but let me know if you have!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;XPerf probably could have gotten the job done, &lt;em&gt;eventually&lt;/em&gt;. It has got great tools for heap analysis, and I am sure to cover it in a future post. For the case in hand though, it would not have accomplished the job efficiently enough. Note that a &lt;a href=&quot;https://social.msdn.microsoft.com/Forums/vstudio/en-US/c4801701-2fd8-428d-9d53-747d8e24ace5/how-to-use-xperf-in-buffering-mode-to-take-last-events?forum=wptk_v4&quot;&gt;circular buffer&lt;/a&gt; would not work for this too. While a circular buffer allows to limit the captured ETW log size, there is no way to know for sure that the past 10 minutes contained a significant lead to the leak.&lt;/p&gt;
&lt;h2 id=&quot;user-memory-heap-dump-umdh-for-the-rescue&quot;&gt;‚ÄúUser Memory Heap Dump‚Äù (UMDH) For the Rescue&lt;/h2&gt;
&lt;p&gt;Slow leaks are harder to catch using XPerf, because of the enormous generated files. That‚Äôs where UMDH shines best: it‚Äôs considerably lightweight to run over vast periods of time (think days). To achieve that, it provides &lt;em&gt;just&lt;/em&gt; enough information to diagnose a leak: how big were allocations that never got deallocated &amp;#x26; their callstack.&lt;/p&gt;
&lt;h3 id=&quot;so-whats-umdh&quot;&gt;So, What‚Äôs UMDH&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/umdh&quot;&gt;User Memory Heap Dump&lt;/a&gt; is a tool by Windows that attaches to alloc/dealloc functions in the heap manager, and &lt;a href=&quot;http://webcache.googleusercontent.com/search?q=cache:RNHg5CsRe9AJ:www.nynaeve.net/%3Fp%3D209+&amp;#x26;cd=7&amp;#x26;hl=en&amp;#x26;ct=clnk&amp;#x26;gl=ca&quot;&gt;records&lt;/a&gt; when a specific process calls those functions. It is possible to take snapshots of this recording, and diff those snapshots. The workflow of UMDH boils down to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;App starts up and allocates uninteresting stuff*&lt;/li&gt;
&lt;li&gt;We trigger first snapshot using UMDH before interesting stuff (leak) is expected to take place&lt;/li&gt;
&lt;li&gt;We wait (hours or days!). Once we are fairly confident leak has happened, we take a second snapshot&lt;/li&gt;
&lt;li&gt;We diff those snapshots. UMDH will show allocations that took place between first and second snapshot.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;*Note that if the leak happens on startup, it is possible to take just one snapshot, with no need for diffs. For startups leaks, however, XPerf might be a more suitable tool.&lt;/p&gt;
&lt;h3 id=&quot;how-to-run-it&quot;&gt;How to Run it&lt;/h3&gt;
&lt;p&gt;In order for &lt;code class=&quot;language-text&quot;&gt;UMDH&lt;/code&gt; to be effective, we need to turn on the global flag &lt;a href=&quot;https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/create-user-mode-stack-trace-database&quot;&gt;Create user mode stack trace database&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;gflags -i &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;process_name&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; +ust&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, we restart the target process if it is already running. We can &lt;em&gt;dump&lt;/em&gt; &lt;strong&gt;snapshots&lt;/strong&gt; of this recording through:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;umdh -pn:&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;process_name&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; -f:&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;dump_text_file&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Don‚Äôt forget to direct the environment variable &lt;code class=&quot;language-text&quot;&gt;_NT_SYMBOL_PATH&lt;/code&gt; to correct symbol resolution stores, otherwise stacktrace will be much less useful:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;set _NT_SYMBOL_PATH=SRV*d:\symbols\*http://msdl.microsoft.com/download/symbols;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;interpreting-umdh-output&quot;&gt;Interpreting UMDH Output&lt;/h3&gt;
&lt;p&gt;UMDH, although powerful in its own context, could definitely borrow a little brush up for its output from &lt;a href=&quot;https://mahdytech.com/2019/01/13/curious-case-999-latency-hike#XPerf&quot;&gt;WPA&lt;/a&gt;. The logged file is basically a list of allocations:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token number&quot;&gt;30&lt;/span&gt; bytes + &lt;span class=&quot;token number&quot;&gt;30&lt;/span&gt; at 206EDDA8BA0 by BackTraceEDD4EEA6
	7FFE82352933
	7FFE8226DA74
	7FFE822AD412
	7FFE822AD2FA
	7FFE822AD0FA
	7FFE7EDC7CAD
	7FFE70A8CA10
	7FFE70A95B63
	7FFE70A61109
	7FFE7F6CA6B3
	7FFE70A95E20&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A list of single allocations is not useful. To decipher it we need to run:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;umdh &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;snapshot_&lt;span class=&quot;token operator&quot;&gt;&lt;span class=&quot;token file-descriptor important&quot;&gt;1&lt;/span&gt;&gt;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;snapshot_&lt;span class=&quot;token operator&quot;&gt;&lt;span class=&quot;token file-descriptor important&quot;&gt;2&lt;/span&gt;&gt;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;analysis_log&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And the last step produces the analysis log we need:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;..&lt;/span&gt;
+  &lt;span class=&quot;token number&quot;&gt;154944&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;154944&lt;/span&gt; -      &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;      &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt; allocs	BackTrace9933FD81
+       &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;      &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt; -      &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;	BackTrace9933FD81	allocations

	ntdll&lt;span class=&quot;token operator&quot;&gt;!&lt;/span&gt;RtlWalkHeap+213
	ntdll&lt;span class=&quot;token operator&quot;&gt;!&lt;/span&gt;RtlAllocateHeap+A64
	KERNELBASE&lt;span class=&quot;token operator&quot;&gt;!&lt;/span&gt;LocalAlloc+6D
	SHELL32&lt;span class=&quot;token operator&quot;&gt;!&lt;/span&gt;SHGetItemFromDataObject+612
	SHELL32&lt;span class=&quot;token operator&quot;&gt;!&lt;/span&gt;SHCreateShellFolderView+1F4F
	SHELL32&lt;span class=&quot;token operator&quot;&gt;!&lt;/span&gt;SHCreateShellFolderView+A3D
	SHELL32&lt;span class=&quot;token operator&quot;&gt;!&lt;/span&gt;Ordinal915+14B4
	SHELL32&lt;span class=&quot;token operator&quot;&gt;!&lt;/span&gt;Ordinal915+FDE
&lt;span class=&quot;token punctuation&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;..&lt;/span&gt;.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Additionally, UMDH &lt;a href=&quot;https://github.com/Nettention/UmdhViz&quot;&gt;visualization tool by Nettention&lt;/a&gt; provides a great way to visualize analysis log:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/dc4ef1ebdddeee4c3b05c0386d9cb476/8ce52/vis.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.08108108108109%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABTUlEQVQoz32SwXKDIBCGefee2tfprdNe20NPpgkqAprYSCdCVcBoYtSu2nbMOJN/dhxw+faHBcTjr0QclJRFnqs0VXKMYSDzPO/7DtS2F1A7UzcKOZEUSmtTpplJlBZTfBtV2LIsgS8KfTxWdX2Crx3+HSEmofun7cNLcvecPmKtq8vBNNI2B3O29QUs9/uEUR5FWyUVkP2wk777E3p1vDeHvK+5kMWY6/qZlFK+T1bOarPGhBBr7XwNYgHhNNhvQ2sMzNsxMwXIWMsYJz5xXQ9j/PGxppRWVTWVQFCPBCQKIzj30lkbAzCYewPsCiGyLGua5teZBgHgABtjb8B4gzkPoc/zLAqAppQzXlV1v9A/7G4w4yFc2BUMe2aQZ+HpfL4NQ88XzoMxCxdVr2DPB3i3i6enMr2XoWG3YTPCLnYhSEDj+BOWQ5MY53DtP50maQvegHTjAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Visuallizing umdh output&quot;
        title=&quot;&quot;
        src=&quot;/static/dc4ef1ebdddeee4c3b05c0386d9cb476/fcda8/vis.png&quot;
        srcset=&quot;/static/dc4ef1ebdddeee4c3b05c0386d9cb476/12f09/vis.png 148w,
/static/dc4ef1ebdddeee4c3b05c0386d9cb476/e4a3f/vis.png 295w,
/static/dc4ef1ebdddeee4c3b05c0386d9cb476/fcda8/vis.png 590w,
/static/dc4ef1ebdddeee4c3b05c0386d9cb476/8ce52/vis.png 681w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;See, &lt;code class=&quot;language-text&quot;&gt;UMDH&lt;/code&gt; becomes most useful in comparison mode, where multiple &lt;strong&gt;snapshots&lt;/strong&gt; (starting point and endpoint) are captured and diff‚Äôd into an analysis log containing the allocations happening in between. This was immensely helpful in my case - I am not interested in the first 50 GB of expected allocations, but the unexpected extra 200 MBs.&lt;/p&gt;
&lt;h2 id=&quot;what-happened-next&quot;&gt;What happened next&lt;/h2&gt;
&lt;p&gt;With UMDH under my belt, the rest was straightforward. I ran it and took two snapshots, one after app startup and stabilizing of cache, and another &lt;strong&gt;one day&lt;/strong&gt; later. The size of the log? A mere dozen of MBs! That was specially the case because allocations are produced repeatedly by the same callstacks, so only the number of allocations is increasing. The offender laid there in top 5 allocation callstacks. It was a small object in a &lt;code class=&quot;language-text&quot;&gt;shared_ptr&lt;/code&gt; that, under special circumstances, gets a circular dependency on another &lt;code class=&quot;language-text&quot;&gt;shared_ptr&lt;/code&gt;. &lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;UMDH has a tightly stripped-down version of XPerf‚Äôs extended heap capturing capabilities. While not nearly as powerful, in several scenarios it is good enough.&lt;/p&gt;
&lt;p&gt;Note that &lt;code class=&quot;language-text&quot;&gt;UMDH&lt;/code&gt; might &lt;strong&gt;not&lt;/strong&gt; be of use if you can‚Äôt restart the process to enabling the user-mode callstack capture. For example, if the issue at hand happens rarely or is hard to reproduce, live debugging or XPerf might be a better idea.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Not all Async is Created Equal: How Using Async Correctly Increased Throughput by 4X]]></title><description><![CDATA[‚ÄúEverybody who learns concurrency thinks they understand it, ends up finding mysterious races they thought weren‚Äôt possible, and discovers‚Ä¶]]></description><link>https://mahdytech.com/2019/02/22/async-throughput-4x/</link><guid isPermaLink="false">https://mahdytech.com/2019/02/22/async-throughput-4x/</guid><pubDate>Fri, 22 Feb 2019 12:00:32 GMT</pubDate><content:encoded>&lt;blockquote&gt;
&lt;p&gt;‚ÄúEverybody who learns concurrency thinks they understand it, ends up finding mysterious races they thought weren‚Äôt possible, and discovers that they didn‚Äôt actually understand it yet after all.‚Äù - Herb Sutter&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I was recently bitten by the pain of getting async wrong - or rather, thinking I am doing async when I was not. It was refreshing to see how fixing one bug can have a big effect on app performance. As usual in my posts - this is a server application, trying its best to perform as well as possible.&lt;/p&gt;
&lt;p&gt;Contents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#lay-of-the-land&quot;&gt;Lay of the Land&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#setting-number-of-threads-in-processing-thread-pool-to-a-constant&quot;&gt;Setting Number of Threads in Processing Thread Pool to a Constant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#1-tls-and-cold-start-tls&quot;&gt;1. TLS and cold start {#TLS}&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2-reasoning-about-app-logic&quot;&gt;2. Reasoning about App Logic&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#first-try-blocking-async&quot;&gt;First Try: Blocking Async&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#wait-what-just-happened&quot;&gt;Wait, What Just Happened&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#what-it-takes-to-be-actually-async&quot;&gt;What it Takes to be &lt;em&gt;Actually&lt;/em&gt; Async&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#1-everything-is-a-callback&quot;&gt;1. Everything is a Callback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2-context-needs-to-be-carried-around&quot;&gt;2. Context Needs to be Carried Around&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;lay-of-the-land&quot;&gt;Lay of the Land&lt;/h2&gt;
&lt;p&gt;The application in hand followed a pretty straightforward pipeline for a server:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;IO Dispatcher receives a request&lt;/li&gt;
&lt;li&gt;IO Dispatcher Publishes Work to &lt;a href=&quot;https://docs.microsoft.com/en-us/windows/desktop/procthread/thread-pools&quot;&gt;Thread Pool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once a thread in the thread pool is ready:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Thread processes request&lt;/li&gt;
&lt;li&gt;Thread returns a response to IO Dispatcher&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;IO Dispatcher Returns Response&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/36c45de06cc3a267cc263058da58a4aa/295bd/Start.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 29.72972972972973%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAA7EAAAOxAGVKw4bAAABRElEQVQY04WQu3KbQBiFefXUeZsUsdNlUiaFhS0Z2SAhJPbCsgt4hSBBsr8sKjzjyv/MmVPszrlFfHLTNFFVFUor6tpQG8NisWC9Tui6hjbgym2DtZZoKXoSeWIVkIgjWlcB+oq6rnlcPXLsPesqphksvvMcyj1V+Lt5suTPlm3AfMvliqhw43ua3PSstwe0kgghkFISL2J836F8wXgZ6NqOYp9TyR6x93Ru4NftBlkM3D/ERN8fHHPKu/2Rn08d4/ljZe894zjSDjX2ZLicL7y+nYPAC/GfYPh7hkAdTmw2KdHt0vHl246vP0pu7krSLLvWndPNnKZZEBzI24SXydFYFzaMr2Z1SPm8cmSJRZd/ybIgOD/Y4z+G6Q3OI7tdgQnDa6VQoboKbGzFVqZsRYZ1FucaRGnY5WGaUqOkwegmGN3zH6AMvrtO37YsAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;ApplicationOverview&quot;
        title=&quot;&quot;
        src=&quot;/static/36c45de06cc3a267cc263058da58a4aa/fcda8/Start.png&quot;
        srcset=&quot;/static/36c45de06cc3a267cc263058da58a4aa/12f09/Start.png 148w,
/static/36c45de06cc3a267cc263058da58a4aa/e4a3f/Start.png 295w,
/static/36c45de06cc3a267cc263058da58a4aa/fcda8/Start.png 590w,
/static/36c45de06cc3a267cc263058da58a4aa/295bd/Start.png 667w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: the separation of dispatcher and processing ThreadPool is almost always a good idea. This way, we‚Äôre not blocking IO in case the processing is taking longer than it should.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For the rest of the article, I am going to ignore the IO dispatcher and focus on request processing, as this is where things are soon to get interesting. So far, the request processing has been synchronous with no blocking IO, and all in the world was good. It had a similar function signature to:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;Response &lt;span class=&quot;token function&quot;&gt;ProcessRequest&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Request request&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
    RequestProcessor &lt;span class=&quot;token function&quot;&gt;requestProcessor&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;request&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; requestProcessor&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;GetResponse&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that &lt;code class=&quot;language-text&quot;&gt;ProcessRequest&lt;/code&gt; is executed in parallel by several threads in a thread pool. The number of threads in the thread pool is set to a constant number at runtime - usually equal to the number of logical cores in the server, as is &lt;a href=&quot;https://blogs.technet.microsoft.com/markrussinovich/2009/07/05/pushing-the-limits-of-windows-processes-and-threads/&quot;&gt;usually recommended&lt;/a&gt;. For simplicity, let‚Äôs suppose we are running a server with 2 logical cores. Here‚Äôs request flow at this stage:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/9c7dfd1fe56733cb4212ebe9454f5016/41431/NormalProcessing.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 343px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.75675675675676%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB2ElEQVQoz42RW3PSUBSF+fE++cCzrz5ZdHQcdaa13joKtBBKuObCJYSLpiUhIYGakAQ+Q7CI7Th2zVmz95yz9t7rnJPhAJvNJo3zZUhT/8nwOmA4DRibAXGUKlhv1qku1aZrs6/bInN7uBcluHJC+obP1FlhuiHeTUjP1bmLu7VbZg6d3Q7SphHmYv1XcduSka0Ow/mE0XzMd8/gwNgfh3Ec76dF8a6JoAVIEz/JouSqYXIY00kadk2Fka1x5U0wvGvW6/V9hx1FQZYkNG1AW1apVS54+qbCk7cqQlOjWBuQFzVyxQIXdZ1idchZsUVVqFAqlVIKgkA+nyebze4c+r5PFEUpVysfZxHwTRwhtntc1mXOhQai2KVST4Y0enxtzQhXQVrnBwFBsMsdx0k+5fCRf0c/3NA1Aro/bpBGHupkyanUQR67yV6Abob8CxkeiIJVJiT+ry5j2zaLhYfnecxmNpZlYW5pWmluWSZOsv+o8BjV6ODNXWb2DNux07jl3J1jGAb9fp+MPtBQVQVd12lLCtVq9R4bYoNX5685Kr/gY/MLJ+J73l0ec1I/5UP9E7nyS46On5N7lnv4lftun3JPQOopNOQa1bZIuSWgDFQ+S2doy1Gq+wXkRznd5bmt4wAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Processing Overview&quot;
        title=&quot;&quot;
        src=&quot;/static/9c7dfd1fe56733cb4212ebe9454f5016/41431/NormalProcessing.png&quot;
        srcset=&quot;/static/9c7dfd1fe56733cb4212ebe9454f5016/12f09/NormalProcessing.png 148w,
/static/9c7dfd1fe56733cb4212ebe9454f5016/e4a3f/NormalProcessing.png 295w,
/static/9c7dfd1fe56733cb4212ebe9454f5016/41431/NormalProcessing.png 343w&quot;
        sizes=&quot;(max-width: 343px) 100vw, 343px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note that these are logical threads, not &lt;a href=&quot;https://stackoverflow.com/questions/5593328/software-threads-vs-hardware-threads&quot;&gt;hardware threads&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;Before moving on to how adding IO to request processing can make our lives harder, let‚Äôs address an important point. Is setting the number of processing threads to a constant number a good idea?&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&quot;setting-number-of-threads-in-processing-thread-pool-to-a-constant&quot;&gt;Setting Number of Threads in Processing Thread Pool to a Constant&lt;/h3&gt;
&lt;p&gt;This is an important detail in the design. We chose to set the number of processing threads in the thread pool to a specific number. This decision is backed by two reasons:&lt;/p&gt;
&lt;h4 id=&quot;1-tls-and-cold-start-tls&quot;&gt;1. TLS and cold start {#TLS}&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://mahdytech.com/2018/12/30/what-happens-when-you-press-x/#Just-don%E2%80%99t-bother-with-TLS&quot;&gt;Thread-Local Storage (TLS)&lt;/a&gt; can help &lt;a href=&quot;https://software.intel.com/en-us/articles/avoiding-heap-contention-among-threads&quot;&gt;alleviate heap contention&lt;/a&gt; among different cores. To achieve the best performance, TLS is allocated on thread creation, which leads to experiencing cold start latency hikes (unless warmup is used).&lt;/p&gt;
&lt;p&gt;Allocations, however, are not cheap. While it can be &lt;em&gt;okay&lt;/em&gt; to have sub-par performance during warmup, arbitrary large allocations during serving are not acceptable and will lead to unwanted latency hikes. If we don‚Äôt use a constant number of threads, QPS increases can trigger the pool manager to create new threads, causing latency hikes. In a perfect world, increased QPS should lead to increased CPU usage, not latency hikes.&lt;/p&gt;
&lt;h4 id=&quot;2-reasoning-about-app-logic&quot;&gt;2. Reasoning about App Logic&lt;/h4&gt;
&lt;p&gt;I find it easier to reason about an app‚Äôs logic when I know for sure how many threads are doing request processing. Allowing the thread pool to create &amp;#x26; delete new threads upon need means we are never really sure how many threads are there. Scheduling, as we are about to elaborate, becomes harder. This might not be as concrete as the first reason, but it has helped a lot in many debugging sessions.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: if you are using Windows thread pool, there‚Äôs a nifty trick to set the number of threads to a specific number, and that is to set both the minimum and the maximum number of threads. E.g.:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;SetNumberOfThreads&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;PTP_POOL ptpp&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; numOfThreads&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;token function&quot;&gt;SetThreadpoolThreadMaximum&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;ptpp&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; numOfThreads&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;token function&quot;&gt;SetThreadpoolThreadMinimum&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;ptpp&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; numOfThreads&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;At this point, the app was capable of handling 40k QPS per machine. That‚Äôs not too bad. Until it was desired to add a remote call within the &lt;code class=&quot;language-text&quot;&gt;ProcessRequest&lt;/code&gt; pipeline.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: for benchmarking throughput, I have used &lt;a href=&quot;https://httpd.apache.org/docs/2.4/programs/ab.html&quot;&gt;Apache Benchmark&lt;/a&gt; under Linux. For some reason, Windows version always has worse numbers. For the numbers reported here, I ran the command: &lt;code class=&quot;language-text&quot;&gt;ab -k -c &amp;lt;concurrency_level&gt; &amp;lt;endpoint&gt; -n 1000000&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&quot;first-try-blocking-async&quot;&gt;First Try: Blocking Async&lt;/h2&gt;
&lt;p&gt;Now that I needed to add the network IO call on the serving hot path, I started thinking, how to inject this into the workflow &lt;a href=&quot;#LayOfLand&quot;&gt;above&lt;/a&gt;? We need some way of stopping processing, do the IO, then continue after IO is done. At a first glance, it looks like a thread synchronization problem. Let‚Äôs consult what C++ has to offer.&lt;/p&gt;
&lt;p&gt;Suggestions for thread synchronization are almost always around using a &lt;code class=&quot;language-text&quot;&gt;std::promise&lt;/code&gt; and &lt;code class=&quot;language-text&quot;&gt;std::future&lt;/code&gt; combo in order to achieve synchronization between different threads. Visiting back our &lt;code class=&quot;language-text&quot;&gt;ProcessRequest&lt;/code&gt; code sample above, and applying suggested primitives, the function has evolved to:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;Response &lt;span class=&quot;token function&quot;&gt;ProcessRequest&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Request request&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
    std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;promise&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;IOResult&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; promise&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;future&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;IOResult&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; fut &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; promise&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;get_future&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token function&quot;&gt;DispatchIOAsync&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;promise&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;auto&lt;/span&gt; ioResult &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; fut&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    RequestProcessor &lt;span class=&quot;token function&quot;&gt;requestProcessor&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;request&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; ioResult&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; requestProcessor&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;GetResponse&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It was easy to add, and we didn‚Äôt have to change a lot of code. Great! it also totally does &lt;strong&gt;not&lt;/strong&gt; work, perf-wise. With those added 3 lines of code, we now go from 40k QPS all the way down to 8k QPS!&lt;/p&gt;
&lt;h3 id=&quot;wait-what-just-happened&quot;&gt;Wait, What Just Happened&lt;/h3&gt;
&lt;p&gt;Let‚Äôs take a second and reason about this. We have added an extra IO operation, which is a remote call to another machine. Hence, the majority of the added work is not done locally, but on another machine and (more importantly) in transport. Why did we lose so much throughput then? To visualize the issue, let‚Äôs have a look at how our threads work now:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/490389243ede85162a3475510b7befb3/3c024/AddingIO.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 573px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 34.45945945945946%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABYElEQVQoz4WQ2XKiYBCFef+XmbmZqniduAxgYtCIiKAWy09mWGQTNOKXX3JjbmZO1dfV1UvV6Va4kxef8SVxcSZr877WXTsZr/xLr7MZD4MBmqaj3DfCrKM5X/m4dOyLPdW5pDwV/E9JHGPbG0QUoSRJQpplCBEy0AKivwfe4xTVNXjZmDiRoGouJIcKX8SIP6mcyXpuuRcIfN+T+wLLslDyPKcoCor8gGpGaPMdk5nN88JhZARMzZAoCpk77wwNn/naQzU2jF9s9MWWqRWRZWlvyvO87ydfJGl1ReQNeuhSNFCfoJGcPqBsv/pJ2ZGVkNdfO/dSwjDs7W63O1zXwdvvsZwVP4yfrAML01ti+Svedgtc4SCSACeQF9g6r85MOtRRVzqaNWWkj1HatuXG8XikrmuqquIkLY23Ko/LEY+LIb9XKr/mDwzXE/mvgKE74cka8eaaaEu9R7ef5d+nfAJlLAkvoH1H0wAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Add IO&quot;
        title=&quot;&quot;
        src=&quot;/static/490389243ede85162a3475510b7befb3/3c024/AddingIO.png&quot;
        srcset=&quot;/static/490389243ede85162a3475510b7befb3/12f09/AddingIO.png 148w,
/static/490389243ede85162a3475510b7befb3/e4a3f/AddingIO.png 295w,
/static/490389243ede85162a3475510b7befb3/3c024/AddingIO.png 573w&quot;
        sizes=&quot;(max-width: 573px) 100vw, 573px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;Now, what if a 3rd request comes along?&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/11578ed459b37a1dc3f0b8e7c0f35eeb/ca12d/IOLimbo.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 43.91891891891892%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABwElEQVQoz42SW2+bQBCF/f9/UKuocqukSSs3cm3wBZvYBMrFGDA2Jtxhv2yI0+ShD53l6KDZs7PamTMQQgCCvGxxohI/rsirmrcQpqBrJToJ8c6i+wdkfvB2MM4Ex6zr/71shy+RdmeEIS/0JFL+Kwa+7xMFPvdzk29jC33rcKvOuZ7MmBkOoZ6gbwLUtcP8wUbRLFTdQpu57KY77ImNPbZ7nioKg+7y5LLu0O0TmhGgbFzmjzFr+8zejVlJ1u0jazOSxXas3JCHYcrp95lIDQknIck0oS5rBkVRkOc5WfZElmcy2TDeTWULjrJfDaVWUecVVVNRVpKLmqIrqVSJ+JLPC4qyIEkSBofDgSAM8TwPx3HYez7f13fcru4Yre4ZLX/xSb1CM1ds3A2flSt+LH7Kltxwrd7wRR2ibmeEfoCu6+9D+Rh5W2DGFkZsYioWduwQp0dOWYJ79vDSHYbxyGaxlWz2+r9D+WNZLOYLbNumri92ER+qj6D1Wqp9RbNv6IKOJmpgLfcSieZV/2KZ3jaapjEcfmW5XNK27Wu9F7+JTurksMySYBoQzSLi2ZGDemCv7EnnT722k6v3cv8JngFfEqdo9c3PQwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;IO Limbo&quot;
        title=&quot;&quot;
        src=&quot;/static/11578ed459b37a1dc3f0b8e7c0f35eeb/fcda8/IOLimbo.png&quot;
        srcset=&quot;/static/11578ed459b37a1dc3f0b8e7c0f35eeb/12f09/IOLimbo.png 148w,
/static/11578ed459b37a1dc3f0b8e7c0f35eeb/e4a3f/IOLimbo.png 295w,
/static/11578ed459b37a1dc3f0b8e7c0f35eeb/fcda8/IOLimbo.png 590w,
/static/11578ed459b37a1dc3f0b8e7c0f35eeb/ca12d/IOLimbo.png 647w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;*this limbo is the interval between submitting work to the thread pool, and a thread becoming ready to process this work.&lt;/p&gt;
&lt;p&gt;And this limbo is exactly why throughput had plummeted. The decisions to limit the number of threads &amp;#x26; using &lt;em&gt;IO Waits&lt;/em&gt; have come together to rack up our request waiting queue while other threads are just waiting for IO.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Side note on the performance of waits: I used to be under the impression that waits, such as &lt;code class=&quot;language-text&quot;&gt;std::future::get()&lt;/code&gt; are part of the cause for perf degradation, due to OS context switching to check if the condition has been satisfied or not. Upon doing a bit of homework, turns out OS actually does a good job with locks and IO waits. Waiting threads are kept waiting, until another thread signals that occurrence of the waited-for event, at which case the scheduler &lt;a href=&quot;https://docs.microsoft.com/en-us/windows/desktop/procthread/priority-boosts&quot;&gt;boosts&lt;/a&gt; the waiting threads‚Äô priority to make sure they get picked up soon after.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;what-it-takes-to-be-actually-async&quot;&gt;What it Takes to be &lt;em&gt;Actually&lt;/em&gt; Async&lt;/h2&gt;
&lt;p&gt;Doing IO within the hot path is an inevitable evil. CPUs are just faster. Which means, while IO is happening, CPU would just be sitting there, doing nothing. Unless we give it some work!&lt;/p&gt;
&lt;p&gt;Following the same request flow model from above, our goal is to achieve something close to:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/b6a4f398e47e4908dce7c66056a3557b/dba9a/Solution.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 35.810810810810814%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABXklEQVQoz42OX0/iQBTF+/0/gC/6RoxrfNNkYzQxq0ZAotkF7G6lLW2RhVI67UwB0cj05/inyoMPnpvJzL3nzD3HKsuSF2hza23e7305L1l5K3Ss0Qv9NjNcpa9Q9RVnVYPHJ004WTLJHlFP9yCNKDYmpkpdfnz46rDmYVWG0qQYybck4f2A4XCIHEm+g5LPlFYcx0yTCe1/fY5bAW3b57xzw+Wpj3MQEV73CZoBzmmP5u8WV+41DfuSpt3iwq7jeLdEQYTrunS7Xax1p3G2JBoX/IkGRKMF0n9g4c5Z+guUo8xsQCBDvMTDFz5+HrAytQ5LKUmW5yRJQppOkZnk2DshkQnFTCGU4H+akqk5qigQhk+EJB1KimlBnuaIiSAf5wRugDWbzVDKCIUwC9PXhe2wQ62xw8avTXaau2zXjzis96kd2tR+ttk/+0tjPyL60ae30cPZcvD2PAYXdzwD7s0NgkuHL7MAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Solution&quot;
        title=&quot;&quot;
        src=&quot;/static/b6a4f398e47e4908dce7c66056a3557b/fcda8/Solution.png&quot;
        srcset=&quot;/static/b6a4f398e47e4908dce7c66056a3557b/12f09/Solution.png 148w,
/static/b6a4f398e47e4908dce7c66056a3557b/e4a3f/Solution.png 295w,
/static/b6a4f398e47e4908dce7c66056a3557b/fcda8/Solution.png 590w,
/static/b6a4f398e47e4908dce7c66056a3557b/dba9a/Solution.png 652w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;To put it in words, we‚Äôd like to replace wait time by actually doing some work. This is achieved through &lt;a href=&quot;https://luminousmen.com/post/asynchronous-programming-cooperative-multitasking&quot;&gt;Cooperative Scheduling&lt;/a&gt;. Basically, instead of thread &lt;code class=&quot;language-text&quot;&gt;T1&lt;/code&gt; waiting for an IO to end then execute a function &lt;code class=&quot;language-text&quot;&gt;foo&lt;/code&gt;, we pass &lt;code class=&quot;language-text&quot;&gt;foo&lt;/code&gt; as a callback to the IO call and ask the dispatcher to execute this callback once IO is done. Now, &lt;code class=&quot;language-text&quot;&gt;T1&lt;/code&gt; is free to handle more requests with no wait.&lt;/p&gt;
&lt;p&gt;Unfortunately, achieving this is not straightforward. Two major changes need to be applied:&lt;/p&gt;
&lt;h3 id=&quot;1-everything-is-a-callback&quot;&gt;1. Everything is a Callback&lt;/h3&gt;
&lt;p&gt;We cannot have functions with the signature &lt;code class=&quot;language-text&quot;&gt;Response ProcessRequest(Request request)&lt;/code&gt; anymore. These need to be overhauled, and replaced with:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;using&lt;/span&gt; ResponseCallback &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;function&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Response&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;ProcessRequest&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Request request&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; ResponseCallback callback&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note how the return type &lt;code class=&quot;language-text&quot;&gt;Response&lt;/code&gt; got transformed into an input parameter in the callback &lt;code class=&quot;language-text&quot;&gt;std::function&amp;lt;void(Response)&gt;&lt;/code&gt;. This way, any thread can return the response, by calling the callback.&lt;/p&gt;
&lt;p&gt;This is the biggest hurdle I had faced, as it requires changing signatures everywhere. If during design, you see doing IO on the hot path in the future of an app, I would highly recommend starting off with signatures supporting callbacks. Doing that later on is painful.&lt;/p&gt;
&lt;h3 id=&quot;2-context-needs-to-be-carried-around&quot;&gt;2. Context Needs to be Carried Around&lt;/h3&gt;
&lt;p&gt;With callbacks - lifetimes become all the more difficult. Not only do objects have to live in the current parentheses context - but we have to be careful to capture them in the callback, in case they are used. For example, &lt;code class=&quot;language-text&quot;&gt;Request&lt;/code&gt; object from before probably needs to be kept alive until the very last callback is called.&lt;/p&gt;
&lt;p&gt;While lambda captures and &lt;code class=&quot;language-text&quot;&gt;std::function&lt;/code&gt; should do a good job of keeping objects alive, I would suggest using an encapsulating context object instead of managing lifetimes one by one. In my case, I created a &lt;code class=&quot;language-text&quot;&gt;RequestContext&lt;/code&gt; object that encapsulated all objects need to be kept alive while serving a request.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;With the last two points in mind, our prototype now becomes:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;ProcessRequest&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;Request request&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; ResponseCallback callback&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;auto&lt;/span&gt; requestContext &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;token generic-function&quot;&gt;&lt;span class=&quot;token function&quot;&gt;make_shared&lt;/span&gt;&lt;span class=&quot;token generic class-name&quot;&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;RequestContext&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;request&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;auto&lt;/span&gt; ioCallback &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; 
        &lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;requestContext &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;move&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;requestContext&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;IOResult ioResult&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
        RequestProcessor &lt;span class=&quot;token function&quot;&gt;requestProcessor&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;move&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;requestContext&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;move&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;ioResult&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;token function&quot;&gt;callback&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;requestProcessor&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;GetResponse&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;token function&quot;&gt;DispatchIOAsync&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;ioCallback&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After applying similar changes, the app was back on track. Latency stayed the same, but throughput under high concurrency levels could now reach about 30k QPS!&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The major defining factor here has been our static number of processing threads in the thread pool. Adding more threads might have solved the problem, but I would argue against that. It would be hard (and hardware dependent) to find the best number. We have already discussed setting that &lt;a href=&quot;#TLS&quot;&gt;dynamically&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Cooperatively-scheduling our threads to yield on IO blocks allow us to process much more requests per second, with no reprimands for latency. Nonetheless, It is unfortunate that there is no standard support yet to make this process easier. &lt;a href=&quot;https://stackoverflow.com/questions/43503656/what-are-coroutines-in-c20&quot;&gt;Coroutines&lt;/a&gt; are promising, and although they are not standardized yet, they already have MSVC and Clang implementations.&lt;/p&gt;
&lt;p&gt;Let me know what you think &lt;a href=&quot;https://twitter.com/aybassiouny&quot;&gt;@aybassiouny&lt;/a&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Wielding Debug Builds against Heap Corruption]]></title><description><![CDATA[Heap corruptions can be nasty to investigate. I recently had to investigate a bug that manifests under special circumstances in production‚Ä¶]]></description><link>https://mahdytech.com/2019/02/10/heap-corruption-debug-build/</link><guid isPermaLink="false">https://mahdytech.com/2019/02/10/heap-corruption-debug-build/</guid><pubDate>Sun, 10 Feb 2019 12:00:32 GMT</pubDate><content:encoded>&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Memory_corruption&quot;&gt;Heap corruptions&lt;/a&gt; can be nasty to investigate. I recently had to investigate a bug that manifests under special circumstances in production. Crashes had all flavors of stack traces - the trademark of heap corruption. To debug it, I ran the usually recommended tool for heap corruption: PageHeap.&lt;/p&gt;
&lt;h2 id=&quot;enabling-pageheap&quot;&gt;Enabling PageHeap&lt;/h2&gt;
&lt;p&gt;PageHeap is an OS flag that adds an extra special buffer after each allocation, allowing to detect instructions that overrun their buffer and signal that to an attached debugger (such as Windbg, Visual Studio, cdb). &lt;/p&gt;
&lt;p&gt;There used to be a separate app for that: &lt;a href=&quot;https://support.microsoft.com/en-us/help/286470/how-to-use-pageheap-exe-in-windows-xp-windows-2000-and-windows-server&quot;&gt;PageHeap.exe&lt;/a&gt;. However, it has been &lt;a href=&quot;https://blogs.technet.microsoft.com/yongrhee/2010/06/17/how-to-enable-pageheap-against-a-process-such-as-print-spooler/&quot;&gt;deprecated&lt;/a&gt; in favor of two new tools: &lt;a href=&quot;https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/application-verifier&quot;&gt;Application Verifier&lt;/a&gt; or &lt;a href=&quot;https://docs.microsoft.com/en-us/windows-hardware/drivers/debugger/gflags-and-pageheap&quot;&gt;GFlags&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/c73d348cd11ad6acfd1f642ea8d07270/b2982/AppVerify1.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.75675675675676%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABj0lEQVQoz5VT2U7DQAzM/38Gv8JDJRAgofRM0jTZbAi5S9OcTQfbpRyiCLA08m48ttYex8iyHDmhLEuURYmmafAfG8dRcDweMQwDjMf5EvP5AqZpYjadwXEcLBZLrFYWVsuV3G379M2yrA9Q3PN9BEEApQIEhKIoYKxdmwi2BLTW8ImkfCVezkoh1KHEbZt5WpL5e5IkyPMcWZaJl4JMcN0NqqpCXdcXUe33MpIwfBLubkfcpqWcPXaEal+j3G4RxwmMKHqGt/GkYN/3aNsWXdcJzueGfJpmcnfolRvH+jbLvq2hqAuDyWfjwX628519Ri0NfYv7mYOraxc37hYTp8Sd7nCre5iqxJPmgm+qctIlnJQ8yoyahl9oYakSTMwNrh8sTGY+pvoFdpjRrP9ccJSC3DIL47trSjicF4ezMQ49iZR+bfkn47J5XogInufJmgyH8T3GdqA7j8VgMXghu64XUS6BheGCvB5ccEuKcg6D4+y5U3khE7md38A7xkjTVFYojmNZ+CiKZB/5B+DzKyEhRmScXET7AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;ApplicationVerifier&quot;
        title=&quot;&quot;
        src=&quot;/static/c73d348cd11ad6acfd1f642ea8d07270/fcda8/AppVerify1.png&quot;
        srcset=&quot;/static/c73d348cd11ad6acfd1f642ea8d07270/12f09/AppVerify1.png 148w,
/static/c73d348cd11ad6acfd1f642ea8d07270/e4a3f/AppVerify1.png 295w,
/static/c73d348cd11ad6acfd1f642ea8d07270/fcda8/AppVerify1.png 590w,
/static/c73d348cd11ad6acfd1f642ea8d07270/b2982/AppVerify1.png 729w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;Application Verifier allows specifying a set of tests to run and signal in case of error - including &lt;code class=&quot;language-text&quot;&gt;PageHeap&lt;/code&gt; from &lt;code class=&quot;language-text&quot;&gt;Basics -&gt; Heaps&lt;/code&gt;. &lt;code class=&quot;language-text&quot;&gt;gflags&lt;/code&gt; can  achieve this through: &lt;code class=&quot;language-text&quot;&gt;gflags /p /enable notepad.exe /full&lt;/code&gt;. &lt;/p&gt;
&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;
&lt;p&gt;It was not very fruitful. Before applying the PageHeap, I used to get random crashes. Now, I was getting consistent crashes, &lt;strong&gt;once I access already corrupted memory&lt;/strong&gt;. I was closer, but finding &lt;em&gt;when&lt;/em&gt; the memory was getting corrupted was still some tedious debugging away. Unless ‚Ä¶&lt;/p&gt;
&lt;h2 id=&quot;wielding-debug-builds&quot;&gt;Wielding Debug Builds&lt;/h2&gt;
&lt;p&gt;I had an idea. Debug builds are notoriously slow for a reason - they do too many checks, and that‚Äôs exactly what I needed now. I rebuilt in debug &amp;#x26; deployed, and voila! The app was throwing exactly where the problem was happening. The problem had to do with misuse of a custom allocator that was freeing its memory without destructing underlying objects. Later on, the kernel would &lt;a href=&quot;https://mahdytech.com/2019/01/05/task-manager-memory-info/&quot;&gt;reclaim&lt;/a&gt; that space, at a  random moment, and accessing that structure would trigger a crash. &lt;/p&gt;
&lt;p&gt;Standard library and most &lt;em&gt;well-written&lt;/em&gt; library enforce debug-mode checks for insecure code. Usually, Unit Tests catch these errors, but we‚Äôre not always that lucky. For example, Visual C++ does boundary checks in this constructor of &lt;code class=&quot;language-text&quot;&gt;std::vector&lt;/code&gt;: &lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;language-cpp&quot;&gt;&lt;pre class=&quot;language-language-cpp&quot;&gt;&lt;code class=&quot;language-language-cpp&quot;&gt;template&amp;lt;class _Iter, class = enable_if_t&amp;lt;_Is_iterator_v&amp;lt;_Iter&amp;gt;&amp;gt;&amp;gt;
vector(_Iter _First, _Iter _Last, const _Alloc&amp;amp; _Al = _Alloc())
: _Mybase(_Al)
{	// construct from [_First, _Last) with optional allocator
    _DEBUG_RANGE(_First, _Last);
    _Range_construct_or_tidy(_Unchecked(_First), _Unchecked(_Last), _Iter_cat_t&amp;lt;_Iter&amp;gt;{});
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Where &lt;code class=&quot;language-text&quot;&gt;_DEBUG_RANGE&lt;/code&gt; will do range checks in debug mode only. In my case, it was ref-counting checks that manifested the problem. Either way, &lt;/p&gt;
&lt;h2 id=&quot;final-words&quot;&gt;Final Words&lt;/h2&gt;
&lt;p&gt;Running an app in debug mode is not straightforward. That‚Äôs especially true if there‚Äôs a lot of data loading involved or the app is a memory-hungry monster, as the startup can go from 5 min to hours. Here, I would recommend separating the app from the data loading logic. &lt;/p&gt;
&lt;p&gt;Debug mode can be a lifesaver!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Spawning Your First C++ Fleet with Service Fabric and REST SDK]]></title><description><![CDATA[I have mostly been working on the details of rather big projects, and that can make one lose touch with end-to-end magic. This week I‚Ä¶]]></description><link>https://mahdytech.com/2019/02/04/spawning-first-restful-c-fleet-with-service-fabric-rest-sdk/</link><guid isPermaLink="false">https://mahdytech.com/2019/02/04/spawning-first-restful-c-fleet-with-service-fabric-rest-sdk/</guid><pubDate>Mon, 04 Feb 2019 12:00:32 GMT</pubDate><content:encoded>&lt;p&gt;I have mostly been working on the details of rather big projects, and that can make one lose touch with end-to-end magic. This week I decided to create a very simple distributed C++ web app, running on an Azure fleet. I settled on using Service Fabric as a distributed framework and CPPREST SDK for building the C++ web server. This is how it went!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#service-fabric&quot;&gt;Service fabric&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#how-to-get-it&quot;&gt;How to Get it&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#how-to-run-it&quot;&gt;How to Run it&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#lets-move-to-the-cloud&quot;&gt;Let‚Äôs move to the cloud&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#who-said-c-is-ancient-cpp-rest-sdk&quot;&gt;Who said C++ is ancient: CPP Rest SDK&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#interlude-vcpkg&quot;&gt;Interlude: vcpkg&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#a-rest-web-server&quot;&gt;A REST web server&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#putting-it-together&quot;&gt;Putting It Together&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#credentials&quot;&gt;Credentials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#certificates&quot;&gt;Certificates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#port-listening-error&quot;&gt;Port Listening Error&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#final-result&quot;&gt;Final Result&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#last-words&quot;&gt;Last Words&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;service-fabric&quot;&gt;Service fabric&lt;/h2&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/91003347c8e6f9c8cc5bef66bb0e6307/a34d8/SF.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 542px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 60.810810810810814%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAECAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHu01CST//EABgQAAIDAAAAAAAAAAAAAAAAAAECABEg/9oACAEBAAEFAmNQPn//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAVEQEBAAAAAAAAAAAAAAAAAAAQQf/aAAgBAgEBPwGn/8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGxAAAQQDAAAAAAAAAAAAAAAAEQAgITFBYYH/2gAIAQEAAT8hAx1EEXtv/9oADAMBAAIAAwAAABBzD//EABYRAQEBAAAAAAAAAAAAAAAAABEBEP/aAAgBAwEBPxBgGf/EABcRAAMBAAAAAAAAAAAAAAAAAAERIRD/2gAIAQIBAT8QRpzP/8QAGhABAQADAQEAAAAAAAAAAAAAAREAECExcf/aAAgBAQABPxBTTpZVA+43c+ilWMppB9MACBNf/9k=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Service Fabirc&quot;
        title=&quot;&quot;
        src=&quot;/static/91003347c8e6f9c8cc5bef66bb0e6307/a34d8/SF.jpg&quot;
        srcset=&quot;/static/91003347c8e6f9c8cc5bef66bb0e6307/a80bd/SF.jpg 148w,
/static/91003347c8e6f9c8cc5bef66bb0e6307/1c91a/SF.jpg 295w,
/static/91003347c8e6f9c8cc5bef66bb0e6307/a34d8/SF.jpg 542w&quot;
        sizes=&quot;(max-width: 542px) 100vw, 542px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-overview&quot;&gt;Service Fabric&lt;/a&gt; is an Azure distributed platform solution. It manages orchestration &amp;#x26; packaging without the need for containerization. In other words, only binaries are provided to the framework, and it takes care of uploading them to all the machines in the &lt;a href=&quot;https://whatis.techtarget.com/definition/cluster&quot;&gt;cluster&lt;/a&gt; in a safe manner. Running an app on a whole fleet of VMs with several clicks is rather empowering - and Service Fabric allows for that.&lt;/p&gt;
&lt;p&gt;Service Fabric is pretty simple to start on and has got good integration with Visual Studio. In my experience though, there are always some knobs that need to be turned before things are working as they are supposed to - more on that later.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: &lt;a href=&quot;https://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt; is usually &lt;a href=&quot;https://blogs.msdn.microsoft.com/azuredev/2018/08/15/service-fabric-and-kubernetes-comparison-part-1-distributed-systems-architecture/&quot;&gt;what comes to mind&lt;/a&gt; when Service Fabric is mentioned, as a very popular orchestrator. However, my experience with containers on windows is pretty bleak, so I went with Service Fabric.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;how-to-get-it&quot;&gt;How to Get it&lt;/h3&gt;
&lt;p&gt;Two main steps are needed to create a Service Fabric app in Visual Studio:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.microsoft.com/web/handlers/webpi.ashx?command=getinstallerredirect&amp;#x26;appid=MicrosoftAzure-ServiceFabric-CoreSDK&quot;&gt;Grab SDK &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Make sure Visual studio has &lt;a href=&quot;https://visualstudio.microsoft.com/vs/support/selecting-workloads-visual-studio-2017/&quot;&gt;Azure Development&lt;/a&gt; workload&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;I recommend starting off with Visual Studio, at least to get a look at required config files and standard deployment pipeline. Later on, Visual Studio can be discarded in favor of Configs &amp;#x26;  PowerShell scripts.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;how-to-run-it&quot;&gt;How to Run it&lt;/h3&gt;
&lt;p&gt;Service Fabric has deep support for .Net and various web technologies, offering &lt;a href=&quot;https://www.bizety.com/2018/08/21/stateful-vs-stateless-architecture-overview/&quot;&gt;stateful&lt;/a&gt; services support and more. Nonetheless, C++ devs, don‚Äôt despair. It still allows for a &lt;code class=&quot;language-text&quot;&gt;Guest Executable&lt;/code&gt; project type, where Service Fabric just needs triggering command to run the service, and that‚Äôs it.&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/b4c13403f9420868962891561c75cc88/8d7b0/ServiceFabricVS.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 34.45945945945946%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAB2HAAAdhwGP5fFlAAABn0lEQVQozx2RzW7TQBSF/YQUsYBFX4cHgaIUiQokNjwAbCoFWtT82nGcOPG/x/bM+C9Oiz4mXhzduzj3zDlnrM0+IowLStUjZGtmhygkaSooS0XXD5yGZ7RuCZISpbtxr+tuhFQ1yuDCG87PWL+XRxZehpd0uFFtZovnR9jrDVmam+PaHDYURUkQC3PcoI2ArDRSavNwThynKFlz6s9YKy9m5Qbso4pjqgmzhp1/YLudGXJGFEXjvAh2XUfTNLRtS54LhBAcjxGPjzPm8zXLpYPlbn3mTwsc2yU3MaVsiIMjVegispQsiSiFcVoVDF3DuW95GXpUabgGIi/xvAO+H7LbHbAuMRzHY2UixokwcVr+Lra8n/zk3e2G688O17c2Vx9WXN04vL6xefXR5u3E4c0nm6lX0Nem+6oZzViZUKNt190ThOkoOF+5TH784utDwN3UH/FlemBy73H3J+D7LOPbYzju+0Qap8p8pDK1KKw0l0RGaL12TVeFKb01/e14mN7TVjkyDamLZMS/XsO5g5cTgy45qYJaN6NYWeoR/wF61f6Bu6gUJgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Service Fabric Project&quot;
        title=&quot;&quot;
        src=&quot;/static/b4c13403f9420868962891561c75cc88/fcda8/ServiceFabricVS.png&quot;
        srcset=&quot;/static/b4c13403f9420868962891561c75cc88/12f09/ServiceFabricVS.png 148w,
/static/b4c13403f9420868962891561c75cc88/e4a3f/ServiceFabricVS.png 295w,
/static/b4c13403f9420868962891561c75cc88/fcda8/ServiceFabricVS.png 590w,
/static/b4c13403f9420868962891561c75cc88/efc66/ServiceFabricVS.png 885w,
/static/b4c13403f9420868962891561c75cc88/c83ae/ServiceFabricVS.png 1180w,
/static/b4c13403f9420868962891561c75cc88/8d7b0/ServiceFabricVS.png 1723w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    

  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/277742e23c2671767e420785941b59b2/c0566/GuestExecutable.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 29.054054054054056%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABDklEQVQY02VPgXKDIBTz/7/P2WnnrFpFQLSICHSnGbB1t265yz0ux8tLEso4ArkQIKTHNE0wxsBaG6dzDgHHsWNgAsV7g6rx/+QKqS2WzaEjFGmaom1bJKStQb2RoARd32McR7984C+CRijDKX/D67n0JgyzVJBqi3qe5+j9fjKXGdzMYcnl93Y0ePCBrutwyjKciyLOpqnBKAVjLAbhnCNJXzIIX1OtOvjgf7avAwEhQVmWoD6RlAvksmD5ppQS8zz7ypcSglEcdsPx4bCH6ayn8W9/5O5+Kg/DgKqqYiK1rlBKPfF2k0jsUOMuBXRfw0wMhl6xjQSG99CkhvVawL7vsVJoo7XG6g2fqWPKTxzYyX2NDjkvAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Guest Executable in Service Fabric&quot;
        title=&quot;&quot;
        src=&quot;/static/277742e23c2671767e420785941b59b2/fcda8/GuestExecutable.png&quot;
        srcset=&quot;/static/277742e23c2671767e420785941b59b2/12f09/GuestExecutable.png 148w,
/static/277742e23c2671767e420785941b59b2/e4a3f/GuestExecutable.png 295w,
/static/277742e23c2671767e420785941b59b2/fcda8/GuestExecutable.png 590w,
/static/277742e23c2671767e420785941b59b2/efc66/GuestExecutable.png 885w,
/static/277742e23c2671767e420785941b59b2/c83ae/GuestExecutable.png 1180w,
/static/277742e23c2671767e420785941b59b2/c0566/GuestExecutable.png 1544w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Create a Guest Exceutable Service Fabric app in Visual Studio&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;After creating the project and adding the path to binaries - running the project deploys the app to a local virtual cluster, simulating an actual cluster to a large extent. Make sure to have your Service Fabric Local Cluster manager &lt;a href=&quot;https://stackoverflow.com/questions/42510388/how-to-start-local-azure-service-fabric-cluster-with-powershell-or-cli&quot;&gt;turned on&lt;/a&gt; first.&lt;/p&gt;
&lt;p&gt;The cluster manager includes the dashboard, which is pretty cool. It shows the overall metrics of the cluster. For example:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/777e860c518b24dae2b6c4f01b182268/5b4a1/localSFDashboard.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 79.05405405405406%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAB2GAAAdhgFdohOBAAACsklEQVQ4y31Ua3ObMBD0X2iT+AUIJBBP8TJgMDiOaZJpptPp//8325PcuE2myYcdxN5x0q32WDS7Gk1dIU1TFEWBsiwRhiEsy4LjONhsNua53W5h2TYYY4azaa1z1uv1GyzCqocse2xtBzKQYA6D6zLEcWQK6w/jODZFPc7NWhcPggBCCFNcv+unxkLlFVRRmYQg8P88A/i+b/C67rrO4LWL15iU8g0W+6FG2zZIksQQ+lT/Q9M02O/3pphS6sO8xXTemeQ8z83umny/q+Z0PMuyawfvc64nHO9bjOPBJEdR9OHOWrvP4tcTci7MwuMeiczBNfhfaO4z/gJx5Rf6JaDb3awc3HxZY7XU17/CanXB3e0at183uLuh2D/88m5tYsslrVdLwxnbKJWj7ciLR47yYEFGHJ4rjHX06ZOCoZ4sqMYB9zTvwvNcqNZGOdqQvocyVQhIP22fBfd85C1De3KxGzlOv2ykhW+KxolE/0j8QWB4Yjg8eXAZR14oDNOOinqYzi7mcURRVbB0QW2Xx8cnCE+Cswiq8jF+d2BtGOb5DJUVYLaAcCNMP8j8MTO2OYw9kpxjfHZwvO/JISVNDhXUE/FtfqIpCUnLkG5S0oc2HNvFNE04DBOKMjebDc+Mirg0TRd52gcbQciRpJGZMtOylCF2fYys9BFGAcYX0qan1hyBTMXoTym1SGg4jj9tc6Ma1YGheXCQkub7ckfyJJeCQgRQtaBCDk4/LzrKIDI2MhNyb+NIrU4vLrI8NBqWVY6+7xFltAlpOx9H4uqLhvMwomtLzKcTun2HYeiR0s3XZOSH8Yi+q3A+ndG0Nek2mNNlKsH93KEeBPqZLmvsoN1iNEzJ/VJSUhZDkAV0267nISCThqRLFJEUYWBiPv089O+LMRdpvUXRW2R4zV+MrVv+DUtR0gI7GRQhAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Service Fabric Dashboard&quot;
        title=&quot;&quot;
        src=&quot;/static/777e860c518b24dae2b6c4f01b182268/fcda8/localSFDashboard.png&quot;
        srcset=&quot;/static/777e860c518b24dae2b6c4f01b182268/12f09/localSFDashboard.png 148w,
/static/777e860c518b24dae2b6c4f01b182268/e4a3f/localSFDashboard.png 295w,
/static/777e860c518b24dae2b6c4f01b182268/fcda8/localSFDashboard.png 590w,
/static/777e860c518b24dae2b6c4f01b182268/5b4a1/localSFDashboard.png 831w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;One thing to note is to &lt;code class=&quot;language-text&quot;&gt;return -1;&lt;/code&gt; in the failure cases. When an app ends with non-zero exit status, Service Fabric understands that the app failed and signals that to the dashboard (or any monitoring setup!).&lt;/p&gt;
&lt;h3 id=&quot;lets-move-to-the-cloud&quot;&gt;Let‚Äôs move to the cloud&lt;/h3&gt;
&lt;p&gt;Now that we have got our local app running locally, let‚Äôs move where everyone has access! Service Fabric supports on-premise (non-Azure) clusters, but for the sake of getting started, it‚Äôs easier to test on Azure. Microsoft has a decent &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-cluster-creation-via-portal&quot;&gt;tutorial&lt;/a&gt; on how to create the cluster from the Azure Portal, on top I have the following notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For a first-time test, don‚Äôt get the cheapest machine - &lt;a href=&quot;https://support.microsoft.com/en-us/help/17463/windows-7-connect-to-another-computer-remote-desktop-connection&quot;&gt;RDPing&lt;/a&gt; into that would be a nightmare. I rather recommend getting a single instance to start with but of decent perf. I got a single &lt;code class=&quot;language-text&quot;&gt;DS2_v2&lt;/code&gt; while doing my tests.&lt;/li&gt;
&lt;li&gt;After primary tests pass, you can cheapen on the model and increase the number of nodes.&lt;/li&gt;
&lt;li&gt;Pay attention to &lt;code class=&quot;language-text&quot;&gt;Status&lt;/code&gt; in the portal. It is not articulated but it‚Äôs &lt;a href=&quot;https://octopus.com/blog/service-fabric-cluster-targets#gotcha-1-the-initial-wait-time&quot;&gt;a major indicator of what‚Äôs happening&lt;/a&gt;. For example, after creating the cluster for the first time, although Azure deployment shows it‚Äôs done, the cluster is not actually usable until &lt;code class=&quot;language-text&quot;&gt;Status&lt;/code&gt; reads &lt;code class=&quot;language-text&quot;&gt;Ready&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/2d356db68b474a4a1a7a88dc3f1c8532/701e9/Ready.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 30.405405405405407%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAB2HAAAdhwGP5fFlAAAAqUlEQVQY022Q2w7CIAxA+f8f9EVnjBuTi4zruBURo06jnIcmtD1tCpJKa60yQMxgAoQEtx7liy2JlkVfhfIht1ytHS2l5L0HgPrmI3NJmBTGPx61h5QSY6yUCiG0ETnnrRMxstPL6TmvKwshKKXWWmOMc6t1DqC85JmZiWqmgg19OcbYdrZT/0voPI774ThOeJ4vDULITx/nfBgO+MLaaWotxpcWpSvtk+6Zk14wDsCmLwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Status on Service Fabric&quot;
        title=&quot;&quot;
        src=&quot;/static/2d356db68b474a4a1a7a88dc3f1c8532/fcda8/Ready.png&quot;
        srcset=&quot;/static/2d356db68b474a4a1a7a88dc3f1c8532/12f09/Ready.png 148w,
/static/2d356db68b474a4a1a7a88dc3f1c8532/e4a3f/Ready.png 295w,
/static/2d356db68b474a4a1a7a88dc3f1c8532/fcda8/Ready.png 590w,
/static/2d356db68b474a4a1a7a88dc3f1c8532/efc66/Ready.png 885w,
/static/2d356db68b474a4a1a7a88dc3f1c8532/c83ae/Ready.png 1180w,
/static/2d356db68b474a4a1a7a88dc3f1c8532/701e9/Ready.png 1780w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;Once Service Fabric cluster is ready, any app is publishable from Visual Studio with a couple clicks! Instead of running the project (for local publish), right-click and select Publish. Now, let‚Äôs make an app to publish.&lt;/p&gt;
&lt;h2 id=&quot;who-said-c-is-ancient-cpp-rest-sdk&quot;&gt;Who said C++ is ancient: CPP Rest SDK&lt;/h2&gt;
&lt;p&gt;C++ is &lt;a href=&quot;https://www.quora.com/Why-is-C++-not-used-in-web-development&quot;&gt;not the easiest&lt;/a&gt; language to develop a RESTful web server. However, some tooling sure makes the job easier. &lt;a href=&quot;https://github.com/Microsoft/cpprestsdk&quot;&gt;CPP Rest SDK&lt;/a&gt; is a relatively new library that allows for easy out-of-the-box Server/Client RESTful communication in C++. My experience has been positive and I‚Äôd recommend checking it out.&lt;/p&gt;
&lt;h3 id=&quot;interlude-vcpkg&quot;&gt;Interlude: vcpkg&lt;/h3&gt;
&lt;p&gt;For the longest time, consuming packages easily on Windows has been a nightmare. That is until &lt;a href=&quot;https://github.com/Microsoft/vcpkg&quot;&gt;vcpkg&lt;/a&gt; came to the scene. VCPkg employs a source-based package management system, incurring a rebuild every time a new library is used. VCPkg has proved itself to be quite essential for Windows users like myself. I cannot really see myself going back to consuming boost the old way - searching for binaries matching my build config, or to keep looking for that blog with the Windows patch.&lt;/p&gt;
&lt;p&gt;For REST SDK, after &lt;a href=&quot;https://github.com/Microsoft/vcpkg#quick-start&quot;&gt;installing VCPkg&lt;/a&gt;, I ran the following: &lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;vcpkg&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;install&lt;/span&gt; cpprestsdk &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and voila! it‚Äôs installed and accessible from any VS project.  Lots of ‚ù§Ô∏è to vcpkg.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: I have recently become aware of &lt;a href=&quot;https://conan.io/&quot;&gt;conan&lt;/a&gt; which is supposed to provide similar functionality. I am yet to try it out for myself tho.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;a-rest-web-server&quot;&gt;A REST web server&lt;/h3&gt;
&lt;p&gt;Starting a REST webserver with the sdk is pretty uneventful (as it should!), the following does the trick:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;http_listener &lt;span class=&quot;token function&quot;&gt;listener&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;L&lt;span class=&quot;token string&quot;&gt;&quot;http://*:9009/processrequest&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
listener&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;support&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;methods&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;GET&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; GetHandler&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
listener
    &lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;then&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;amp;&lt;/span&gt;listener&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;cout&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;\nstarting to listen\n&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It does not get much easier than this! I have hosted &lt;a href=&quot;https://github.com/aybassiouny/ServiceFabricRestCPP&quot;&gt;my source&lt;/a&gt; for full implementation. &lt;code class=&quot;language-text&quot;&gt;GetHandler&lt;/code&gt; in its simplest form should return a status code and a message - for example:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;GetHandlerFunc&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;const&lt;/span&gt; http_request&lt;span class=&quot;token operator&quot;&gt;&amp;amp;&lt;/span&gt; request&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
    request&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;reply&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;status_codes&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;OK&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;Node ready to serve!&quot;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that running this listener requires running the app as admin. If the setup is done successfully, &lt;code class=&quot;language-text&quot;&gt;GetHandler&lt;/code&gt; should run when a request is made to &lt;code class=&quot;language-text&quot;&gt;http://127.0.0.1:9009/processrequest&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&quot;putting-it-together&quot;&gt;Putting It Together&lt;/h2&gt;
&lt;p&gt;Now to the interesting part: running our server on the Service Fabric fleet. After creating a service fabric &lt;code class=&quot;language-text&quot;&gt;Guest Executable&lt;/code&gt; project and pointing it to our binaries, there remains a couple of things to take care of.&lt;/p&gt;
&lt;h3 id=&quot;credentials&quot;&gt;Credentials&lt;/h3&gt;
&lt;p&gt;As noted above, our app needs Admin Privileges to listen on the associated port (9009 in our case). &lt;a href=&quot;https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-application-runas-security&quot;&gt;Service Fabric documentation&lt;/a&gt;  has a nice explanation of how to set the right permissions fit for your app - I took a shortcut by giving my app admin privileges in &lt;code class=&quot;language-text&quot;&gt;ApplicationManifest.xml&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;xml&quot;&gt;&lt;pre class=&quot;language-xml&quot;&gt;&lt;code class=&quot;language-xml&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;Principals&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;
  &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;Users&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;
    &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;User&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;Name&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation attr-equals&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;myLocalAccount&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;AccountType&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation attr-equals&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;LocalSystem&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;/&gt;&lt;/span&gt;&lt;/span&gt;
  &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;/&lt;/span&gt;Users&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;/&lt;/span&gt;Principals&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;Policies&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;
  &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;DefaultRunAsPolicy&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;UserRef&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation attr-equals&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;myLocalAccount&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;/&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;/&lt;/span&gt;Policies&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Please don‚Äôt&lt;/strong&gt; use this for production scenarios. It is worth to spend some time getting accurate permissions needed by the app. Unfortunately, Service Fabric is not really making this part easy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;certificates&quot;&gt;Certificates&lt;/h4&gt;
&lt;p&gt;Another &lt;em&gt;nice&lt;/em&gt; concept is how Service Fabric forces cluster admins and apps to use certificates to run the app on the cloud. That usually entails adding certificate thumbprint to &lt;code class=&quot;language-text&quot;&gt;ApplicationManifest.xml&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;xml&quot;&gt;&lt;pre class=&quot;language-xml&quot;&gt;&lt;code class=&quot;language-xml&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;Policies&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;
    ...
    &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;SecurityAccessPolicies&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;
      &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;SecurityAccessPolicy&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;ResourceRef&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation attr-equals&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;MyCert&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;PrincipalRef&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation attr-equals&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;myLocalAccount&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;GrantRights&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation attr-equals&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;Full&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;ResourceType&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation attr-equals&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;Certificate&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;/&gt;&lt;/span&gt;&lt;/span&gt;
    &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;/&lt;/span&gt;SecurityAccessPolicies&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;
  &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;/&lt;/span&gt;Policies&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;
  &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;Certificates&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;
    &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;&lt;/span&gt;SecretsCertificate&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;X509FindValue&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation attr-equals&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&amp;lt;Certificate_Thumbprint&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token attr-name&quot;&gt;Name&lt;/span&gt;&lt;span class=&quot;token attr-value&quot;&gt;&lt;span class=&quot;token punctuation attr-equals&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;MyCert&lt;span class=&quot;token punctuation&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;/&gt;&lt;/span&gt;&lt;/span&gt;
  &lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token tag&quot;&gt;&lt;span class=&quot;token punctuation&quot;&gt;&amp;lt;/&lt;/span&gt;Certificates&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The certificate thumbprint can be found in the portal under &lt;strong&gt;Service Fabric Cluster&lt;/strong&gt; &gt; &lt;strong&gt;Security&lt;/strong&gt; &gt;&gt; &lt;strong&gt;Cluster certificates&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/13c54b37242e137bbdcd1afc7ea3c317/2642d/thumbprint.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 30.405405405405407%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAoElEQVQY042PwQ7DIAxD+f8/rKbu0mk7VLQQCgMKZU/03s6HKEpsJ1bvz+vZMU2T9z6l+P0bahO9LAuyGGMpu4815dJaO46j3UE55zbvTypHxW3W2pTSqb+GstBFYmcbY6wxIoJjrfX+MswQfAhh76DRWlNLKeu6kgUSuXDMOfMRE5rzL0VaojOiMqVByQIjVljwAi7jOD46hmGY5xkxqx87LFxIOec46AAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Certificate Thumbprint&quot;
        title=&quot;&quot;
        src=&quot;/static/13c54b37242e137bbdcd1afc7ea3c317/fcda8/thumbprint.png&quot;
        srcset=&quot;/static/13c54b37242e137bbdcd1afc7ea3c317/12f09/thumbprint.png 148w,
/static/13c54b37242e137bbdcd1afc7ea3c317/e4a3f/thumbprint.png 295w,
/static/13c54b37242e137bbdcd1afc7ea3c317/fcda8/thumbprint.png 590w,
/static/13c54b37242e137bbdcd1afc7ea3c317/efc66/thumbprint.png 885w,
/static/13c54b37242e137bbdcd1afc7ea3c317/c83ae/thumbprint.png 1180w,
/static/13c54b37242e137bbdcd1afc7ea3c317/2642d/thumbprint.png 2003w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;Without the right settings/credentials, apps won‚Äôt be able to run on the remote cluster.&lt;/p&gt;
&lt;h3 id=&quot;port-listening-error&quot;&gt;Port Listening Error&lt;/h3&gt;
&lt;p&gt;This is kind of a side story - and the reason why this project took longer than I had expected. Initially, I had my server running fine on its own (outside Service Fabric), but does not run on Service Fabric,  either locally or on Azure. It was returning a &lt;code class=&quot;language-text&quot;&gt;503 Service Unavailable&lt;/code&gt; error code, and my breakpoints were never hit. It seemed like requests were not making it to the web server.&lt;/p&gt;
&lt;p&gt;After spending some time on many false paths, this &lt;a href=&quot;https://blogs.msdn.microsoft.com/webtopics/2010/02/17/a-not-so-common-root-cause-for-503-service-unavailable/&quot;&gt;article&lt;/a&gt; came as a life savior.&lt;/p&gt;
&lt;p&gt;The problem had been that I was using this line in Service Fabric to open the port:&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;&amp;lt;Endpoint Name=&quot;HelloSFServiceTypeEndpoint1&quot; Protocol=&quot;http&quot; Port=&quot;9009&quot;/&gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Which, as described in the MSDN blog, causes Service Fabric to listen on those URLs and block the CPP REST SDK from receiving those requests.  &lt;/p&gt;
&lt;p&gt;I tried to remove the line, but this renders the respective port closed on the cluster nodes. The solution was as simple as changing the protocol from &lt;code class=&quot;language-text&quot;&gt;HTTP&lt;/code&gt; to &lt;code class=&quot;language-text&quot;&gt;TCP&lt;/code&gt;, in which Service Fabric seems to open the port, but it does not block the &lt;code class=&quot;language-text&quot;&gt;http://*:9009&lt;/code&gt; requests. Final config is available on &lt;a href=&quot;https://github.com/aybassiouny/ServiceFabricRestCPP/blob/master/RestCluster/ApplicationPackageRoot/HelloSFServicePkg/ServiceManifest.xml&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;final-result&quot;&gt;Final Result&lt;/h3&gt;
&lt;p&gt;After going through all these hops, it is a pleasure to see the final result! In my case, running &lt;code class=&quot;language-text&quot;&gt;http://cpprestsf.eastus2.cloudapp.azure.com:9009/processrequest&lt;/code&gt; results in:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/3b2006da885f8261384e8d400173a253/9de76/3nodes.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 69.5945945945946%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABk0lEQVQ4y62SC2/cIBCE/f9/Y1U18QuDMQYbP683nV0rbXKJ0qgq0ie4M8zuDBR5WbCQaZrRew/vB8SUkPi7bAxa28NYD+MuOjfA9uFDun5AcRwHTrJtG4YQ4HqPMI7wXNcUrNsObWe5mYIUdz5gTDOZHpjhx4hijBGJHZmugzEdBXsVlG6XZYU4WFlMCsq87zvO8/wQaa6QRYwiaC9B18Naq3NiZbHeamejdnfZG9T6FcHFy7oAh1QX4dvtplVGti5dJs11wFPVoKxbtd90DrWxKupDfIcKyqUEZhZpv6obHjTMy/GQVzKtz/myLiwrI2DhQ2w+oIIvuYSUURkHN0SlD4lMiPOKgd9K41FbXlY3KJXA/16jgmJTRlp2rOuq5Jz1CQmSZWAM374/40fZ4KlsGYMhLZ5rg6qxv3kjOC2b2l9pSd6iPCHrHJ/TyLnXZyWZirh8D4xoYuGNDrdt1/lth3nTHOdp4i07JFnPkxYRvjL+CN7vyNv56eY79/yNB8EDPz/Z/BXRd4KvD/7L+O+CvwAG7TqvaQfWoQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;final result&quot;
        title=&quot;&quot;
        src=&quot;/static/3b2006da885f8261384e8d400173a253/fcda8/3nodes.png&quot;
        srcset=&quot;/static/3b2006da885f8261384e8d400173a253/12f09/3nodes.png 148w,
/static/3b2006da885f8261384e8d400173a253/e4a3f/3nodes.png 295w,
/static/3b2006da885f8261384e8d400173a253/fcda8/3nodes.png 590w,
/static/3b2006da885f8261384e8d400173a253/efc66/3nodes.png 885w,
/static/3b2006da885f8261384e8d400173a253/c83ae/3nodes.png 1180w,
/static/3b2006da885f8261384e8d400173a253/9de76/3nodes.png 1423w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;No matter how many times I see this, it is still spectacular! The time it takes from editing my code to seeing the request responded to by &lt;code class=&quot;language-text&quot;&gt;N&lt;/code&gt; machines is &amp;#x3C;1 minute. Although this is just a test app, the concept is pretty powerful for a test-driven world.&lt;/p&gt;
&lt;h2 id=&quot;last-words&quot;&gt;Last Words&lt;/h2&gt;
&lt;p&gt;Service Fabric &amp;#x26; C++ REST SDK got the job done, and it was a lot of fun. C++ is my favorite language. It‚Äôd be a shame if I could not spin up a 100% RESTful server whenever I wanted.&lt;/p&gt;
&lt;p&gt;I usually work with special-purpose internal tools, so it was new for me getting out there and trying OSS replacements. I hope this article gets even more folks toying with these frameworks! Let me know your favorite non-C++ (sane?) way to spin up a distributed service.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[The Curious Case of the 99.9% Latency Hike]]></title><description><![CDATA[Disclaimer: This is a story from production. I have changed a couple of details, but the gist of the story holds. Exposition On a normal‚Ä¶]]></description><link>https://mahdytech.com/2019/01/13/curious-case-999-latency-hike/</link><guid isPermaLink="false">https://mahdytech.com/2019/01/13/curious-case-999-latency-hike/</guid><pubDate>Sun, 13 Jan 2019 12:00:32 GMT</pubDate><content:encoded>&lt;blockquote&gt;
&lt;p&gt;Disclaimer: This is a story from production. I have changed a couple of details, but the gist of the story holds.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;exposition&quot;&gt;Exposition&lt;/h2&gt;
&lt;p&gt;On a normal morning, I was checking up on health metrics of a bunch of services, when a new service under test caught my attention. Let‚Äôs call this service &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt;. &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt; so far was doing pretty good perf-wise, stable latencies across the board, memory and CPU usage, all was good in the world. However, that day I found out there has been a 99.9% latency hike for several days. When I looked at latency counters it looked something similar to:&lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/1fe2cf1c3f84fe8e7b55e9c6e13094a7/eb3fa/Latencies.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.08108108108109%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAB2GAAAdhgFdohOBAAAAzklEQVQoz62Siw6DIAxF+f+vHYi8H+utluCiziUjubEt5UBbVc6511p7a+1UMcZurWWVUjh2l68k6alkXfk/AbFQUUppxGAjNoDz5jcYLpfDAkb5cwuU1vrw5DvNL7nsoTHmv8BlWR4BUe6Tfo+hMPRM+yAZSL0aeQL58JU0tNKBWvL+ne3MyhheSTTmSPS0YRpdUDb/ACx0wFHpZ/IWsqwYQg8e8j2sdhNsisvDlPxLjhJ9iCSxE/vGuo7BvbTp2liOr7TvfOQ8fOGDgfUG9elldo+LY1IAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Latencies&quot;
        title=&quot;Latencies show a hike in 99.9% latencies&quot;
        src=&quot;/static/1fe2cf1c3f84fe8e7b55e9c6e13094a7/fcda8/Latencies.png&quot;
        srcset=&quot;/static/1fe2cf1c3f84fe8e7b55e9c6e13094a7/12f09/Latencies.png 148w,
/static/1fe2cf1c3f84fe8e7b55e9c6e13094a7/e4a3f/Latencies.png 295w,
/static/1fe2cf1c3f84fe8e7b55e9c6e13094a7/fcda8/Latencies.png 590w,
/static/1fe2cf1c3f84fe8e7b55e9c6e13094a7/efc66/Latencies.png 885w,
/static/1fe2cf1c3f84fe8e7b55e9c6e13094a7/eb3fa/Latencies.png 1026w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;Latencies show a hike in 99.9% latencies&lt;/figcaption&gt;
  &lt;/figure&gt;
      &lt;/p&gt;
&lt;p&gt;These numbers are averaged across hundreds of machines in one &lt;a href=&quot;https://azure.microsoft.com/en-us/global-infrastructure/regions/&quot;&gt;data center&lt;/a&gt;. Also, this is a zoom-in for the problem, but let‚Äôs assume that following 8:45, and for the next couple of days, &lt;a href=&quot;https://www.elastic.co/blog/averages-can-dangerous-use-percentile&quot;&gt;99.9% latency&lt;/a&gt; stays high.&lt;/p&gt;
&lt;p&gt;Latency is how much time it takes &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt; to respond to a request, starting from the time it receives the request until it sends the response back:&lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/9ba6b3cf7e2ce34d2b4b6a0579fb44d3/a8a6f/LatencyExp.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 27.7027027027027%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABWUlEQVQY012OS0sCURiG5y8J4aYQKyEjpdrYqkhsEYSUiy6GoFDmlBGURKv2bYzIH2A1o1OpLVpE6YzhpdJxbniGxmlmzulYtOnj4eXdvDwfoWYSaoYEF1ta9kTm2coT81op6OqbofFQ5+GXgJD4Um3sn7HH51wqzR2lWQwuqXSVEGN2jBCxKYdTutpUOmUgsrD3oYF3Q2tZJh5L2ULZuUxPbjIT63n3am58LefZyHvCDCEnx+QDr7Q9JCXdCEKE7yc13ZK6RpsXuoqQoZv2xauREIWXM7H76citc4UaDtGEFHdIuy4xOiCRo//GMjBESdE/wSXVsAWyjuCNK0T7onfeMDO4dO0IUgTW9s3J8e5poAdqXZEDIqeDhgZaRq8N+2/LzGPdFyss7JXmE6XZeHFup+gnS37ygUCWiYGmgY2K3OHY53qNlUUeQQNBHVl9oGWYFvzF+iuYb/UvFs3gdPRNAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;What is Latency?&quot;
        title=&quot;Latency is the time interval between Request and Response&quot;
        src=&quot;/static/9ba6b3cf7e2ce34d2b4b6a0579fb44d3/fcda8/LatencyExp.png&quot;
        srcset=&quot;/static/9ba6b3cf7e2ce34d2b4b6a0579fb44d3/12f09/LatencyExp.png 148w,
/static/9ba6b3cf7e2ce34d2b4b6a0579fb44d3/e4a3f/LatencyExp.png 295w,
/static/9ba6b3cf7e2ce34d2b4b6a0579fb44d3/fcda8/LatencyExp.png 590w,
/static/9ba6b3cf7e2ce34d2b4b6a0579fb44d3/efc66/LatencyExp.png 885w,
/static/9ba6b3cf7e2ce34d2b4b6a0579fb44d3/c83ae/LatencyExp.png 1180w,
/static/9ba6b3cf7e2ce34d2b4b6a0579fb44d3/a8a6f/LatencyExp.png 1516w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;Latency is the time interval between Request and Response&lt;/figcaption&gt;
  &lt;/figure&gt;
      &lt;/p&gt;
&lt;p&gt;That was weird for many reasons. First, &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt; is a new service with less than 10 &lt;a href=&quot;https://en.wikipedia.org/wiki/Queries_per_second&quot;&gt;QPS&lt;/a&gt; - which is very low compared to other similar services that were handling 100 QPS with less 99.9% latency. Second, &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt; has been doing a pretty standard distributed load: receive N documents, divide them between processing threads, do a data lookup or two, and return processing result. For the load done, we had expected less than 5ms end-to-end latency, which was the case up until 8:45.&lt;/p&gt;
&lt;p&gt;When any &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt; instance is restarted, the problem &lt;em&gt;goes away&lt;/em&gt;, and latency is back to normal. But we could not ship &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt; this way: what if this happens in production when we have 10x more QPS? We had to figure this out sooner than later.&lt;/p&gt;
&lt;p&gt;Another interesting part, this problem occurred in &lt;em&gt;only one&lt;/em&gt; data center. Other data centers were fine. This excludes issues where a change is rolled out to all machines at the same time - whatever caused this was local. However, we had done nothing! &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt; had no new deployments for some time, no new data, nothing! &lt;strong&gt;How can nothing trigger something?&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;lets-debug-this&quot;&gt;Let‚Äôs Debug this&lt;/h2&gt;
&lt;p&gt;Naturally, I emptied my schedule, fired up the coffee machine, and dug in.&lt;/p&gt;
&lt;h3 id=&quot;f1-profile&quot;&gt;F1 Profile&lt;/h3&gt;
&lt;p&gt;First thing I did was running a profile using &lt;a href=&quot;https://docs.microsoft.com/en-us/visualstudio/profiling/how-to-install-the-stand-alone-profiler?view=vs-2017&quot;&gt;F1 Profiler&lt;/a&gt;. The profile is usually useful for showing CPU hot spots. Its ease of use and its lightweight report makes it usually my first tool to run unless there are clear signs for other root causes, which I didn‚Äôt have by then. I ran something close to:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;batch&quot;&gt;&lt;pre class=&quot;language-batch&quot;&gt;&lt;code class=&quot;language-batch&quot;&gt;&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;vsperf&lt;/span&gt; &lt;span class=&quot;token parameter attr-name&quot;&gt;/attach&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;/span&gt;Lucy.exe &lt;span class=&quot;token parameter attr-name&quot;&gt;/file&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;/span&gt;LucyProfile.vspx&lt;/span&gt;
&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;sleep&lt;/span&gt; 5m&lt;/span&gt;
&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;vsperf&lt;/span&gt; &lt;span class=&quot;token parameter attr-name&quot;&gt;/detach&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;vsperfreport&lt;/span&gt; &lt;span class=&quot;token parameter attr-name&quot;&gt;/symbolpath&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;srv*d:\symbols*https://msdl.microsoft.com/download/symbols;&quot;&lt;/span&gt; &lt;span class=&quot;token parameter attr-name&quot;&gt;/summaryfile&lt;/span&gt; &lt;span class=&quot;token parameter attr-name&quot;&gt;/packsymbols&lt;/span&gt; LucyProfile.vspx&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Basically, attaching to the process for a 5 min, detach, then finally &lt;code class=&quot;language-text&quot;&gt;vsperfreport&lt;/code&gt; is used to add needed &lt;a href=&quot;https://docs.microsoft.com/en-us/windows/desktop/dxtecharts/debugging-with-symbols&quot;&gt;symbols&lt;/a&gt; for the report. The resulting &lt;code class=&quot;language-text&quot;&gt;.vsps&lt;/code&gt; file can be opened using F1 Profile tools (or Visual Studio if it was used for capture). A typical CPU profile looks like this:&lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/431f61b981547d21a772f74df49911c4/cb93d/F1Profile.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 62.83783783783784%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAB2HAAAdhwGP5fFlAAACT0lEQVQ4y3VT2W4bMQz0/39JgQAO8tAPKIqkB4okdosisb33WntoL2klrR0HnZDauA0Q9IGgDnI0JEeLJM2g9ehNKT0b70eDYVCoqhpFUaJtO79mn1JOSeu6lkizHFI2Pm+knMVut0PXdbDWenPOvq4NrDHo+44ABQytOc6MI/IsI7CaQAZEYUgPVf6e8xZRFCFOEhgGcc6/MprZjLGeuWwaCnYYlPJxzKhlcLrn3Hwv/D2DLoaqQBxssM8StLLGgRi+tcmOGIcWz0eHg9Heq07SWYfTwUJkMWQp4EY1M7wNa3xeB/jyK8DPMEdYURmVIhsQ1wq7osePoMQq63EXN95/3wp/dp92uP4d49MqwNeHlPpOgFfrChc3G1w/7LFJS4Rlj0RqD5Y2GlsCvFoJLCnu8r7AJfnlbY7l3R7LVYmLbwE+3Gzxcb1Hr6nkP0eLpsgxNDTBuoQl6qfjhKeDm22yOLkReHJ4ngz5CZPucRh7gMrn3LYS1A4FxyXX1ODNdoeikkjywluvHZmdTdGkhwGaJ04y4mHVUoLzFE08imMEYeT3voeiKBCQdFJRY5s12OUNssaSGe/35JWaG372bdvOEiLwNE0hhCB59fOU+eDxcUNaKtG1DSqamBk1Tk8HHKnkyb0HbEhGDMoALDvW5DRN/wC3xJB/QUkCTUm0ZVn5X8DqZwCt9asm9TvAmEpmYbOGPWBCB/wKU+ZALoWDpZSeEQMN1MP/MUxI2EIU/twDhvR1mGWe5wQc+l/AjecSzkFnZn97+AaQc/lvnx99Af/kzypZ+Yc0AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;F1 Perf&quot;
        title=&quot;A typical F1 Profile window&quot;
        src=&quot;/static/431f61b981547d21a772f74df49911c4/fcda8/F1Profile.png&quot;
        srcset=&quot;/static/431f61b981547d21a772f74df49911c4/12f09/F1Profile.png 148w,
/static/431f61b981547d21a772f74df49911c4/e4a3f/F1Profile.png 295w,
/static/431f61b981547d21a772f74df49911c4/fcda8/F1Profile.png 590w,
/static/431f61b981547d21a772f74df49911c4/efc66/F1Profile.png 885w,
/static/431f61b981547d21a772f74df49911c4/c83ae/F1Profile.png 1180w,
/static/431f61b981547d21a772f74df49911c4/cb93d/F1Profile.png 2304w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;A typical F1 Profile window&lt;/figcaption&gt;
  &lt;/figure&gt;
      &lt;/p&gt;
&lt;p&gt;&lt;em&gt;My favorite feature in F1 over XPerf: &lt;code class=&quot;language-text&quot;&gt;Expand hot path&lt;/code&gt;. Bonus points if you can guess which famous windows app in the preview!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The profile didn‚Äôt show anything unusual taking over the CPU. Even when I did a profile on a healthy machine, the two profiles looked very similar. I decided to move on.&lt;/p&gt;
&lt;h3 id=&quot;xperf&quot;&gt;XPerf&lt;/h3&gt;
&lt;p&gt;Next, I ran XPerf, the swiss army knife of live profiles. XPerf has the big advantage of being non-invasive as it has almost negligible effect on perf of running apps. It is highly customizable but suffers from a pretty steep learning curve. &lt;a href=&quot;https://randomascii.wordpress.com&quot;&gt;randomascii&lt;/a&gt; has been an excellent up-to-date XPerf resource, I highly recommend the blog. I also recommend &lt;a href=&quot;https://www.amazon.com/Inside-Windows-Debugging-Practical-Strategies/dp/B00D46F9IU&quot;&gt;Inside Windows Debugging&lt;/a&gt; that dissects XPerf and puts the reader on track for using XPerf proficiently.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: XPerf seems to have been rebranded to &lt;a href=&quot;https://docs.microsoft.com/en-us/windows-hardware/test/wpt/&quot;&gt;Windows Performance Toolkit (WPT)&lt;/a&gt;, and it can also be downloaded from the Windows Store. I actually do &lt;em&gt;not&lt;/em&gt; recommend using the &lt;code class=&quot;language-text&quot;&gt;Windows Performance Recorder (WPR)&lt;/code&gt; tool to record ETW traces and prefer to use the XPerf command line tool as shown below. WPR‚Äôs defaults produce &lt;strong&gt;massive&lt;/strong&gt; traces that are both inconvenient to move around and can contain too much information for a first-time user. For analyzing traces, &lt;code class=&quot;language-text&quot;&gt;Windows Performance Analyzer (WPA)&lt;/code&gt; is the way to go, hands down.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now, while F1 Profiler provided &lt;a href=&quot;https://docs.microsoft.com/en-us/windows-hardware/test/wpt/cpu-analysis#cpu-usage-sampled-graph&quot;&gt;Sampled CPU&lt;/a&gt; info, it was time to get &lt;a href=&quot;https://docs.microsoft.com/en-us/windows-hardware/test/wpt/cpu-analysis#cpu-usage-precise-graph&quot;&gt;Precise CPU&lt;/a&gt; info. A &lt;code class=&quot;language-text&quot;&gt;Sampled CPU&lt;/code&gt; profile captures call stacks on regular time intervals (i.e. takes samples). On the other hand, a &lt;code class=&quot;language-text&quot;&gt;Precise CPU&lt;/code&gt; profile captures context switches across threads, and in turn helps to detect any locks or long IO waits. I ran something close to:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;batch&quot;&gt;&lt;pre class=&quot;language-batch&quot;&gt;&lt;code class=&quot;language-batch&quot;&gt;&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;xperf&lt;/span&gt; -on PROC_THREAD+LOADER+Base+CSWITCH+DISPATCHER -stackwalk  CSwitch+ReadyThread -BufferSize &lt;span class=&quot;token number&quot;&gt;1024&lt;/span&gt; -MinBuffers &lt;span class=&quot;token number&quot;&gt;512&lt;/span&gt; -MaxBuffers &lt;span class=&quot;token number&quot;&gt;5120&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;sleep&lt;/span&gt; 1m&lt;/span&gt;
&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;xperf&lt;/span&gt; -stop &lt;span class=&quot;token parameter attr-name&quot;&gt;-d&lt;/span&gt; Lucy_Profile_1m.etl&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Explanation:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Run XPerf and captures events, as well as call stacks, for Context Switches.&lt;/li&gt;
&lt;li&gt;Keep running for one minute&lt;/li&gt;
&lt;li&gt;Stop capturing events, and output captured trace into Lucy&lt;em&gt;Profile&lt;/em&gt;1m.etl&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: in order to get a list of available &lt;a href=&quot;https://docs.microsoft.com/en-us/windows-hardware/test/wpt/providers&quot;&gt;event providers&lt;/a&gt;, run &lt;code class=&quot;language-text&quot;&gt;xperf -providers  K&lt;/code&gt;. See the &lt;a href=&quot;https://docs.microsoft.com/en-us/windows-hardware/test/wpt/stackwalk&quot;&gt;docs&lt;/a&gt; for possible &lt;code class=&quot;language-text&quot;&gt;-stackwalk&lt;/code&gt; arguments.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let‚Äôs take a look at a Sampled vs Precise CPU profile in WPA:&lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/5144e945eb6a32f89e3e91c302c4ab75/cc3e2/sampledvsprecise.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 35.13513513513513%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAIAAACHqfpvAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABZUlEQVQY0x2Qy26jMABF+f9FP6LLkVq1qkbVaPZRk0UI5WmMMTbgB7aBQFIICaS0Z3XP1V1di1JphDGySVCKKS25OPanpu26/jxO8zjWRnGFaafMdFsu020YJyEVFQqjzNIQDZQOOSWBJ1kpedm19fUyLPP1vjLX174aWHHR1f3X1/5Ya900VU4s7scqJQzEyT7gXIAElZwvP6tlvt9vt+YytGdZnaT80WWZ5rlu26o9VnlulbYjwlD4Ltptwt3W//hI7EPmedh1oe0U/oEFLrUP1N4zADiIizBIPx3PPvjbnaVdx4CgiX3p7dMoSiE0QtRSHHUlC9rXZlwvUIXkTk5jlsSMJCyBEOEkDK3wfZNtnM/3zZ+HF8E5JsQOSIR1lClAdISVi5gN0S5wA4C/GJvO5y4valObklnPT29vf/8/v/57fHzhjKUYewAjKmHGY8wg5mtAGU8poYU4yeqr71vG9Qpn38mpdUofDH3CAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;SampledVsPrecise&quot;
        title=&quot;Sampled Vs Precise CPU usage in XPerf&quot;
        src=&quot;/static/5144e945eb6a32f89e3e91c302c4ab75/fcda8/sampledvsprecise.png&quot;
        srcset=&quot;/static/5144e945eb6a32f89e3e91c302c4ab75/12f09/sampledvsprecise.png 148w,
/static/5144e945eb6a32f89e3e91c302c4ab75/e4a3f/sampledvsprecise.png 295w,
/static/5144e945eb6a32f89e3e91c302c4ab75/fcda8/sampledvsprecise.png 590w,
/static/5144e945eb6a32f89e3e91c302c4ab75/efc66/sampledvsprecise.png 885w,
/static/5144e945eb6a32f89e3e91c302c4ab75/c83ae/sampledvsprecise.png 1180w,
/static/5144e945eb6a32f89e3e91c302c4ab75/cc3e2/sampledvsprecise.png 2581w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;Sampled Vs Precise CPU usage in XPerf&lt;/figcaption&gt;
  &lt;/figure&gt;
      &lt;/p&gt;
&lt;p&gt;Unfortunately, again, nothing new was in my Precise CPU run. The callstack had the usual time-wasters, but nothing special. I then tried to run XPerf with different parameters:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;batch&quot;&gt;&lt;pre class=&quot;language-batch&quot;&gt;&lt;code class=&quot;language-batch&quot;&gt;&lt;span class=&quot;token command&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;xperf&lt;/span&gt; -on PROC_THREAD+LOADER+DISK_IO+HARD_FAULTS+ALL_FAULTS -stackwalk  HardFault+PagefaultDemandZero+PagefaultHard+PagefaultTransition&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Tat focuses more on disk issues and &lt;a href=&quot;https://stackoverflow.com/questions/5684365/what-causes-page-faults&quot;&gt;page faults&lt;/a&gt;. But, it didn‚Äôt yield anything either. What‚Äôs going on?&lt;/p&gt;
&lt;h4 id=&quot;i-have-made-a-mistake-in-my-analysis-so-far-have-you-figured-it-out&quot;&gt;&lt;em&gt;I have made a mistake in my analysis so far. Have you figured it out?&lt;/em&gt;&lt;/h4&gt;
&lt;hr&gt;
&lt;h2 id=&quot;resolution&quot;&gt;Resolution&lt;/h2&gt;
&lt;p&gt;It was the granularity! I was only capturing 1 min traces. At &amp;#x3C;10 QPS, 99.9% latency is less than 3 requests in a 5-min aggregation interval. Capturing only 1 minute of the profile can miss the actual problem - and it did.&lt;/p&gt;
&lt;p&gt;This was solved by running another 10-min disk-focused XPerf. And lo and behold, the bad guy! A couple of hard faults:&lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/5d8deed5584f5da6b0e6986bca56f03e/a0b80/WPT.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 25.675675675675674%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAAB2HAAAdhwGP5fFlAAAA+UlEQVQY022NTU+DQBRF+f260Mbf4F5jYowxaJOK6aSxcYGGkrbAlFKYlvIxFGbmzTzBbn05uTl3c59VVlywuYxf5Haskrc/xjLpfahNHvGmk0pK0B1fVWUpFQjRsaxOd43VtgLWt+hdon+Niyv0Ruj1MkL/Bn8uTPmNiEaDMWgkRdSmNzRlgWFkrLpuj5Ts3LvYva8i2+QEmAPsYyB7Vy1TBhUAaFQdBQ1q2NH7g1kHYKEUgtdZvE0ozdMUtcZ/zgwBm/7zuZ44FgytiXd4dZOnz+Bxtnr+ohN/Pw1KElZnnOXRdhNnWRB6mgcLElXTkM82te3yB1L9Alq1EZAqgb5RAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Hard Faults Found&quot;
        title=&quot;When using longer timeframe, we can find hard faults&quot;
        src=&quot;/static/5d8deed5584f5da6b0e6986bca56f03e/fcda8/WPT.png&quot;
        srcset=&quot;/static/5d8deed5584f5da6b0e6986bca56f03e/12f09/WPT.png 148w,
/static/5d8deed5584f5da6b0e6986bca56f03e/e4a3f/WPT.png 295w,
/static/5d8deed5584f5da6b0e6986bca56f03e/fcda8/WPT.png 590w,
/static/5d8deed5584f5da6b0e6986bca56f03e/efc66/WPT.png 885w,
/static/5d8deed5584f5da6b0e6986bca56f03e/a0b80/WPT.png 955w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;When using longer timeframe, we can find hard faults&lt;/figcaption&gt;
  &lt;/figure&gt;
      &lt;/p&gt;
&lt;p&gt;The case is not actually solved yet! What caused those hard faults out of the blue? Nothing indeed had changed in &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt;. I had already checked &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt;‚Äôs memory graphs, which although pointing to a decrease in Working Set size, didn‚Äôt provide a clue for the trigger. But now that I know &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt; got swapped out, I suspected &lt;em&gt;another&lt;/em&gt; process was responsible.  This time, I checked the whole ecosystem, and the culprit stood out:&lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/374e955b6babb988d6df2e1dc85354ba/56caf/LatencyPrivateBytes.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.08108108108109%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAB2HAAAdhwGP5fFlAAAA7UlEQVQoz4WSi3KFIAxE/f+PVVCEvO0Cvb3t1NqdTFTM4bFkcffrpzCyrmtKqZSCl23bUsruMf9G9ICYeTGz604xSnpl2GX6Sbxk7q21P+G3pHI7ubX5RWzqAYqIFlV9It2UiDWUKokTu1oYYHdmWs5SnmDlRjw2ymFq/vblOA7AZz+atkvpd4QQFhwe+CVtjoSyu8HRpdb6tLCFatydxnAX/xgm2g95A7t3w6JrrPAtREe2aHw/NWCeMBpAxERn+ORt5K/emDcfsxopgEjftqBZMA8THrDgOHaYUetZz7LnvO895ZzRFfQSLhjFHyGDihC75OZ3AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;LatencyPrivateBytes&quot;
        title=&quot;Lucy&apos;s latency vs private bytes&quot;
        src=&quot;/static/374e955b6babb988d6df2e1dc85354ba/fcda8/LatencyPrivateBytes.png&quot;
        srcset=&quot;/static/374e955b6babb988d6df2e1dc85354ba/12f09/LatencyPrivateBytes.png 148w,
/static/374e955b6babb988d6df2e1dc85354ba/e4a3f/LatencyPrivateBytes.png 295w,
/static/374e955b6babb988d6df2e1dc85354ba/fcda8/LatencyPrivateBytes.png 590w,
/static/374e955b6babb988d6df2e1dc85354ba/efc66/LatencyPrivateBytes.png 885w,
/static/374e955b6babb988d6df2e1dc85354ba/c83ae/LatencyPrivateBytes.png 1180w,
/static/374e955b6babb988d6df2e1dc85354ba/56caf/LatencyPrivateBytes.png 1712w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;Lucy&apos;s latency vs private bytes&lt;/figcaption&gt;
  &lt;/figure&gt;
      &lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt; was not alone. &lt;em&gt;Another team‚Äôs&lt;/em&gt; service also lives there - and theirs had a memory leak around the same time the 99.9% latency hiked, as the graph shows. When there‚Äôs a memory leak, and the kernel runs low on available physical memory, &lt;a href=&quot;https://mahdytech.com/2019/01/05/task-manager-memory-info/&quot;&gt;it tries to free up memory by paging other services&lt;/a&gt;. In this scenario, &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt; was the victim and most of its working set was written to the page file.&lt;/p&gt;
&lt;p&gt;The other team quickly realized and fixed the issue - but &lt;strong&gt;they did not tell us&lt;/strong&gt;. Shortly after the fix, most of &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt;‚Äôs paged memory was swapped back into its working set - but not all of it. Some parts were not accessed frequently, and the Kernel decided to leave them paged. However, 2 or 3 requests every several minutes needed to access that paged memory. Those couple of requests experienced &lt;a href=&quot;https://www.brighthub.com/computing/windows-platform/articles/52249.aspx&quot;&gt;hard-faults&lt;/a&gt; and that in turn hiked the 99.9% latency.&lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/dbab0b899fa4090894dc388033f7dfb1/c4353/Resolution.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 26.351351351351354%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABPElEQVQY0wExAc7+AOns8d/i6Ojr8Ofp7v39/fr7/f7+//Ly9ePk5+bm6fLy8/z+//r7/OTn7Ofq8OPm6/L0+P///////////wD547f54bT647f23rD+8NH5/f/79efx4Lry4r7v37vz4734+fb88t764bH54rf34LT85rv//vr+//////4AboKmaX+jboOmX3WdpLDE////9dS544Qz5Ys+4YU55Ik8/O/k1se+o3xkrJKFpIV0rox37+/x6+zs7u7uAFiD0lOA0VWC0UV2zYmm3P////TKr/CAOPGNS/GKR+6CO//p1qK/7UV1y1eD0lF+0FJ/0O/z+v////7+/wBmisxghstojM1Zgciasdv////207zvjEnwlljvkFDtj1D/7t+wx+tXf8ZnjM1jictpjc3y9fv////+/v/C/eraCZy/WAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Resolution&quot;
        title=&quot;Lucy&apos;s memory across time&quot;
        src=&quot;/static/dbab0b899fa4090894dc388033f7dfb1/fcda8/Resolution.png&quot;
        srcset=&quot;/static/dbab0b899fa4090894dc388033f7dfb1/12f09/Resolution.png 148w,
/static/dbab0b899fa4090894dc388033f7dfb1/e4a3f/Resolution.png 295w,
/static/dbab0b899fa4090894dc388033f7dfb1/fcda8/Resolution.png 590w,
/static/dbab0b899fa4090894dc388033f7dfb1/efc66/Resolution.png 885w,
/static/dbab0b899fa4090894dc388033f7dfb1/c83ae/Resolution.png 1180w,
/static/dbab0b899fa4090894dc388033f7dfb1/c4353/Resolution.png 4094w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;Lucy&apos;s memory across time&lt;/figcaption&gt;
  &lt;/figure&gt;
      &lt;/p&gt;
&lt;p&gt;After I realized the leak, I emailed the other team asking them, and they confirmed that was actually the case, but ‚ÄúNot to worry, &lt;em&gt;it is all solved now&lt;/em&gt;‚Äú.&lt;/p&gt;
&lt;p&gt;It is interesting to note if &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt; was getting more QPS, the kernel would have probably swapped the rest of its paged memory back into the working set, and this problem would not be there. In a sense, having less load has caused the latency issues. The good news is, this was not a problem to be worried about in production, and once we restarted all &lt;code class=&quot;language-text&quot;&gt;Lucy&lt;/code&gt; instances, the issue was mitigated for good.&lt;/p&gt;
&lt;p&gt;I learned so much while debugging this issue - and had a lot of fun! I think there are a lot of takeaways, especially how lack of communication can trigger such a series of events. Let me know your thoughts in the comments!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Be careful using Task Manager for Memory Metrics]]></title><description><![CDATA[[Disclaimer: This post was edited in Feb 2022 to address feedback. Previous version can be found on Github] As a windows user for many many‚Ä¶]]></description><link>https://mahdytech.com/2019/01/05/task-manager-memory-info/</link><guid isPermaLink="false">https://mahdytech.com/2019/01/05/task-manager-memory-info/</guid><pubDate>Sat, 05 Jan 2019 22:40:32 GMT</pubDate><content:encoded>&lt;p&gt;[Disclaimer: This post was edited in Feb 2022 to address feedback. Previous version can be found on Github]&lt;/p&gt;
&lt;p&gt;As a windows user for many many years, Task Manager is a friend. Through the years, I have used it to kill thousands of misbehaving applications, and getting info about which ones are exhausting my resources. Until I started working with machines that have  100+ of GBs of memory hosting data-intensive services, that‚Äôs when I first started seeing discrepancies between how much memory my app was allocating vs what Task Manager shows. In this post I will discuss how Task Manager can be lacking as a memory tracker, and go over alternatives that could replace it. First, let‚Äôs discuss how memory allocations work in Windows.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#allocations-in-windows&quot;&gt;Allocations in Windows&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#reserving-vs-committing-memory&quot;&gt;Reserving vs Committing memory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#os-paging&quot;&gt;OS Paging&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#memory-tracking&quot;&gt;Memory Tracking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#effective-memory-metrics&quot;&gt;Effective Memory Metrics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#debugging-with-memory-info&quot;&gt;Debugging with Memory Info&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;tl;dr: Task Manager hides info about process‚Äôs Paged Memory and does not have a way to show its Virtual Space. &lt;code class=&quot;language-text&quot;&gt;Process Explorer&lt;/code&gt; is a better alternative for in-depth tracking.&lt;/p&gt;
&lt;h2 id=&quot;allocations-in-windows&quot;&gt;Allocations in Windows&lt;/h2&gt;
&lt;p&gt;Whenever a new process starts, OS reserves some memory space for this process‚Äôs use. In x86 systems, this space is 4GB, with 2GB for kernel use, and the rest for the process. For x64-systems, reserved process memory can grow to a whopping 64TB. How come can we reserve up to several TBs when we actually have a measly 32GB RAM? We‚Äôd need first to understand reserving vs committing memory.  &lt;/p&gt;
&lt;h3 id=&quot;reserving-vs-committing-memory&quot;&gt;Reserving vs Committing memory&lt;/h3&gt;
&lt;p&gt;Not all parts of that huge address space are ‚Äúusable‚Äù. Only a tiny fraction of the Process Address Space is backed by either physical RAM, or by disk (explained &lt;a href=&quot;#OS-Paging&quot;&gt;below&lt;/a&gt;). Memory that is backed is referred to as &lt;code class=&quot;language-text&quot;&gt;Committed&lt;/code&gt;. Memory otherwise, and that‚Äôs the vast majority of a process‚Äôs address space, is either free or &lt;code class=&quot;language-text&quot;&gt;Reserved&lt;/code&gt; memory. In C++, reserving a piece of memory can by achieved through a call to &lt;a href=&quot;https://docs.microsoft.com/en-ca/windows/win32/api/memoryapi/nf-memoryapi-virtualalloc?redirectedfrom=MSDN&quot;&gt;VirtualAlloc&lt;/a&gt; with the &lt;code class=&quot;language-text&quot;&gt;MEM_RESERVE&lt;/code&gt; flag. Committed memory is then the actual resource limit in the OS, since it‚Äôs backed by hardware. Let‚Äôs give it a look.&lt;/p&gt;
&lt;h3 id=&quot;os-paging&quot;&gt;OS Paging&lt;/h3&gt;
&lt;p&gt;OS Paging is an amazing concept. Basically, the OS &lt;em&gt;realizes&lt;/em&gt; that some parts of the memory are not used a lot by your app. Now, why waste precious physical memory on that? The kernel moves this unused space from RAM to disk. Once it gets accessed again, it gets brought back into RAM. Another use for paging is when the system runs out of free RAM, but some process needs more memory, in which case the OS can try and free up some RAM by moving it to the disk. &lt;/p&gt;
&lt;p&gt;For a more detailed explanation of how memory works in windows, I cannot recommend enough Mark Russinovich‚Äôs &lt;a href=&quot;https://www.youtube.com/watch?v=TrFEgHr72Yg&quot;&gt;Mysteries of Memory Management Revealed&lt;/a&gt;.  &lt;/p&gt;
&lt;h2 id=&quot;memory-tracking&quot;&gt;Memory Tracking&lt;/h2&gt;
&lt;p&gt;Now that‚Äôs a lot of info, whom to turn to to understand process memory details? of course it‚Äôs Task Manager!&lt;/p&gt;
&lt;p&gt;Memory that is backed by RAM is generally referred to as &lt;code class=&quot;language-text&quot;&gt;Working Set&lt;/code&gt;, while &lt;code class=&quot;language-text&quot;&gt;Private Bytes&lt;/code&gt;, in general, are the overall committed memory. Dlls make definitions a little more complicated, so let‚Äôs ignore them for now. In other words:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;Private Bytes [Committed Memory] =  Working Set (RAM-backed memory) + Page File (Disk-backed memory) &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By default, Task Manager shows Working Set under any process:&lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/3f18af5faae54d7c6f00cb0f770825e2/5e4a4/TaskManagerWorkingSet.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 33.108108108108105%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAB2HAAAdhwGP5fFlAAABOklEQVQoz21RSVLDQAz0O3giR/7AG/IEngA3XsEhFSfexkscO949SXlpWkooKEBVKrVn2q2WxknTFKfTCcuyYF1XrV9Ycp7nH9/4ld8cTfIcNzCIoghN06Druj91GAb0/YC2bSiMf+NmZFXsFHXPn2uUZYnj8YhcMs9xPp/1TGpdV7yryXtngxfmBtY+M1+JW0zTrGLTNMEpixzjOOpBVVXqKE0SHVMIYRjyfsD1Cgq/0e2GTR5hzAPS9Am+98GVlWxewEQGzs51OU6rgnEck5ThsD9oE2utrkOi72V83PGK7XaHICjhuh48z9NpiqKAY4xRJxKC5YF838flclFBwRK3XXayMeKOQnu697GnoSAI6L7mztvbyMt92yLW8iESjnzljJKyTwlLx+NoFUuzKAqRZZmaEL7wRPQTZf0Uqm9FOagAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Default Task Manager&quot;
        title=&quot;Task Manager shows Working Set by default&quot;
        src=&quot;/static/3f18af5faae54d7c6f00cb0f770825e2/fcda8/TaskManagerWorkingSet.png&quot;
        srcset=&quot;/static/3f18af5faae54d7c6f00cb0f770825e2/12f09/TaskManagerWorkingSet.png 148w,
/static/3f18af5faae54d7c6f00cb0f770825e2/e4a3f/TaskManagerWorkingSet.png 295w,
/static/3f18af5faae54d7c6f00cb0f770825e2/fcda8/TaskManagerWorkingSet.png 590w,
/static/3f18af5faae54d7c6f00cb0f770825e2/efc66/TaskManagerWorkingSet.png 885w,
/static/3f18af5faae54d7c6f00cb0f770825e2/c83ae/TaskManagerWorkingSet.png 1180w,
/static/3f18af5faae54d7c6f00cb0f770825e2/5e4a4/TaskManagerWorkingSet.png 1403w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;Task Manager shows Working Set by default&lt;/figcaption&gt;
  &lt;/figure&gt;
      &lt;/p&gt;
&lt;p&gt;And that‚Äôs the number I used to look at all the time. Now, I understand that it says that in parentheses, but I still find it easy to miss, especially for someone (as I was) unaware of all these memory terms; (private) Working Set, Private Bytes, Reserved Set, etc, but wondering where did his allocated bytes go. To my surprise, Task Manager &lt;em&gt;actually&lt;/em&gt; has info on process total commit size, but it‚Äôs under the column &lt;code class=&quot;language-text&quot;&gt;Commit Size&lt;/code&gt;. So far, I could not find Virtual/Reserve Memory info in Task Manager.&lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/9fbd7ab28b18c6bc8ac62271626bd34f/d9ed0/TaskManagerCommitSize.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 35.810810810810814%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAB2HAAAdhwGP5fFlAAABYUlEQVQoz22R3W6cQAyFef9X6E2fope9qqr+RGlJk80uCcsAy/LPzLBtCBD46qFSK0W1dHR0jj2W7fHyoqDIc4qiZBgGpmliHMd/PM/MAqcd/y/WFZZlEV7xIhUTxzFKqa1p13VUdU3ruKoxxtD3/aat8OtGr8NrmppfF8vw9HOD1R1Gt7R1xTg8cekNdVVITb/5vdVY42rcG0Vv3oj3lq6tBQ3e15sQf38kPMsEE4RZw6PgR5CgR1Cl4V7ldAPEVU91mSnsM1e3oeQy7qN3+If3fNsrrvw7vI/+gS87xf5syS4r10HG9cOZT7cRsZ65iSr8Y0lqF3apJjUv4k98+B6ItlKv+XyXi35gF57wDo9HToniWdZz0ch6bvRTErsr/TlB1245t7bzWF9IVLTpujxzStWm80waBsGRJEn+HrxpGtq23Tx39E5rtMCFtT2LmO434zjBWEtZyvTpadN5XvAb9tUPYe/3LwQAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Task Manager after adding Commit Size&quot;
        title=&quot;It is possible to add Commit Size&quot;
        src=&quot;/static/9fbd7ab28b18c6bc8ac62271626bd34f/fcda8/TaskManagerCommitSize.png&quot;
        srcset=&quot;/static/9fbd7ab28b18c6bc8ac62271626bd34f/12f09/TaskManagerCommitSize.png 148w,
/static/9fbd7ab28b18c6bc8ac62271626bd34f/e4a3f/TaskManagerCommitSize.png 295w,
/static/9fbd7ab28b18c6bc8ac62271626bd34f/fcda8/TaskManagerCommitSize.png 590w,
/static/9fbd7ab28b18c6bc8ac62271626bd34f/efc66/TaskManagerCommitSize.png 885w,
/static/9fbd7ab28b18c6bc8ac62271626bd34f/c83ae/TaskManagerCommitSize.png 1180w,
/static/9fbd7ab28b18c6bc8ac62271626bd34f/d9ed0/TaskManagerCommitSize.png 1415w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;It is possible to add Commit Size&lt;/figcaption&gt;
  &lt;/figure&gt;
      
&lt;em&gt;Task Manager allows adding Commit Size by right-clicking columns and adding it&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;more-memory-meters&quot;&gt;More Memory Meters&lt;/h2&gt;
&lt;p&gt;Thankfully, there are many other resources to examine process metrics in Windows. &lt;code class=&quot;language-text&quot;&gt;PerfMon&lt;/code&gt; is a Win32 app that can be used to expose very detailed info about each process and the system in general:&lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/276f9ec52c95d9d47eee99b1de3832ac/a0a3d/PerfMon.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 72.2972972972973%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABo0lEQVQ4y6VTiW7CMAzt///aNO3gKAMmmpaGhqYXpQWxtm/PZUwghlRpkaz4eHmxHceJzAbR1sDECSVFXR8gq7uSX7t7LF9Ng31Vw1HeJ1SgkGQFwshi7oUItI9AzbHRGkEQYBVo6E0Ea2PE8WOx1sIZj57w8vIMb+UhiiKs9YaZGsTM3Apwu6Vte3CapkiS5E4u/p6wKDOU+x2apkXFlLck6LpLoT91DlhyJssyONfOuj4TNuxHD2pbdNTPfeoeiqyWWMnUuXbeEUpMCDGMsM/wL8L2ihA/+qPSBxE2DN6U/K8MjUFzPAKnE7qyREd9KOHfPSRhm+dinMu9lDzgle8JDwcEvs8ZNBylPYqiQE5ymU/LORNbRObTECP6brdDyUrE1vwIN4RVVfGWDAVB0g8ZVNmFUA4IuWGPNYdf/IKVnxSGGhljYRjezuGBGfrM0Pc8qNUKSiksFov+kCZ4uVxCMebT3+vcJTZzXXzSXq/XcNIs5z/OeUOByMT4WCzhTl1MJ1NM3BneR2OMxhNMqY/pk11EfG+MTYgV/+v7CLOPOb4BG600L1ckTuMAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;PerfMon&quot;
        title=&quot;PerfMon allows for examining real time system metrics&quot;
        src=&quot;/static/276f9ec52c95d9d47eee99b1de3832ac/fcda8/PerfMon.png&quot;
        srcset=&quot;/static/276f9ec52c95d9d47eee99b1de3832ac/12f09/PerfMon.png 148w,
/static/276f9ec52c95d9d47eee99b1de3832ac/e4a3f/PerfMon.png 295w,
/static/276f9ec52c95d9d47eee99b1de3832ac/fcda8/PerfMon.png 590w,
/static/276f9ec52c95d9d47eee99b1de3832ac/efc66/PerfMon.png 885w,
/static/276f9ec52c95d9d47eee99b1de3832ac/c83ae/PerfMon.png 1180w,
/static/276f9ec52c95d9d47eee99b1de3832ac/a0a3d/PerfMon.png 1965w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;PerfMon allows for examining real time system metrics&lt;/figcaption&gt;
  &lt;/figure&gt;
      &lt;/p&gt;
&lt;p&gt;Interestingly, PerfMon can actually examine &amp;#x26; compare metrics across multiple machines in the network. It‚Äôs very powerful, but Task Manager IMO is more user friendly. In order to get an in-the-middle solution, I recommend &lt;a href=&quot;https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer&quot;&gt;Process Explorer&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/43ce9ca8e4cbb62c7587adaf23c42b42/d7ab4/ProcessExplorer.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 33.108108108108105%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAIAAACHqfpvAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABlElEQVQY0x3Ga0/aUACA4f5vTIgTBKEBlH2TOeeihsXYDRDKZZtjjEEdUlsOBkYPPb2DvQozGZeeNUuevHkJTYEzXXNM/Xmm6DJaWDO8esGbwAJv/+LV0l+v/O0KB/AG+/8n4K+32zUBRmAkICjL4mTS7bO/xwNdHuoKkMYtU4KeLuqGOTfduWnbjustlwHb82zXDRCHn0bZmp6uu2TFitPTdLVDXpeOqEbqfTF18f11RY1cctGrcSQ/eHXOposwSyuJj0LorH9W4YjiDd9sOw8DfM9iAB3NFCVppMlTA0HAC7ctq1yF9a9quQarDfHbD6vP42bbrH3ReOAQtQY7BA5CGyiskWo5z5KKHgwRPEHwyPK/7uTPDa7bEX+2J72exHNzCflDYDEMEkWbSB1dnryhKar3Id9tdfnFH00ROXU69FSBaXVOT+lsNn+cKwXNZC5yuRJF3b89oROJd/U6Q+yEozuhcCxGxvbJQqW8fJkZKjDQI3bnTPM2tp8MhcK7u9FIJJ5MZg4OUkFJ8nBvL14o3PwD/FVOdYkIPTwAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Process Explorer&quot;
        title=&quot;Process Explorer showing detailed memory metrics; Private Bytes, Working Set, and Virtual Size&quot;
        src=&quot;/static/43ce9ca8e4cbb62c7587adaf23c42b42/fcda8/ProcessExplorer.png&quot;
        srcset=&quot;/static/43ce9ca8e4cbb62c7587adaf23c42b42/12f09/ProcessExplorer.png 148w,
/static/43ce9ca8e4cbb62c7587adaf23c42b42/e4a3f/ProcessExplorer.png 295w,
/static/43ce9ca8e4cbb62c7587adaf23c42b42/fcda8/ProcessExplorer.png 590w,
/static/43ce9ca8e4cbb62c7587adaf23c42b42/efc66/ProcessExplorer.png 885w,
/static/43ce9ca8e4cbb62c7587adaf23c42b42/d7ab4/ProcessExplorer.png 1014w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;Process Explorer showing detailed memory metrics; Private Bytes, Working Set, and Virtual Size&lt;/figcaption&gt;
  &lt;/figure&gt;
      
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/a882df5bbd3a0f1b0550532fb3d0d0a7/9fafa/ProcessExplorer2.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 75.67567567567568%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAIAAABr+ngCAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACVElEQVQoz21TyW6cQBDl/78ihyj5iRxiycohShzZM56FGaChV+gVaJZhmxRYiiwrj6JUFLzq2ggKVQgpcmXKquQYM0Z97Trvmlp03gyt77uuafu272+A4TaMcA/bQx9c4+QaXTPMjVboHL6cXnDyG19/0PAb2T1U6CTSNI4YwZxRoqRy1hmtGWOc8WD3fDjvXwUmBWG1tlQxzg8EPclsTw5PjqQMpSQhAtMsRjlhWhQFZehyzVAavJ6PKU7zQittar9e3nfjdB+mZZzvt3EaQaYRsp3meZyWYZyHYQINeQchZrkqsvSXc6aqagcoXVlCB8p/ejMq56S11Fr2Jo2vgjivTVVm+NF74FTu/7Bl2TL28xJ9iuKvUfzlGn22LglCqpQtJYqdsXVdVxvqDe/tFaWrrfZWg66Nar0PjlECgdtk5x1Ma03bGKOUAg1M0HmeKynhXZWd+933/vDYvz52+4desSDGJJcScwGdggFY55IkQQiN46C0LopitYehaRoo+w5Y5k2WcRyDhDOpteAM/FmWcSFAE0KWZYnjGMhhGPqmscZwzu8be9P3lRwTLLVKEZJSQXgojTIGaU/TBNNr2xZWCJyMUkzISl3ekS+04FIJwed5poRqrSml4eUCjbr1t67rUIrgZCgbY/yRvMOG5Op8PIIXOgRnvtWJCV53eRgg0DorawUXH9MOSe5qv0CWM6zQPE/TsmE9AlZqHGRRALNpPCS/bB8AIGjf98H+dLomKeE5whQkIwxlYLAUDEyTjLJcwj/HCyWkBpvnMmXFn1Oyj/Bfd4lBDoT26MwAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Process Explorer System Info&quot;
        title=&quot;Process Explorer showing overall system info&quot;
        src=&quot;/static/a882df5bbd3a0f1b0550532fb3d0d0a7/fcda8/ProcessExplorer2.png&quot;
        srcset=&quot;/static/a882df5bbd3a0f1b0550532fb3d0d0a7/12f09/ProcessExplorer2.png 148w,
/static/a882df5bbd3a0f1b0550532fb3d0d0a7/e4a3f/ProcessExplorer2.png 295w,
/static/a882df5bbd3a0f1b0550532fb3d0d0a7/fcda8/ProcessExplorer2.png 590w,
/static/a882df5bbd3a0f1b0550532fb3d0d0a7/efc66/ProcessExplorer2.png 885w,
/static/a882df5bbd3a0f1b0550532fb3d0d0a7/c83ae/ProcessExplorer2.png 1180w,
/static/a882df5bbd3a0f1b0550532fb3d0d0a7/9fafa/ProcessExplorer2.png 1565w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;Process Explorer showing overall system info&lt;/figcaption&gt;
  &lt;/figure&gt;
      &lt;/p&gt;
&lt;p&gt;Boom! So much info! Visual Studio, why are yous till 32-bit (notice its Virtual Size)? My computer‚Äôs peak memory usage has been at 89% of its limit, not too shabby. This comes in useful &lt;a href=&quot;#debugging-with-memory-info&quot;&gt;later&lt;/a&gt;. &lt;/p&gt;
&lt;h2 id=&quot;debugging-with-memory-info&quot;&gt;Debugging with Memory Info&lt;/h2&gt;
&lt;p&gt;This info is not just some OS trivia. It has time and time helped me debug various problems.&lt;/p&gt;
&lt;p&gt;Most importantly, is figuring out the &lt;em&gt;untouched&lt;/em&gt; parts of committed memory. The paged part of the process represents a very important piece of information: memory committed and not used frequently or rarely used.&lt;/p&gt;
&lt;p&gt;Even if this memory is going to be used occasionally, it is important to realize that this access is going to be expensive, and doing this on the hot path is a no-no. Leaked memory should show up as part of this value too.&lt;/p&gt;
&lt;p&gt;For this reasons, I have previously heard it suggested to remove &lt;code class=&quot;language-text&quot;&gt;PageFiles&lt;/code&gt; completely, effectively making &lt;code class=&quot;language-text&quot;&gt;Private Bytes == Working Set&lt;/code&gt;. However, it‚Äôs a double-edged idea though. This renders the OS unable to discard memory for misbehaving apps, which could sometimes include OS apps allocating data not needed in memory.  &lt;/p&gt;</content:encoded></item><item><title><![CDATA[What happens when you press "X"]]></title><description><![CDATA[or¬†Why it is hard to get Graceful Shutdowns right I used to think shutdowns are easy. You‚Äôre shutting down and the OS is going to take care‚Ä¶]]></description><link>https://mahdytech.com/2018/12/30/what-happens-when-you-press-x/</link><guid isPermaLink="false">https://mahdytech.com/2018/12/30/what-happens-when-you-press-x/</guid><pubDate>Sun, 30 Dec 2018 12:00:32 GMT</pubDate><content:encoded>&lt;h4 id=&quot;or-why-it-is-hard-to-get-graceful-shutdowns-right&quot;&gt;or¬†&lt;em&gt;Why it is hard to get Graceful Shutdowns right&lt;/em&gt;&lt;/h4&gt;
&lt;p&gt;I used to think shutdowns are easy. You‚Äôre shutting down and the OS is going to take care of all my resources. Unfortunately, that‚Äôs not completely the case. Shutdowns are easy, but perfectly graceful ones are not as intuitive. Ungraceful shutdowns bring about crashes, or even worse, unpredicted change to¬†&lt;a href=&quot;https://www.bizety.com/2018/08/21/stateful-vs-stateless-architecture-overview/&quot;&gt;state&lt;/a&gt;, and nobody likes either.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Disclaimer&lt;/em&gt;: Most of my knowledge is limited to windows scenarios, but I‚Äôd imagine most modern Operating Systems have parallel paradigms.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;tl;dr&lt;/em&gt;: globals and TLS objects can make graceful shutdown a nightmare&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#pressing-x-sends-a-signal&quot;&gt;Pressing ‚ÄúX‚Äù sends a signal&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#different-exit-signals-in-windows&quot;&gt;Different Exit Signals in Windows&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#using-a-ctrl-handler&quot;&gt;Using a Ctrl handler&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#threads--global-objects-make-things-tough&quot;&gt;Threads &amp;#x26; Global Objects make things tough&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#just-dont-bother-with-tls&quot;&gt;Just don‚Äôt bother with TLS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;pressing-x-sends-a-signal&quot;&gt;Pressing ‚ÄúX‚Äù sends a signal&lt;/h2&gt;
&lt;p&gt;To start things off, let‚Äôs see what happens when a user ends the application pro-actively. In other words, an exit is triggered by the outside world.&lt;/p&gt;
&lt;p&gt;When a user presses close or ‚ÄúX‚Äù, OS starts a thread in the process (OS is all mighty and it can do such things) and this thread executes signal handling code. The way this works exactly depends on the signal raised.&lt;/p&gt;
&lt;h3 id=&quot;different-exit-signals-in-windows&quot;&gt;Different Exit Signals in Windows&lt;/h3&gt;
&lt;p&gt;Pressing X in Windows emits a¬†&lt;code class=&quot;language-text&quot;&gt;CTRL_CLOSE_EVENT&lt;/code&gt;¬†signal. However, that is not the only signal the user can send to end an app. Others include¬†&lt;code class=&quot;language-text&quot;&gt;CTRL_BREAK_EVENT&lt;/code&gt;¬†(SIGBREAK) and¬†&lt;code class=&quot;language-text&quot;&gt;CTRL_C_EVENT&lt;/code&gt;¬†(SIGINT) that we use frequently to end apps in the command line without having to close the CMD window. There‚Äôs also shutdown/logoff events but I am not going to discuss those.&lt;/p&gt;
&lt;p&gt;Note:¬†In case you‚Äôd like to play around a bit with sending signals, I would personally recommend¬†&lt;a href=&quot;https://github.com/alirdn/windows-kill&quot;&gt;windows-kill&lt;/a&gt;. The old defacto was¬†&lt;a href=&quot;http://web.archive.org/web/20170909040729/http://www.latenighthacking.com/projects/2003/sendSignal/&quot;&gt;SendSignal&lt;/a&gt;¬†but it didn‚Äôt work well enough for myself and¬†&lt;a href=&quot;https://stackoverflow.com/questions/25142403/in-windows-7-how-to-send-a-ctrl-c-or-ctrl-break-to-a-separate-process/53949491#53949491&quot;&gt;others&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;using-a-ctrl-handler&quot;&gt;Using a Ctrl handler&lt;/h3&gt;
&lt;p&gt;While Windows theoretically can just kill apps when users want, that would get a lot of developers mad, including Windows dev themselves. Apps need some time to clean up resources it has consumed, for example saving current work it is doing, or letting the client in a web app know it is shutting down. Because of these reasons, windows allow devs to handle those signals first.&lt;/p&gt;
&lt;p&gt;For Windows Console apps,¬†&lt;code class=&quot;language-text&quot;&gt;SetConsoleCtrlHandler&lt;/code&gt;¬†is the right way to achieve this. For example:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;token macro property&quot;&gt;&lt;span class=&quot;token directive-hash&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;token directive keyword&quot;&gt;include&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&amp;lt;Windows.h&gt;&lt;/span&gt;&lt;/span&gt;

&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;bool&lt;/span&gt; useWantsToExit &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;SetConsoleCtrlHandler&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;DWORD eventType&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;switch&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;eventType&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;case&lt;/span&gt; CTRL_C_EVENT&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;case&lt;/span&gt; CTRL_BREAK_EVENT&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt;
useWantsToExit &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token boolean&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; TRUE&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;// We got an unknown signal, ignore&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; FALSE&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; TRUE&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;token function&quot;&gt;RunMainAppLogic&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;// Add a blocking wait to prevent main from returning unless user wants to exit&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;!&lt;/span&gt;useWantsToExit&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;// Sleep in order not to waste cycles&lt;/span&gt;
&lt;span class=&quot;token function&quot;&gt;Sleep&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;token function&quot;&gt;CleanupResources&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;// Exit gracefully&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It‚Äôs possible to add more and more handlers by doing more calls to¬†&lt;code class=&quot;language-text&quot;&gt;SetConsoleCtrlHandler&lt;/code&gt;. According to¬†&lt;a href=&quot;https://docs.microsoft.com/en-us/windows/console/setconsolectrlhandler&quot;&gt;MS Docs&lt;/a&gt;, handlers are added in a stack and the last handler appended is the first to get executed. Then, if any of them returns true, this list is not processed anymore.&lt;/p&gt;
&lt;p&gt;I have not included¬†&lt;code class=&quot;language-text&quot;&gt;CTRL_CLOSE_EVENT&lt;/code&gt;¬†above because it‚Äôs special. While handling¬†&lt;code class=&quot;language-text&quot;&gt;CTRL_C_EVENT&lt;/code&gt;¬†and¬†&lt;code class=&quot;language-text&quot;&gt;CTRL_BREAK_EVENT&lt;/code&gt;¬†lets the program continue, that‚Äôs not the case for Close, which is the result of pressing¬†&lt;code class=&quot;language-text&quot;&gt;X&lt;/code&gt;. For this one, Windows gives a time limit to the app to exit, after which it kills it no matter what. I could not find documentation for how long that period is, but on my machine, it‚Äôs about 5 seconds.&lt;/p&gt;
&lt;h2 id=&quot;threads--global-objects-make-things-tough&quot;&gt;Threads &amp;#x26; Global Objects make things tough&lt;/h2&gt;
&lt;p&gt;Let‚Äôs get real ‚Äî and make things a little complicated. While single-threaded applications with no global objects or state could be straightforward as shown in the snippet above, that‚Äôs not really exciting (or fast), is it?&lt;/p&gt;
&lt;p&gt;Let‚Äôs first see how processes exit in Windows. There are multiple ways, but the one we‚Äôre discussing here involves windows terminating the process by spawning a thread that calls¬†&lt;code class=&quot;language-text&quot;&gt;ExitProcess()&lt;/code&gt;. This triggers a series of events, the interesting ones for us are about threads and global resources.&lt;/p&gt;
&lt;p&gt;Global resources are tricky. They are constructed &amp;#x26; deconstructed by the C runtime. To overly simplify things, let‚Äôs assume they are constructed¬†before calling main, and deconstructed¬†after all threads signal to the kernel that they have exited.&lt;/p&gt;
&lt;p&gt;See the gotcha here? It‚Äôs the responsibility of the application to relieve any dependency by global objects on threads during those 5 seconds cleanup. Even with heavy use of counter-based pointers, things can get out of hand, for example, if global objects keep others alive for too long by holding on a reference to them. Trying to destruct those abruptly could trigger access violation. For example:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;ServiceHolder&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;shared_ptr&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;Service&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; heldService&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt; globalServiceHolder&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
foo&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; n &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
globalServiceHolder&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;heldService &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;token generic-function&quot;&gt;&lt;span class=&quot;token function&quot;&gt;make_shared&lt;/span&gt;&lt;span class=&quot;token generic class-name&quot;&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;Service&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;amp;&lt;/span&gt;n&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;token function&quot;&gt;DoWorkInAnotherThread&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;SetConsoleCtrlHandler&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;signalHandler&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; TRUE&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;!&lt;/span&gt;signaled&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;


&lt;span class=&quot;token keyword&quot;&gt;delete&lt;/span&gt; n&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;// n has died but service is kept alive by globalServiceHolder&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;// Trying to access n now is UB&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In order to keep things safe, the below model makes sense for which objects can make references to which objects:&lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/b59e3d0b4ebfbe899b2aa865146a3fe3/160a3/Presentation1.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 56.08108108108109%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABoUlEQVQoz33PbU/aUBQH8PutTXyji85IAgMk4sNGp9vCLPhGfGDBAn267e2l0ErpbaETSQSM1sTNLN0SoXflA5STX27OObn/FwdACKvVaqVSWbznF5XzS67eNMwb86a7RPSBEAIQQoIgcFyd5wWZrwrcGYY1y5B7JrRNZQmj0wJGp2OahmF2p/ZVOGTo6JjefaZDJrwtvA0+xjv8434Buo5bUWHt3+DTbyM1bGw6P9bd2rvb5vtZfz/0DuJQbx9EMQ3jFkZ/nYOZk301Ur/aSV9LvLa3w36aeplYgyzQkBqdrSElIPlopl6O/syF3u6L+/3RZp/skzi+XQRIVRRVRSoMejnqpGZOmrqJkVkuKs+s6rPqc5yS+gQUKMsQKlAKrDQliTlJUmfDbZ99lfwyvC/BSRwWTgCUJSmKy2JgJSnZnNvb1F139FNG8JmalyzCbLmVPdUzJZxZNO0PLIo2R/XRN3EKJFEQRUkS+aC7RcnavLdBnVULl/OczzTGhfq40JjEAYsc32zy0lTfpfbq3FqjZKWPj3ZqD3vX9/nr8RL/ASj5AVhykR/CAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Object lifetime hierarchy&quot;
        title=&quot;Logo Title Text 1&quot;
        src=&quot;/static/b59e3d0b4ebfbe899b2aa865146a3fe3/fcda8/Presentation1.png&quot;
        srcset=&quot;/static/b59e3d0b4ebfbe899b2aa865146a3fe3/12f09/Presentation1.png 148w,
/static/b59e3d0b4ebfbe899b2aa865146a3fe3/e4a3f/Presentation1.png 295w,
/static/b59e3d0b4ebfbe899b2aa865146a3fe3/fcda8/Presentation1.png 590w,
/static/b59e3d0b4ebfbe899b2aa865146a3fe3/160a3/Presentation1.png 682w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;Logo Title Text 1&lt;/figcaption&gt;
  &lt;/figure&gt;
      &lt;/p&gt;
&lt;p&gt;In short, bigger rectangles cannot assume smaller ones are alive, especially in their destructors.&lt;/p&gt;
&lt;h2 id=&quot;just-dont-bother-with-tls&quot;&gt;Just don‚Äôt bother with TLS&lt;/h2&gt;
&lt;p&gt;I am not a TLS fan, and I might go into more details into that in another post, but as the last section, I would like to wave a special warning for why TLS (Thread Local Storage) is evil in this context.&lt;/p&gt;
&lt;p&gt;The standard way to initialize TLS storage is using the keyword¬†&lt;code class=&quot;language-text&quot;&gt;thread_local&lt;/code&gt;(&lt;em&gt;shutter&lt;/em&gt;). E.g.:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;token macro property&quot;&gt;&lt;span class=&quot;token directive-hash&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;token directive keyword&quot;&gt;include&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&amp;lt;iostream&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;token macro property&quot;&gt;&lt;span class=&quot;token directive-hash&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;token directive keyword&quot;&gt;include&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&amp;lt;thread&gt;&lt;/span&gt;&lt;/span&gt;

&lt;span class=&quot;token keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; staticvar &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;thread_local&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; tlsvar &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
staticvar&lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
tlsvar&lt;span class=&quot;token operator&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;cout &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;staticvar: &quot;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; staticvar &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;endl&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;cout &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;tlsvar: &quot;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; tlsvar &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;endl&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;cout &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;Output for thread #1: &quot;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;endl&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;thread t1&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
t1 &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;thread&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;foo&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
t1&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;cout &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;endl &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;Output for thread #1: &quot;&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;endl&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
t1 &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;thread&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;foo&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
t1&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;token keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;token comment&quot;&gt;//std output:&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;//&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;//Output for thread #1:&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;//staticvar: 1&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;//tlsvar : 1&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;//&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;//Output for thread #1:&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;//staticvar: 2&lt;/span&gt;
&lt;span class=&quot;token comment&quot;&gt;//tlsvar : 1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The problem with TLS is mostly about the added complexity. On one hand, lifetime management becomes even more complicated, especially that there‚Äôs if there‚Äôs TLS, there are usually global objects and lifetimes have to be managed carefully. On the other hand, maintaining TLS code is no fun. It is a bit of a steep curve and I have rarely seen anyone making a change to a TLS-heavy part of the code, for the first time, bug-free.In my experience, a mix of¬†&lt;a href=&quot;https://mahdytech.com/2018/12/30/what-happens-when-you-press-x/2018/12/23/fast-services-cpp/&quot;&gt;thread &amp;#x26; object pools&lt;/a&gt;¬†can replace TLS in most cases.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Elements of Fast Services with C++]]></title><description><![CDATA[‚ÄúComputers are really fast‚Äù said my friend to me a while ago, as I was trying to figure out how to optimize the hottest path in my service‚Ä¶]]></description><link>https://mahdytech.com/2018/12/23/fast-services-cpp/</link><guid isPermaLink="false">https://mahdytech.com/2018/12/23/fast-services-cpp/</guid><pubDate>Sun, 23 Dec 2018 12:00:32 GMT</pubDate><content:encoded>&lt;blockquote&gt;
&lt;p&gt;‚ÄúComputers are really fast‚Äù said my friend to me a while ago, as I was trying to figure out how to optimize the hottest path in my service. ‚ÄúIt is almost always the IO‚Äù he added. It‚Äôs been 3 years since, and I have learnt a bit more about computers, but I still clearly recall his saying as the root cause for too many problems.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Writing fast C++ services is a mix of following the right patterns, while, obviously enough, evading the wrong patterns. I would like to focus in this post on memory-related topics, for the reason my good friend mentions above.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Tl;dr&lt;/em&gt;: use arenas and object pools, use vectors sometimes, and don‚Äôt allocate on the hot path.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#the-right-tools&quot;&gt;The Right Tools&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#arena-allocators&quot;&gt;Arena Allocators&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#object-pools&quot;&gt;Object Pools&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#the-right-data-structures&quot;&gt;The Right Data Structures&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#stdvectoris-king&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;std::vector&lt;/code&gt;¬†is king&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#a-word-of-caution&quot;&gt;A word of caution:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#dont-be-afraid-of-hybrid-data-structures&quot;&gt;Don‚Äôt be afraid of hybrid data structures&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;#the-wrong-practices&quot;&gt;The Wrong Practices&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#allocating-on-the-hot-path&quot;&gt;Allocating on the hot path&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#stdmap-erything&quot;&gt;std::map er‚Äôything&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#final-words&quot;&gt;Final Words&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-right-tools&quot;&gt;The Right Tools&lt;/h2&gt;
&lt;p&gt;Having the right tools at an arm‚Äôs length, and getting comfortable using them can make the difference between fast and slow code.&lt;/p&gt;
&lt;h3 id=&quot;arena-allocators&quot;&gt;Arena Allocators&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-text&quot;&gt;Arenas&lt;/code&gt;¬†are awesome. Basically, they pre-allocate big chunks of memory when they are created, then they work as a memory manager. That big sloth object that you need to allocate a 1000 of, and it causes your services to hang for several precious milliseconds? No need.¬†&lt;code class=&quot;language-text&quot;&gt;Arenas&lt;/code&gt;¬†will give out that memory at runtime at almost no performance surcharge (given that it‚Äôs needed to pre-configure them to have enough memory beforehand).&lt;/p&gt;
&lt;p&gt;
  &lt;figure class=&quot;gatsby-resp-image-figure&quot; style=&quot;&quot;&gt;
  
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/15b12db5d7380bab6867427f5f45ac26/5a791/Media.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 68.91891891891892%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACDUlEQVQ4y6VUyZLTMBDN/9+4UcVMzQAHDtwowmTgzpkiq7N6ieNMHCe2402L/WjJ44wzobigqucXqVut7n5SOlVV4X/G6/0d9UnTFEEQIAxD7HyfsIe/D7APDrReQ80VH44hfLIfwwhSylbQSrMOqAJZlgV77cJ/2mC3dbDdWDj4Gzx5NgJin9ai4w5hsIXnmjjuPcjyJWCTZ+ci5TxA96eH2wcXH767uO+tcffg4P5xjfePLu56jl77+GODm29r2KYLFGEdrGplyBhDnheoWIqpHeLXPER/EWKwijA0YwyWhFWMIaG/rG3KJ44SVDxHRnubTHXAoigghLhuuGQQPANnGSRtlKLQvboUhQrL85eATcnqW+q0iUv1W4mVIz4lZ5ySlA4utU2h9m0OaJW8JwVnszmWqxWmxLP5ApbtwLQcGNMZJsZMz42psi21z2A4JiFtHbAJeg64WCzQ7/cxmkwwHv4mVT2VL4GTF68ZpGjFiEUNWheCt7Jr3UPGOE5RhHS7wqeegTefDdx2Lbz7al7gpuGuibdfTDjmRqtcvlZZ9U5KWpYFTC/FyCJodSPNYyvRCjfzkXUi1U+IY6VyAcblZclZlumro0cpkKUxcVPO87zOQw9epGB5UrtTqUmSXKvc9EJdnyzLdRuUhXOhDxT0zBpVc7pmyqcsy6s33Tk/nWf86+H/7Y+kvU/xH0FRLxDXhavGAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Arena sequence&quot;
        title=&quot;Arena sequence&quot;
        src=&quot;/static/15b12db5d7380bab6867427f5f45ac26/fcda8/Media.png&quot;
        srcset=&quot;/static/15b12db5d7380bab6867427f5f45ac26/12f09/Media.png 148w,
/static/15b12db5d7380bab6867427f5f45ac26/e4a3f/Media.png 295w,
/static/15b12db5d7380bab6867427f5f45ac26/fcda8/Media.png 590w,
/static/15b12db5d7380bab6867427f5f45ac26/efc66/Media.png 885w,
/static/15b12db5d7380bab6867427f5f45ac26/c83ae/Media.png 1180w,
/static/15b12db5d7380bab6867427f5f45ac26/5a791/Media.png 1248w&quot;
        sizes=&quot;(max-width: 590px) 100vw, 590px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
  &lt;figcaption class=&quot;gatsby-resp-image-figcaption&quot;&gt;Arena sequence&lt;/figcaption&gt;
  &lt;/figure&gt;
      &lt;/p&gt;
&lt;p&gt;Google has a decent¬†&lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/reference/arenas&quot;&gt;implementation&lt;/a&gt;, or if you‚Äôre feeling adventurous go write your own implementation! Heads-up, Integrating it with STL can be a tad tricky.&lt;/p&gt;
&lt;h3 id=&quot;object-pools&quot;&gt;Object Pools&lt;/h3&gt;
&lt;p&gt;Some objects are just expensive to construct. Instead of doing that millions of time over the course of an service‚Äôs uptime, why not just do it a few dozen times, and re-use them? That‚Äôs what¬†&lt;code class=&quot;language-text&quot;&gt;Object Pools&lt;/code&gt;¬†are. For example:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;&lt;span class=&quot;token keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;token class-name&quot;&gt;Program&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;token function&quot;&gt;Program&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token keyword&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;token keyword&quot;&gt;void&lt;/span&gt; RepeatedOperation
    &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;token keyword&quot;&gt;auto&lt;/span&gt; expensiveObject &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; myObjectPool&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;TakeOne&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;token comment&quot;&gt;// use the expensive object&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;
    &lt;span class=&quot;token comment&quot;&gt;// When we&apos;re done using it, it&apos;s returned to the pool and can be re-used&lt;/span&gt;
    &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;token comment&quot;&gt;// To top it off, &apos;RepeatedOperation&apos; is thread-safe! Every thread gets its own instance.&lt;/span&gt;

&lt;span class=&quot;token keyword&quot;&gt;private&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;:&lt;/span&gt;
    ObjectPool&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;ExpensiveObject&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; myObjectPool&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There‚Äôs a¬†&lt;a href=&quot;https://sourcemaking.com/design_patterns/object_pool&quot;&gt;nice explanation&lt;/a&gt;¬†for the pattern. I highly recommend getting one‚Äôs hand dirty with an example. Getting those two techniques in one‚Äôs toolbox can get you far in terms of performance!&lt;/p&gt;
&lt;h2 id=&quot;the-right-data-structures&quot;&gt;The Right Data Structures&lt;/h2&gt;
&lt;p&gt;Not all Data structures are created equal. Different situations call for different ones, and our go-tos are not always optimal.&lt;/p&gt;
&lt;h3 id=&quot;stdvector-is-king&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;std::vector&lt;/code&gt;¬†is king&lt;/h3&gt;
&lt;p&gt;Vector achieves a sweet spot between ease of use, as well as high efficiency through data locality. It allows you to just occupy a memory block, as is:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;cpp&quot;&gt;&lt;pre class=&quot;language-cpp&quot;&gt;&lt;code class=&quot;language-cpp&quot;&gt;td&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;vector&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; vec&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;token keyword&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt; ptr &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token generic-function&quot;&gt;&lt;span class=&quot;token function&quot;&gt;reinterpret_cast&lt;/span&gt;&lt;span class=&quot;token generic class-name&quot;&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;vec&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// Of course it&apos;s possible to use an int*, but char* has the advantage of accessing memory 1 byte at a time&lt;/span&gt;
std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;cout &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token generic-function&quot;&gt;&lt;span class=&quot;token function&quot;&gt;reinterpret_cast&lt;/span&gt;&lt;span class=&quot;token generic class-name&quot;&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt;ptr&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;endl&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// Outputs 1, the first element&lt;/span&gt;
ptr &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; ptr &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// Add 4 bytes (size of an int)&lt;/span&gt;
std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;cout &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;token generic-function&quot;&gt;&lt;span class=&quot;token function&quot;&gt;reinterpret_cast&lt;/span&gt;&lt;span class=&quot;token generic class-name&quot;&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;token keyword&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;*&lt;/span&gt;ptr&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; std&lt;span class=&quot;token double-colon punctuation&quot;&gt;::&lt;/span&gt;endl&lt;span class=&quot;token punctuation&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;token comment&quot;&gt;// Outputs 2, the second element&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The code above shows how what you see in a vector is what you get. That‚Äôs why in my day-to-day coding, vector is by far my most used data structure. Memory is arranged in the same way it‚Äôs expected to be, and that‚Äôs very nice for cache.&lt;/p&gt;
&lt;p&gt;See, cache lines are usually 64 bytes. That means whenever you access an element, say¬†&lt;code class=&quot;language-text&quot;&gt;vec[1]&lt;/code&gt;, not only this element gets cached. Rather, the whole cache line gets cached, which usually means its surroundings are also put in cache. And memory access is not so bad any more!&lt;/p&gt;
&lt;h4 id=&quot;a-word-of-caution&quot;&gt;A word of caution:&lt;/h4&gt;
&lt;p&gt;Vectors are sweet, but in order to fully exploit their powers, it‚Äôs always recommended to reserve them first.¬†&lt;code class=&quot;language-text&quot;&gt;std::vector&lt;/code&gt;¬†offers the great¬†&lt;code class=&quot;language-text&quot;&gt;reserve()&lt;/code&gt;¬†method to allow for alleviating some of the pains of allocating memory on the hot path. Of course, we cannot always know how big vectors are going to be. But when we do ‚Ä¶&lt;/p&gt;
&lt;h3 id=&quot;dont-be-afraid-of-hybrid-data-structures&quot;&gt;Don‚Äôt be afraid of hybrid data structures&lt;/h3&gt;
&lt;p&gt;As nice as it might be to always use a std::vector&amp;#x3C;&gt;, some situations ask for a more complicated data structures. A prime example of that is¬†&lt;a href=&quot;https://www.boost.org/doc/libs/1_69_0/doc/html/boost/container/small_vector.html&quot;&gt;boost::small_vector&lt;T&gt;&lt;/a&gt;. I, for one, was very happy when I found out such a thing exists! It‚Äôs basically the child of an array + vector. It does not use dynamic allocation, unless it grows over a¬†&lt;code class=&quot;language-text&quot;&gt;constexpr N&lt;/code&gt;, in which case it starts allocating. A prime use case is when it‚Äôs¬†&lt;em&gt;expected&lt;/em&gt;¬†to have no more than¬†&lt;code class=&quot;language-text&quot;&gt;N&lt;/code&gt;¬†elements, but it‚Äôs not the end of the world if we need one or two more elements.&lt;/p&gt;
&lt;h2 id=&quot;the-wrong-practices&quot;&gt;The Wrong Practices&lt;/h2&gt;
&lt;p&gt;Not trying to sound standoffish, but these are a couple of my pet-peeves.&lt;/p&gt;
&lt;h3 id=&quot;allocating-on-the-hot-path&quot;&gt;Allocating on the hot path&lt;/h3&gt;
&lt;p&gt;Allocate all (at least most) of the memory needed at startup, before serving traffic (opening the port). The tools mentioned above (Arenas + Object Pools) can make a perfect team to achieve that. On a typical month, a change adding a memory allocation on the hotpath is responsible for 90% of latency pumps. Unfortunately, as much as arenas offer of help to latency, in my experience, they are usually alien to the codebase hosting them, unless it‚Äôs an arena-native code (kudos!). Having no previous experience using them makes it extra hard to add changes too.&lt;/p&gt;
&lt;h3 id=&quot;stdmap-erything&quot;&gt;std::map er‚Äôything&lt;/h3&gt;
&lt;p&gt;Now I have no problem with std::map, but over-using them can be bad sometimes. For maps to offer O(logn) search, n is gotta be sizeable. If N is gonna be 3 elements, it‚Äôs almost never worth the hassle of a map. An array together with linear search is¬†&lt;a href=&quot;https://terrainformatica.com/2017/10/15/when-linear-search-is-faster-than-stdmapfind-and-stdunordered_mapfind/&quot;&gt;usually faster&lt;/a&gt;. Keep in mind that maps/sets always allocate (unless an arena is used). Unlike vectors, we can‚Äôt reserve() maps.&lt;/p&gt;
&lt;h2 id=&quot;final-words&quot;&gt;Final Words&lt;/h2&gt;
&lt;p&gt;This is by far an incomplete set. For example, there are many topics that could have been covered including threading and communication models, but I hope I can cover these in their own posts.&lt;/p&gt;
&lt;p&gt;My point of view is a bit painted by my cloud backgound, but I would expect this to apply in other areas of native programming. Let me know what‚Äôs on your hot list in the comments! (especially for other languages!)&lt;/p&gt;</content:encoded></item></channel></rss>