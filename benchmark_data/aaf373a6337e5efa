<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="https://willpatrick.xyz/feed.xml" rel="self" type="application/atom+xml" /><link href="https://willpatrick.xyz/" rel="alternate" type="text/html" /><updated>2025-07-08T18:19:52+00:00</updated><id>https://willpatrick.xyz/feed.xml</id><entry><title type="html">Teaching LLMs how to solid model</title><link href="https://willpatrick.xyz/technology/2025/04/23/teaching-llms-how-to-solid-model.html" rel="alternate" type="text/html" title="Teaching LLMs how to solid model" /><published>2025-04-23T18:00:00+00:00</published><updated>2025-04-23T18:00:00+00:00</updated><id>https://willpatrick.xyz/technology/2025/04/23/teaching-llms-how-to-solid-model</id><content type="html" xml:base="https://willpatrick.xyz/technology/2025/04/23/teaching-llms-how-to-solid-model.html"><![CDATA[<p>It turns out that LLMs can make CAD models for simple 3D mechanical parts. And, I think they‚Äôll be extremely good at it soon.</p>

<ul>
  <li>See discussion on <a href="https://news.ycombinator.com/item?id=43774990">HackerNews</a></li>
  <li><a href="https://github.com/wgpatrick/cadeval">GitHub Repo</a> for Text-to-CAD Evaluation</li>
  <li><a href="https://willpatrick.xyz/cadevalresults_20250422_095709/">Results dashboard</a></li>
</ul>

<h2 id="an-ai-mechanical-engineer">An AI Mechanical Engineer</h2>

<p>Code generation is the first breakthrough application for LLMs. What would an AI agent look like for mechanical engineering? Material selection, design for manufacturing, computer-aided manufacturing (CAM), and off-the-shelf part comparison would all be important features of an AI mechanical engineer. Perhaps, most importantly, an AI mechanical engineer would design and improve CAD models. Mechanical engineers typically design CAD using point-and-click software (e.g. Fusion 360, Solidworks, and Onshape). How could AI generate these solid models instead?</p>

<h2 id="code-generation-meets-cad">Code generation meets CAD</h2>

<p>One promising direction is training a generative model on millions of existing CAD files. This approach is being actively researched by <a href="https://damassets.autodesk.net/content/dam/autodesk/www/pdfs/brepgen.pdf">multiple</a> <a href="https://arxiv.org/pdf/2105.09492">teams</a> who are investigating both diffusion and transformer architectures. In particular, I like <a href="https://www.youtube.com/watch?v=5r1qQ5DOsUI">Autodesk Research</a>‚Äôs approach to encode the parametric primitives (points, curves, shapes, extrusions, etc) into a transformer architecture. However, as far as I understand, the models in these projects cannot yet take an arbitrary input command and generate a desired shape.</p>

<p>Then a few weeks ago, I was inspired by the <a href="https://github.com/ahujasid/blender-mcp">recent use of LLMs to drive Blender</a>, the open source modeling tool widely used for animation. Given that LLMs are incredibly good at generating code, perhaps programmatic interfaces for CAD modeling could be used to generate solid models in a similar way. I immediately thought of <a href="https://openscad.org/">OpenSCAD</a>, an open-source programmatic CAD tool that‚Äôs been developed for more than 15 years. Instead of using point-and-click software to create a solid model, the user writes a software script, which is then rendered into the solid CAD model.</p>

<h2 id="llms-rock-at-writing-openscad">LLMs rock at writing OpenSCAD</h2>

<p>To test it out, I created a simple project in Cursor, made a blank OpenSCAD script (Cursor.scad), and added some Cursor rules:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Your rule content

- We're creating files to model things in open scad. 
- All the OpenScad files you create will be in Cursor.scad. I've set up this file such that if you edit it, it will automatically be read by OpenScad (it's the open file in the program). 
- If I want to save what you've done, I'll tell you and you should create a new file and put it in the Saved folder. 
- That's it! Overtime, if needed, we could create documentation about how to use OpenScad. 
- If I'm asking you to create a new design, you should delete the current contents of cursor.scad and add the new design into it.
- When I make requests you should always first develop a step by step plan. Then tell me the step by step plan. And then I'll tell you to start modeling. 
- When you're going through the step by step plans, only execute one step at a time. 
- When you've executed a step, ask the user if its right.
</code></pre></div></div>

<p>Then, I started using Cursor to create solid models.</p>

<p>Here‚Äôs an example:  ‚ÄúCreate an iPhone case‚Äù.</p>

<p><img src="/assets/images/blog/iphone.gif" alt="iPhone GIF" /></p>

<p>It didn‚Äôt nail it on the first try, but with a couple of iterations (including giving it screenshots) we created a basic case.</p>

<p>You can also leverage OpenSCAD libraries (there are many public ones). Here, I use a library to make a thread for a flange.</p>

<p><img src="/assets/images/blog/flange.gif" alt="Flange GIF" /></p>

<p>One thing that‚Äôs pretty neat is that the LLM can use its general knowledge of mechanical engineering. For example, above, Cursor created holes in the pipe for M6 bolts and it correctly made the diameter slightly bigger than 6 mm, so the bolts could pass through.</p>

<pre><code class="language-openscad">bolt_hole_d = 6.5; // Diameter for M6 bolts
</code></pre>

<p>Of course, one of the really nice things about this approach is that the files are editable and Cursor defaults to parameterizing all the key elements of the design. In the above example, I asked it to add holes for mounting bolts, which it did, and then I edited the number of holes manually to 3 from 4.</p>

<pre><code class="language-openscad">// Flange parameter
flange_OD = 50; // Outer diameter of the flange in mm 
flange_thickness = 10; // Thickness of the flange in mm
pipe_size = 1/2; // NPT Pipe Size

// Bolt hole parameters
num_bolts = 3;
bolt_hold_d = 6.5; // Diameter for M6 bolts
bold_hole_circle = 35; // Diameter for the bolt circle
</code></pre>

<h2 id="building-an-eval-for-llm---openscad---stl">Building an eval for LLM -&gt; OpenSCAD -&gt; STL</h2>

<p>I was impressed by these initial results but I wanted to learn more. For example, did the model‚Äôs reasoning ability help it think through the steps of creating a part? So, I decided to develop an evaluation to test the performance of various LLMs at generating solid models via OpenSCAD.</p>

<p>One of the challenges with creating an eval for CAD design is that most tasks have many correct answers. For example, a task such as ‚Äúmake a m3 screw that‚Äôs 10mm long‚Äù could have many correct answers because the length, diameter, and style of the head are not defined in the task. To account for this, I decided to write the tasks in my eval such that there was only a single, correct interpretation of the geometry.</p>

<p>For example, here is one of the tasks in the eval:</p>

<blockquote>
  <p>This is a 3mm thickness rectangular plate with two holes.</p>

  <ol>
    <li>
      <p>The plate is 18mm x 32mm in dimension.</p>
    </li>
    <li>
      <p>When looking down at the plate, it has two holes that are drilled through it. In the bottom left of the plate, there‚Äôs a hole with a centerpoint that is 3mm from the short (18mm) side and 3 mm from the long (32mm) side. This hole has a diameter of 2mm.</p>
    </li>
    <li>
      <p>In roughly the top left corner of plate, there‚Äôs a hole of diameter 3mm. Its center point is 8mm from the short side (18mm side) and 6mm away from the long (32mm) side.</p>
    </li>
  </ol>
</blockquote>

<p>The benefit of this approach is that we can score each task as a Pass or Fail and we can do this in an automated way. I wrote 25 total CAD tasks which ranged in difficulty from a single operation (‚ÄúA 50mm long pipe that has a 10mm outer diameter and 2mm wall thickness‚Äù) to 5 sequential operations. For each task, I designed a reference CAD model using Autodesk Fusion 360 and then exported a STL mesh file.</p>

<p>Then, I set about programming the automated eval pipeline (of course, <a href="https://willpatrick.xyz/software/2025/03/17/software-with-a-market-of-one.html">I didn‚Äôt actually write much code</a>).</p>

<p>Here is how the eval pipeline works:</p>

<ol>
  <li>For each task and model, the eval sends the text prompt (along with a system prompt) to the LLM via API.</li>
  <li>The LLM sends back the openSCAD code.</li>
  <li>The openSCAD code is rendered into a STL</li>
  <li>The generated STL is automatically checked against the reference STL</li>
  <li>The task ‚Äúpasses‚Äù if it passes a number of geometric checks.</li>
  <li>The results are then outputted in a dashboard.</li>
</ol>

<div class="mermaid">
graph LR
    A[Start Eval For each Task &amp; Model] --&gt; B{Send System + Task Prompt to LLM};
    B --&gt; C[LLM Returns OpenSCAD];
    C --&gt; D{Render OpenSCAD to STL};
    D --&gt; E{Compare Generated STL to Reference STL};
    E --&gt; I[Output Eval Results to Dashboard];
</div>

<p>[Note: The eval runs multiple replicates per task x model combo. And the eval is executed in parallel, because there can be 1000+ tasks when running the full evaluation.]</p>

<p>Here‚Äôs how the geometric check works:</p>

<ul>
  <li>The generated STL and reference STL are aligned using the iterative closest point (ICP) algorithm.</li>
  <li>The aligned meshes are then compared by:
    <ul>
      <li>Their volumes (pass = &lt;2% diff)</li>
      <li>Their bounding boxes (pass = &lt;1 mm)</li>
      <li>The average chamfer distance between the parts (pass = &lt;1 mm)</li>
      <li>The Hausdorff distance (95% percentile) (pass = &lt;1 mm)</li>
    </ul>
  </li>
  <li>To ‚Äúpass‚Äù the eval, all of the geometric checks must be passed.</li>
</ul>

<p>There are a few areas where the eval pipeline could be improved. In particular, false negatives are common (est: ~5%). I‚Äôve also noticed that occasionally, small features that are incorrect (like a small radius fillet) are not caught by the automated geometry check. Nevertheless, the eval pipeline is still good enough to see interesting results and compare the performance of the various LLMs.</p>

<p>If you‚Äôd like to learn more about the eval, use it, or check out the tasks, please check out the <a href="https://github.com/wgpatrick/cadeval">GitHub repo</a>.</p>

<p>Finally, there are a number of ways to improve the evaluation. Here are a few things that I‚Äôd like to do next:</p>

<ul>
  <li>More tasks with greater coverage</li>
  <li>Optimize system prompts, in particular by adding OpenSCAD documentation and code snippets</li>
  <li>Create an eval variation that uses sketches and drawings as input</li>
  <li>Add another variation that tests the ability of the LLM to add operations to existing OpenSCAD script and STL</li>
  <li>Evaluate the ability of the LLM to fix mistakes in an existing STL / OpenSCAD code</li>
</ul>

<h2 id="rapid-improvement-of-frontier-models">Rapid improvement of frontier models</h2>

<p>Here are the results from an eval run executed on April 22, 2025. In the eval run, 15 different models were tested on the 25 tasks with 2 replicates were task. All of the results and configuration details from the run are available <a href="https://willpatrick.xyz/cadevalresults_20250422_095709/">here</a>.</p>

<p>The results show that LLMs only became good at OpenSCAD solid modeling recently.</p>

<figure>
  <img src="/assets/images/blog/overall_result2.png" alt="Results from CadEval" />
  <figcaption>Results from CadEval. In this run, each model attempted to complete 25 tasks (2 replicates per task). "Success" means they passed a number of geometric checks that compared to a reference geometry.</figcaption>
</figure>

<p>The top 3 models were all launched while I was working on the project and the top 7 models are all reasoning models. These models offer large performance increases compared to their predecessor, non-reasoning counterparts. Sonnet 3.5 is the best non-reasoning model and Sonnet 3.7 is only slightly better performing in the eval (for Sonnet 3.7, thinking was used with a budget of 2500 tokens).</p>

<p>Digging into the results offers some interesting insights. First, the LLMs are quite good at generating OpenSCAD code that compiles correctly and can be rendered into a STL. In other words, only a small portion of the failures are coming from things like OpenSCAD syntax errors. Anthropic‚Äôs Sonnet models are the best at this.</p>

<figure>
  <img src="/assets/images/blog/stl_render_success.png" alt="Rendering Success Rate" />
  <figcaption>For the same eval run as above, the % of tasks for each model where a STL was rendered (and the geometry was checked).</figcaption>
</figure>

<p>Additionally, we can look at the success rate for tasks where a STL was rendered. The o3-mini is quite strong, with nearly the same sucess rate as the full-size o3 model, while Sonnet 3.7 appears to be a step behind the leading Gemini 2.5 Pro and o1, o3, o4-mini, and o3-mini models.</p>

<figure>
  <img src="/assets/images/blog/success_rate_for_only_tasks_with_rendered_stl.png" alt="Success Rate if STL Rendered" />
  <figcaption>Of tasks where a STL was generated, the % of tasks that successfully passed all geometric checks.</figcaption>
</figure>

<p>Finally, to be expected, Gemini 2.5 and o4-mini are substantially cheaper and slightly faster to run than the full o3 and o1 models.</p>

<figure>
  <img src="/assets/images/blog/average_estimated_cost.png" alt="Average cost per task for various models" />
  <figcaption>The estimated cost per task for each model.</figcaption>
</figure>

<figure>
  <img src="/assets/images/blog/average_estimated_time.png" alt="Average time per task for various models" />
  <figcaption>The average total time per task to generate OpenSCAD and then render a STL. The time to make the API call and receive the OpenSCAD is much, much greater than the time to render the STL, which is  less than 1 second. </figcaption>
</figure>

<p>As expected, some tasks were easy and some tasks were hard to complete.</p>

<figure>
  <img src="/assets/images/blog/task_success_rate.png" alt="Pass rate for each of the 25 tasks" />
  <figcaption>Overall success rate task by task.</figcaption>
</figure>

<p>Generally, speaking tasks with more operations we‚Äôre more challenging.</p>

<figure>
  <img src="/assets/images/blog/part_complexity.png" alt="Pass rate by part complexity" />
  <figcaption>Each task required 1 to 5 operations to complete manually in Fusion360. Within the eval, there were 5 tasks that required a single operation, 5 required two, and so forth. </figcaption>
</figure>

<p>Tasks 2, Task 3, and Task 6 were the easiest tasks with over 80% correct across models. Here‚Äôs what these tasks looked like with example successes.</p>

<div class="carousel blog-carousel">
  <div class="carousel-container">
    <figure class="carousel-slide">
      <img src="/assets/images/blog/easy_task2.png" alt="Easy Task 2 Example" class="carousel-image" />
    </figure>
    <figure class="carousel-slide">
      <img src="/assets/images/blog/easy_task3.png" alt="Easy Task 3 Example" class="carousel-image" />
    </figure>
    <figure class="carousel-slide">
      <img src="/assets/images/blog/easy_task6.png" alt="Easy Task 6 Example (substituted for easy_task4)" class="carousel-image" />
    </figure>
  </div>
  <button class="carousel-button prev" onclick="moveCarousel(-1, this)">‚ùÆ</button>
  <button class="carousel-button next" onclick="moveCarousel(1, this)">‚ùØ</button>
  <div class="carousel-dots"></div>
</div>

<p>Only 2 tasks had 0% success, task 11 and task 15. Here are the prompts for those two tasks and representative failures.</p>

<div class="carousel blog-carousel">
  <div class="carousel-container">
    <figure class="carousel-slide">
      <img src="/assets/images/blog/hard_task11.png" alt="Hard Task 11 Example" class="carousel-image" />
    </figure>
    <figure class="carousel-slide">
      <img src="/assets/images/blog/hard_task15.png" alt="Hard Task 15 Example" class="carousel-image" />
    </figure>
  </div>
  <button class="carousel-button prev" onclick="moveCarousel(-1, this)">‚ùÆ</button>
  <button class="carousel-button next" onclick="moveCarousel(1, this)">‚ùØ</button>
  <div class="carousel-dots"></div>
</div>

<p>These failures are both interesting and quite different. Task 11 is a good example of poor spatial reasoning. In the specific failure highlighted in the image, the model extrudes the shank of the eyebolt  orthogonally to the torus (instead of in the same plane). Task 15 is a different failure mode. It‚Äôs hard to see in the attached image, but if you zoom in closely, it‚Äôs clear that the generated shape is slightly larger than the reference shape (which makes sense, because the generated STL failed the volume check). From looking at the OpenSCAD code for this example, it appears that the failure is due to using OpenSCAD‚Äôs <a href="https://www.openscad.info/index.php/2020/10/18/hull/">hull operation</a>, which is not precisely the same as a loft operation. OpenSCAD does not have a loft operation built-in.</p>

<p>Tasks 20-24 all required 5 sequential operations and the average success rate for these tasks ranged from 3.3% to 30%. Here are the prompts for those 5 tasks with representative successes and failures.</p>

<p>The failures can be tricky to spot. The green areas of the failed images should have geometry in the generated STL, but do not (the reference point cloud is plotted in green). Likewise, the red areas have geometry in the generated STL, but they shouldn‚Äôt.</p>

<div class="carousel blog-carousel">
  <div class="carousel-container">
    <figure class="carousel-slide">
      <img src="/assets/images/blog/5part_task20.png" alt="5-Part Task 20 Example" class="carousel-image" />
    </figure>
    <figure class="carousel-slide">
      <img src="/assets/images/blog/5part_task21.png" alt="5-Part Task 21 Example" class="carousel-image" />
    </figure>
    <figure class="carousel-slide">
      <img src="/assets/images/blog/5part_task22.png" alt="5-Part Task 22 Example" class="carousel-image" />
    </figure>
    <figure class="carousel-slide">
      <img src="/assets/images/blog/5part_task23.png" alt="5-Part Task 23 Example" class="carousel-image" />
    </figure>
    <figure class="carousel-slide">
      <img src="/assets/images/blog/5part_task24.png" alt="5-Part Task 24 Example" class="carousel-image" />
    </figure>
  </div>
  <button class="carousel-button prev" onclick="moveCarousel(-1, this)">‚ùÆ</button>
  <button class="carousel-button next" onclick="moveCarousel(1, this)">‚ùØ</button>
  <div class="carousel-dots"></div>
</div>

<h2 id="start-ups">Start-ups</h2>

<p>In the past few months, two different start-ups launched text-to-CAD products, AdamCad and Zoo.dev. Zoo.dev offers an API to use their text-to-CAD model. Zoo‚Äôs demos of their API and text-to-CAD product are very cool and look quite similar to the Cursor -&gt; OpenSCAD demo I have above.</p>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We're excited to announce the launch of Zoo.dev, a text-to-CAD API that lets you generate 3D models from text descriptions.<br /><br />We've been working on this for the past year, and we're finally ready to share it with the world.<br /><br />Here's a thread on what we've built üßµ <a href="https://t.co/Yd9Yd9Ixqm">pic.twitter.com/Yd9Yd9Ixqm</a></p>&mdash; Abhishek (@abhi1thakur) <a href="https://twitter.com/abhi1thakur/status/1881766438383337573?ref_src=twsrc%5Etfw">July 21, 2024</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>I added Zoo into the eval pipeline to compare against LLM -&gt; OpenSCAD -&gt; STL. Instead of generating OpenSCAD, the Zoo.dev API shoots back a STL directly. Zoo says they use <a href="https://zoo.dev/machine-learning-api">a proprietary dataset and machine learning model</a>. To my surprise, Zoo‚Äôs API didn‚Äôt perform particularly well in comparison to LLMs generating STLs by creating OpenSCAD. Despite that, I‚Äôm excited to see the development of Zoo.dev and I will be eager to see how future model launches from Zoo.dev compare to LLMs creating OpenSCAD.</p>

<h2 id="whats-next">What‚Äôs next?</h2>

<p>I think these initial results are promising. Cursor (or another coding agent) + OpenSCAD offers a solution for producing solid models in an automated way.</p>

<p>However, I don‚Äôt think this approach is about to take off and spread rapidly through the CAD design ecosystem. The current set-up is seriously clunky and I think substantial product improvements are needed to make this work better. Similar to how Cursor, Windsurf, and other tools have developed specific UX and LLM workflows for code generation, I imagine there will be substantial work required to develop workflows and UX that make sense for CAD generation. Here are a few ideas that I think could be worth pursuing in this direction:</p>

<ul>
  <li>Tools that bring in console logs and viewport images to Cursor from OpenSCAD for iterative improvement and debugging.</li>
  <li>A UI to highlight (and measure) certain faces, lines, or aspects of a part, which are fed to the LLM for additional context.</li>
  <li>Drawing or sketch-input, so the user can quickly visually communicate their ideas.</li>
  <li>A UI with sliders to adjust parameters instead of editing the code.</li>
</ul>

<p>Additionally, I expect that further model advances will continue to unlock this application. In particular, improving spatial reasoning is an <a href="https://arxiv.org/pdf/2504.05786">active area of research</a>. I imagine that improved spatial reasoning could greatly improve models‚Äô ability to design parts step by step.</p>

<p>So when does text-to-CAD become a commonly used tool for mechanical engineers? With start-ups actively building products and the rapid improvement of frontier models, my guess would be something like 6-24 months.</p>

<h2 id="where-does-this-go">Where does this go?</h2>

<p>In the medium to long term (2-10 years), I imagine that most parts will be created with a form of GenCAD. Allow me to speculate.</p>

<ul>
  <li>Initially, GenCAD will be used to create parts that fit within existing assemblies. For example, you might say: ‚ÄúI need a bracket that fits here.‚Äù  And, the GenCAD tool will create a bracket that perfectly joins with the existing assembly components. Want to analyze three variants with FEA? Ask for them. I expect mainstream CAD suites (Autodesk, Solidworks, Onshape) to add these capabilities directly into their product suite.</li>
  <li>Longer term, I imagine GenCAD will reach every aspect of a CAD suite: sketches, mates, assemblies, exploded views, CAM tool-pathing, rendering visualizations, and CAE. Imagine a design review where you highlight a subassembly and say ‚Äúreplace these rivets with M6 countersunk screws and regenerate the BOM.‚Äù The model, drawings, and purchasing spreadsheet all update in seconds.</li>
</ul>

<p>We‚Äôre watching CAD begin to exit the manual-input era. I, for one, am quite excited about that.</p>

<!-- Carousel CSS and JS -->
<style>
.carousel {
  position: relative;
  width: 100%;
  max-width: 700px; /* Adjust as needed */
  margin: 20px auto;
  overflow: hidden;
  border-radius: 8px;
  box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}

.carousel-container {
  display: flex;
  transition: transform 0.5s ease-in-out;
}

.carousel-slide {
  min-width: 100%;
  box-sizing: border-box;
  text-align: center; /* Center image and caption */
  margin: 0; /* Reset figure margin */
  padding: 0; /* Reset figure padding */
}

.carousel-image {
  width: 100%;
  display: block;
  object-fit: contain; /* Scale image nicely */
  max-height: 500px; /* Limit image height */
  margin: 0; /* Ensure no margin */
  padding: 0; /* Ensure no padding */
  vertical-align: middle; /* Align image vertically */
}

.carousel-slide figcaption {
  padding: 10px;
  font-size: 0.9em;
  color: #555;
  background-color: #f8f8f8; /* Light background for caption */
}

.carousel-button {
  position: absolute;
  top: 50%;
  transform: translateY(-50%);
  background-color: rgba(0, 0, 0, 0.5);
  color: white;
  border: none;
  padding: 10px 15px;
  font-size: 20px;
  cursor: pointer;
  border-radius: 50%;
  z-index: 10;
  opacity: 0.7;
  transition: opacity 0.3s ease;
}

.carousel-button:hover {
  opacity: 1;
}

.carousel-button.prev {
  left: 10px;
}

.carousel-button.next {
  right: 10px;
}

.carousel-dots {
  position: absolute;
  bottom: 15px; /* Position above captions if they exist */
  left: 50%;
  transform: translateX(-50%);
  display: flex;
  z-index: 10;
}

.dot {
  height: 10px;
  width: 10px;
  margin: 0 5px;
  background-color: rgba(255, 255, 255, 0.7);
  border-radius: 50%;
  display: inline-block;
  cursor: pointer;
  transition: background-color 0.3s ease;
}

.dot.active {
  background-color: white;
}

/* Adjust button/dot position if figcaption pushes them out */
.carousel-slide figcaption ~ .carousel-button,
.carousel-slide figcaption ~ .carousel-dots {
  /* Consider adjusting 'bottom' or 'top' if needed */
}
</style>

<script>
let carousels = new Map();

function initCarousel(carouselElement) {
  const slides = carouselElement.querySelectorAll('.carousel-slide');
  const dotsContainer = carouselElement.querySelector('.carousel-dots');
  // Use a more robust unique ID for each carousel instance
  const carouselId = `carousel-${Math.random().toString(36).substr(2, 9)}`; 
  
  if (slides.length === 0) return; // Don't initialize if no slides

  carousels.set(carouselId, {
    currentSlide: 0,
    element: carouselElement,
    slides: slides
  });
  
  // Clear and create dots
  dotsContainer.innerHTML = ''; // Ensure it's empty before adding
  slides.forEach((_, i) => {
    const dot = document.createElement('span');
    dot.className = 'dot';
    // Use an anonymous function to pass the carouselId and index correctly
    dot.onclick = () => goToSlide(carouselId, i); 
    dotsContainer.appendChild(dot);
  });
  
  carouselElement.dataset.carouselId = carouselId;
  updateCarousel(carouselId); // Initial setup
}

function moveCarousel(direction, button) {
  const carousel = button.closest('.carousel');
  const carouselId = carousel.dataset.carouselId;
  if (!carouselId || !carousels.has(carouselId)) return;
  
  const state = carousels.get(carouselId);
  state.currentSlide = (state.currentSlide + direction + state.slides.length) % state.slides.length;
  updateCarousel(carouselId);
}

function goToSlide(carouselId, slideIndex) {
  if (!carousels.has(carouselId)) return;
  const state = carousels.get(carouselId);
  state.currentSlide = slideIndex;
  updateCarousel(carouselId);
}

function updateCarousel(carouselId) {
  const state = carousels.get(carouselId);
  if (!state) return;
  
  const container = state.element.querySelector('.carousel-container');
  if (container) {
    container.style.transform = `translateX(-${state.currentSlide * 100}%)`;
  }
  updateDots(carouselId);
}

function updateDots(carouselId) {
  const state = carousels.get(carouselId);
  if (!state) return;
  
  const dots = state.element.querySelectorAll('.dot');
  dots.forEach((dot, i) => {
    dot.classList.toggle('active', i === state.currentSlide);
  });
}

// Initialize all carousels on the page after the DOM is loaded
document.addEventListener('DOMContentLoaded', function() {
  // Find all elements with the 'carousel' class *within this post's content*
  // This assumes the script runs within the context of the post.
  // If not, might need a more specific selector (e.g., '.post-content .carousel')
  const blogCarousels = document.querySelectorAll('.blog-carousel'); 
  blogCarousels.forEach(carouselElement => {
    // Check if already initialized to prevent duplicates if script runs multiple times
    if (!carouselElement.dataset.carouselId) { 
      initCarousel(carouselElement);
    }
  });
});
</script>]]></content><author><name></name></author><category term="Technology" /><summary type="html"><![CDATA[It turns out that LLMs can make CAD models for simple 3D mechanical parts. And, I think they‚Äôll be extremely good at it soon.]]></summary></entry><entry><title type="html">Vibe Code Everything</title><link href="https://willpatrick.xyz/technology/2025/03/27/vibe-everything.html" rel="alternate" type="text/html" title="Vibe Code Everything" /><published>2025-03-27T18:00:00+00:00</published><updated>2025-03-27T18:00:00+00:00</updated><id>https://willpatrick.xyz/technology/2025/03/27/vibe-everything</id><content type="html" xml:base="https://willpatrick.xyz/technology/2025/03/27/vibe-everything.html"><![CDATA[<p>I have been spending a lot of time <span class="annotated-term" data-id="vibe-coding">vibe coding</span> recently. Now, when I come across a task of any type, I think: could I do it in <span class="annotated-term" data-id="cursor">Cursor</span>? Making a quick financial model? Cursor. Building a 3D model of a desk? Cursor. Writing a book for my son? You guessed it, Cursor. It‚Äôs made me think that there‚Äôs a near future where most non-software tasks are done with code. In other words, vibe code everything. Let me tell you how.</p>

<p>My son likes trains, so I wanted to write a short children‚Äôs book about my son and I riding the Muni. I chatted with Cursor and Cursor wrote the story, generated prompts for illustrations, sent API requests for images (using <span class="annotated-term" data-id="replicate">Replicate</span>), and created the final book. I told Cursor to ‚ÄúAdd the text to the images for each page‚Äù, and it created a Python script to add the dialogue to the images. All of this took all of 10-15 minutes and I didn‚Äôt leave the <span class="annotated-term" data-id="ide">IDE</span>. The alternative would have been hours brushing up on photoshop, futsing around with the image generation APIs, tweaking text, and so on. Now that it‚Äôs complete, I can extend the story with a query like, ‚ÄúContinue for 2-3 more pages.‚Äù</p>

<figure>
  <img src="/assets/images/blog/book-page-1.png" alt="Page 1 of the children's book" />
  <figcaption>Page 1 of the book. The text was added to this image with a prompt that said, "Can you add the text to the images. Is there some way you can do that programmatically?". Cursor wrote a script that used PIL library to add the text.</figcaption>
</figure>

<p>I‚Äôm also on the board of a company, and I recently wanted to run a sensitivity analysis of the company‚Äôs operating plan for the next 12 months. I gave Cursor the basic details of the business and then it built a model. After 2-3 iterations and about 90 seconds of actual work time, I had a stunningly useful local web app (just HTML/CSS/JS) where I could move sliders to adjust revenue growth and look at the impact on the company‚Äôs runway. Again, the alternative would have been spending time with Excel (yay!), and the result would have been far less pretty. Check out a demo (with synthetic data) of this <a href="/finmodel/index.html">here</a>.</p>

<figure>
  <img src="/assets/images/blog/financial-model.png" alt="Financial model demo" />
  <figcaption>A demo version (scrubbed of real data) of the simple cash flow model that I made in about ~10-15 mins using Cursor.</figcaption>
</figure>

<p>What enables these new workflows is a combination of code generation, <span class="annotated-term" data-id="agentic-tool-use">agentic tool use</span>, reasoning models, <span class="annotated-term" data-id="model-context-protocol">Model Context Protocol (MCP)</span>, multimodal models, and whatever magic Cursor is doing under the hood to bring in the right context. I chat with the agent about how to solve the problem and then we write documents, create images, write code, and use tools. The key unlock is that, in this new world, everything is programmable. For example, a markdown document can be updated with a simple query  (‚ÄúOutline each page of Jasper‚Äôs story in a markdown doc.‚Äù). Alternatively, a markdown document can serve as input data to another action (‚ÄúFor each page, create a prompt that we can use to generate an image via the Replicate MCP.‚Äù)</p>

<p>I think these powerful vibe everything workflows will extend beyond personal tasks to how we complete most work. AI native start-ups are already using the IDE to quickly and effectively complete non-software tasks. And, I think it‚Äôs a safe assumption that this approach will have a huge impact on many if not the majority of businesses in the near future.</p>

<h2 id="as-always-start-ups-are-on-the-vanguard">As always, start-ups are on the vanguard</h2>

<p>My friends running AI native startups are using IDE agents as a core part of their business already. For example, Tim Delisle, founder of FiveOneFour told me recently <span class="annotated-term" data-id="company-repo">his entire company lives in a GitHub repo</span>. Strategy documents, sales assets, marketing materials‚Äîall in markdown. The benefits? Everything‚Äôs version-controlled. No time spent switching to a different UI.  And, again, everything is programmable. This enables superpowers like automatically creating customer-specific sales and marketing assets from template markdown materials, or automatically updating company strategy and comms based on product progress.</p>

<p>Another founder running an AI agent start-up showed me his custom <span class="annotated-term" data-id="crm">CRM</span> using <span class="annotated-term" data-id="sqlite">SQLite</span> and ~10 scripts. It pulls lead data from the web, generates personalized cold emails, tracks responses, and updates automatically. He looked at off-the-shelf CRMs, but their workflows didn‚Äôt make it easy to programmatically interface with the data. And, features like permissioning were an impediment.</p>

<figure>
  <img src="/assets/images/blog/crm-ui.png" alt="Custom CRM UI" />
  <figcaption>The read-only UI for the CRM that my friend built. To blur the email addresses in the image above, I first tried to use the recently launched <span class="annotated-term" data-id="gpt4o-image-generation">GPT4o image generation</span>. Didn't work. Instead, I asked Cursor to do it, and it wrote a script that worked beautifully.</figcaption>
</figure>

<p>Why does this matter? Obviously, large companies won‚Äôt move their businesses into GitHub repos (yet!). But, AI-native startups will grow and I think this vibe everything approach will become a core part of company building.</p>

<h2 id="here-are-3-ways-i-see-this-playing-out">Here are 3 ways I see this playing out:</h2>

<ol>
  <li>
    <p>There are many existing SaaS apps that don‚Äôt need to be re-built. <span class="annotated-term" data-id="hris">HRIS</span> systems (e.g. Rippling) come to mind as a prime example; it would be silly for a start-up to build out all of the regulatory logic/workflows into their own in-house app. Instead of building their own, IDE dwellers will want to interface with these apps programmatically using Model Context Protocol (MCP) (‚ÄúUpdate my board deck in my company strategy folder with our org chart from Rippling‚Äù). If existing apps fail to create a programmatic interface, we could see new players that are MCP-first (with only a lightweight UI) that compete with them.</p>
  </li>
  <li>
    <p>I think business critical software like Hubspot will be exploded into 5-20 modular sub-components available via API, enabling AI native start-ups to easily create their own software for core business apps. For example, the founder who built the CRM wanted to use a hosted API service for writing cold email campaigns with built-in best practices. There‚Äôs a big opportunity for new start-ups to build these modular app components.</p>
  </li>
  <li>
    <p>Finally, some currently popular apps won‚Äôt be used by AI native start-ups. I‚Äôve found myself using Google Docs only in particularly situations where I need collaborative feedback (e.g. like this blog post). Even Notion, which has nailed AI integration, is not necessary for most work that I do. I imagine this will accelerate once some kind of collaborative / multiplayer Cursor/IDE is created.</p>
  </li>
</ol>

<h2 id="vibe-everything">Vibe everything</h2>

<p>Did I convince you to dive in? Maybe it‚Äôs all a little overwhelming? If you want a place to start, here‚Äôs a suggestion. Download <a href="https://cursor.sh">Cursor</a>. Switch into Agent mode in the menu at the bottom of the chat.</p>

<p>Now think of the next task on your to-do list that involves creating any kind of output. Type in the prompt: ‚ÄúI want to make a ___. How should we start?‚Äù</p>

<p>And see what happens :)</p>]]></content><author><name></name></author><category term="Technology" /><summary type="html"><![CDATA[I have been spending a lot of time vibe coding recently. Now, when I come across a task of any type, I think: could I do it in Cursor? Making a quick financial model? Cursor. Building a 3D model of a desk? Cursor. Writing a book for my son? You guessed it, Cursor. It‚Äôs made me think that there‚Äôs a near future where most non-software tasks are done with code. In other words, vibe code everything. Let me tell you how.]]></summary></entry><entry><title type="html">Software with a Market of One</title><link href="https://willpatrick.xyz/software/2025/03/17/software-with-a-market-of-one.html" rel="alternate" type="text/html" title="Software with a Market of One" /><published>2025-03-17T18:00:00+00:00</published><updated>2025-03-17T18:00:00+00:00</updated><id>https://willpatrick.xyz/software/2025/03/17/software-with-a-market-of-one</id><content type="html" xml:base="https://willpatrick.xyz/software/2025/03/17/software-with-a-market-of-one.html"><![CDATA[<p>Two months ago, I needed a new personal website and decided to give codegen a spin. Friends pointed me to Cursor and, hours later, I had a markdown <a href="https://willpatrick.xyz">website</a> on a shiny new domain. Had I known hours earlier that Github hosted websites? Nope. How about a <a href="https://willpatrick.xyz/growth/">bio-inspired art thing</a> for the entrance animation? Bang. Unnecessary but <span class="annotated-term" data-id="useful-annotations"> useful annotations</span> on my CV page? Letsss gooo. Suddenly, I realized I could easily build my own software, and that this was true for everyone else.</p>

<p>In college, I first encountered the steep learning curve of syntax, methods, and functions. My classmates, it appeared, had been coding since they were 12 and flew through our assignments. Thoroughly deflated, I focused on hardware for the rest of my career, leaving software to others.</p>

<p>Cursor lodged dynamite in programming‚Äôs steep learning curve and blew it up in a giant, joyous explosion. Never in my life have I gone so quickly from thought to useful thing. The world of code is no longer off limits to me.</p>

<p>After building my website, I realized that I was a single wildebeest in a stampede. Daily, I‚Äôm meeting folks coding for the first time, dusting off out of reach app ideas. We all realized, oh shit, we can build software now.</p>

<p>I‚Äôve been calling this <span class="annotated-term" data-id="market-of-one">software with a market of one</span>. To solve a problem. To make software more personal. To have fun. What an awesome opportunity for us to use AI to become creators instead of consumers.</p>

<p>Some of this software will be terrible at first. I recently built a new app and it was bad. But building it gave me some new ideas that might actually be good. And, that little loop (idea -&gt; it‚Äôs real! -&gt; it sucks -&gt; but it could be better!) can now happen very quickly, accelerating our ability to develop useful applications.</p>

<p>The first order impacts on tech seem clear. <a href="https://techcrunch.com/2025/03/06/a-quarter-of-startups-in-ycs-current-cohort-have-codebases-that-are-almost-entirely-ai-generated/">25% of YC founders</a> in the current batch said that 95% of their code base is generated by AI. Start-ups building software will have fewer people and <a href="https://techcrunch.com/2025/03/11/y-combinator-founders-raising-less-money-signal-a-vibe-shift-vc-says/">need less capital</a>. Products that serve TAMs too small for VCs, like software for life scientists, are much more likely to be built by small, bootstrapped teams. Start-ups are now distributing technology created by large companies by finding the niche industry applications. Software with programmatic interfaces, which I had always thought were quite strange, can suddenly be controlled by text or voice (example: <a href="https://x.com/sidahuj/status/1899586709752594919">Blender</a>).</p>

<p>And, the role of enterprise SaaS companies is likely to change. If an employee needs to automate a workflow, they can build it themselves. And, the time saved from deleting the software procurement process is massive. Instead of SaaS, dev tool companies (code generation tools, models, etc) that serve employees or AI agents through a code gen interface will flourish.</p>

<p>Many work tasks can be completed using disposable micro-apps. Need a quick financial model for a business? Ask Claude Code to build one with sliders and dials for sensitivity analysis. Sometimes, it will simply be faster to build a tool than to hunt for the right pre-existing one. Given that the majority of coding time is waiting for codegen to finish, writing apps will get faster and faster.</p>

<p>Code generation will become a central aspect within products too. Want to customize the display of your oven? Ask it to do so and the oven will generate, test, and run the front-end code for your desired UI. Customization could be automated too with each person‚Äôs taste profile communicated to software products via API.</p>

<p>Mass customization probably won‚Äôt end with software. Code generation is the first breakthrough AI application, but it won‚Äôt be the last. Why won‚Äôt there be something similar for comics? Designing mechanical parts? Architecture? Fiction? Movies? It seems like it‚Äôs just a matter of time.</p>]]></content><author><name></name></author><category term="Software" /><summary type="html"><![CDATA[Two months ago, I needed a new personal website and decided to give codegen a spin. Friends pointed me to Cursor and, hours later, I had a markdown website on a shiny new domain. Had I known hours earlier that Github hosted websites? Nope. How about a bio-inspired art thing for the entrance animation? Bang. Unnecessary but useful annotations on my CV page? Letsss gooo. Suddenly, I realized I could easily build my own software, and that this was true for everyone else.]]></summary></entry></feed>